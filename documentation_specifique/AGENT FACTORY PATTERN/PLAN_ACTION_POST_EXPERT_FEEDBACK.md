# ğŸš€ **PLAN D'ACTION RÃ‰VISÃ‰ - AGENT FACTORY PATTERN**
## **Roadmap OptimisÃ©e Post-Expert Feedback avec Shift-Left Security**

---

## ğŸ“‹ **SYNTHÃˆSE EXÃ‰CUTIVE CONSOLIDÃ‰E**

### **âœ… VALIDATION UNANIME DES 3 EXPERTS**
- **Claude (Anthropic)** : Architecture entreprise + Code production-ready âœ…
- **ChatGPT (OpenAI)** : Plan d'implÃ©mentation pragmatique + Timeline concrÃ¨te âœ…  
- **Gemini (Google)** : Innovations avancÃ©es + Vision long terme âœ…

### **ğŸ¯ OBJECTIF VALIDÃ‰ ET RAFFINÃ‰**
- **RÃ©duction 80%** du temps de crÃ©ation d'agents (2-3h â†’ 3-5 minutes) âœ…
- **Architecture Orchestration as a Service** validÃ©e comme future-ready âœ…
- **SÃ©curitÃ© Shift-Left** : Signature crypto dÃ¨s Sprint 2 (non plus Phase 3) âœ…

### **âš¡ OPTIMISATIONS PLAN RÃ‰VISÃ‰**
- **Gain temps 20%** : Fusion phases redondantes
- **SÃ©curitÃ© avancÃ©e** : Semaine +1 (vs Semaine +2 initialement)
- **Production-ready** : Semaine +4 avec perf + monitoring complets

---

## ğŸƒâ€â™‚ï¸ **ROADMAP SPRINT-BASED OPTIMISÃ‰E**

### **ğŸ“… SPRINT 0 - KICK-OFF (J+0 â†’ J+2)**
*Fusion des anciennes Phase 1 J+0 et J+1 pour gagner 1 jour*

#### **ğŸ¯ OBJECTIF**
Code base production-ready opÃ©rationnelle avec CI/CD

#### **ğŸ“¦ LIVRABLES MAJEURS**
- **Merge code Claude** : Adoption versions optimisÃ©es AgentTemplate + TemplateManager
- **Config Pydantic unifiÃ©e** : Configuration centralisÃ©e avec variables environnement
- **CI "smoke" + lint** : GitHub Actions avec mypy --strict + ruff (fail-fast)

#### **ğŸ”§ ACTIONS DÃ‰TAILLÃ‰ES**

**J+0 : Migration Code Base (4h)**
```bash
# Backup + adoption versions Claude
cp orchestrator/app/agents/agent_templates.py orchestrator/app/agents/agent_templates.py.bak
cp enhanced-agent-templates.py orchestrator/app/agents/agent_templates.py
cp optimized-template-manager.py orchestrator/app/agents/template_manager.py
```

**J+1 : Configuration UnifiÃ©e (3h)**
```python
# orchestrator/app/config/agent_config.py
class AgentFactoryConfig(BaseSettings):
    # Chemins
    templates_dir: Path = Path(__file__).resolve().parent.parent / "agents" / "templates"
    
    # Performance optimisÃ©e
    cache_ttl: float = 300.0        # 5 min prod, 60s dev (adaptatif)
    max_workers: int = 8            # ThreadPool auto-tuned
    
    # SÃ©curitÃ© (prÃ©paration Sprint 2)
    enable_signature_validation: bool = True  # ActivÃ© dÃ¨s Sprint 2
    rsa_public_key_path: str = "keys/template_signing.pub"
    
    class Config:
        env_prefix = "NG_"
```

**J+2 : CI/CD Pipeline (2h)**
```yaml
# .github/workflows/agent-factory-ci.yml
name: Agent Factory CI
on: [push, pull_request]
jobs:
  quality:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: 3.11
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Lint with ruff
        run: ruff check . --fix
      - name: Type check with mypy
        run: mypy --strict orchestrator/app/agents/
      - name: Security scan
        run: pip-audit --desc
      - name: Smoke tests
        run: pytest tests/test_smoke.py -v
```

#### **âœ… DEFINITION OF DONE SPRINT 0**
- âœ… Code Claude intÃ©grÃ© et fonctionnel
- âœ… Configuration Pydantic centralisÃ©e
- âœ… CI pipeline opÃ©rationnelle (lint + type check + smoke tests)
- âœ… 0 vulnÃ©rabilitÃ© critical/high (pip-audit)

---

### **ğŸ“… SPRINT 1 - TESTS & OBSERVABILITÃ‰ DE BASE (J+3 â†’ J+6)**

#### **ğŸ¯ OBJECTIF**
Validation robustesse et performance avec monitoring basique

#### **ğŸ“¦ LIVRABLES MAJEURS**
- **Tests complets** : HÃ©ritage, hot-reload, performance
- **Endpoint mÃ©triques** : /factory/metrics + /health
- **Benchmark Locust** : Validation < 100ms/agent en CI

#### **ğŸ§ª TESTS SPÃ‰CIFIQUES**

**J+3-4 : Tests Fonctionnels (6h)**
```python
# tests/test_template_inheritance.py - HÃ©ritage templates
# tests/test_hot_reload.py - Rechargement automatique
# tests/test_scalability_load.py - Performance parallÃ¨le

# Nouveau : Benchmark Locust intÃ©grÃ© CI
# tests/locust_benchmark.py
from locust import HttpUser, task, between

class AgentFactoryUser(HttpUser):
    wait_time = between(0.1, 0.5)
    
    @task
    def create_agent(self):
        response = self.client.post("/factory/agents", 
                                  json={"template_name": "documentaliste"})
        assert response.status_code == 200
        # Validation < 100ms
        assert response.elapsed.total_seconds() < 0.1
```

**J+5-6 : API MÃ©triques (4h)**
```python
# orchestrator/app/main.py - Endpoints monitoring
@app.get("/factory/metrics")
def get_factory_metrics():
    return {
        "templates_loaded": template_manager.get_metrics()["templates_loaded"],
        "cache_hit_rate": template_manager.get_metrics()["cache_hit_rate"],
        "creation_time_p95": template_manager.get_metrics()["creation_time_p95"],
        "active_agents": len(template_manager.active_agents)
    }

@app.get("/health")
def health_check():
    stats = agent_factory.get_factory_stats()
    return {
        "status": "healthy" if stats["templates_loaded"] > 0 else "degraded",
        "version": "1.0.0-sprint1",
        "uptime_seconds": time.time() - start_time
    }
```

#### **âœ… DEFINITION OF DONE SPRINT 1**
- âœ… Tests hÃ©ritage + hot-reload + performance verts
- âœ… Benchmark Locust < 100ms/agent validÃ© en CI
- âœ… API mÃ©triques exposÃ©e et documentÃ©e
- âœ… p95 performance respectÃ©

---

### **ğŸ“… SPRINT 2 - SÃ‰CURITÃ‰ "SHIFT-LEFT" (Semaine +1)**
*Avancement majeur : SÃ©curitÃ© cryptographique dÃ¨s maintenant (non plus Sprint 3)*

#### **ğŸ¯ OBJECTIF**
SÃ©curitÃ© entreprise opÃ©rationnelle avant staging

#### **ğŸ“¦ LIVRABLES MAJEURS**
- **Signature RSA 2048 + SHA-256** : Validation obligatoire au load des templates
- **Policy OPA basique** : Blacklist tools dangereux
- **Rotation clÃ©s** : IntÃ©gration Vault + alertes Prometheus

#### **ğŸ” SÃ‰CURITÃ‰ CRYPTOGRAPHIQUE**

```python
# orchestrator/app/security/crypto_validator.py
from cryptography.hazmat.primitives import hashes, serialization
from cryptography.hazmat.primitives.asymmetric import rsa, padding
import json
import hashlib
import logging

logger = logging.getLogger(__name__)

class ProductionSecurityValidator:
    """Validation cryptographique production (RSA 2048 + SHA-256)"""
    
    def __init__(self, public_key_path: str):
        try:
            with open(public_key_path, "rb") as f:
                self.public_key = serialization.load_pem_public_key(f.read())
            logger.info(f"ClÃ© publique chargÃ©e: {public_key_path}")
        except Exception as e:
            logger.error(f"Ã‰chec chargement clÃ©: {e}")
            raise
            
    def verify_template_signature(self, template_data: Dict, signature_b64: str) -> bool:
        """VÃ©rification signature template (obligatoire)"""
        try:
            # DÃ©codage signature base64
            signature = base64.b64decode(signature_b64)
            
            # Hash canonique du template
            template_content = json.dumps(template_data, sort_keys=True, separators=(',', ':'))
            template_hash = hashlib.sha256(template_content.encode('utf-8')).digest()
            
            # VÃ©rification RSA-PSS
            self.public_key.verify(
                signature,
                template_hash,
                padding.PSS(
                    mgf=padding.MGF1(hashes.SHA256()),
                    salt_length=padding.PSS.MAX_LENGTH
                ),
                hashes.SHA256()
            )
            
            logger.debug(f"Signature valide pour template {template_data.get('name')}")
            return True
            
        except Exception as e:
            logger.error(f"Signature invalide: {e}")
            return False
            
    def validate_policy_opa(self, template_data: Dict) -> bool:
        """Validation politique OPA basique"""
        dangerous_tools = [
            "shell_command", "file_system_write", "network_access", 
            "subprocess", "eval", "exec"
        ]
        
        tools = template_data.get("tools", [])
        blocked_tools = [tool for tool in tools if tool in dangerous_tools]
        
        if blocked_tools:
            logger.warning(f"Tools bloquÃ©s par politique: {blocked_tools}")
            return False
            
        return True
```

#### **ğŸ”„ ROTATION CLÃ‰S & MONITORING**

```python
# orchestrator/app/security/key_rotation.py
import hvac  # HashiCorp Vault
from prometheus_client import Counter

SIGNATURE_FAILURES = Counter('template_signature_failures_total', 
                            'Template signature validation failures')

class KeyRotationManager:
    """Gestion rotation clÃ©s via Vault"""
    
    def __init__(self, vault_url: str, vault_token: str):
        self.vault_client = hvac.Client(url=vault_url, token=vault_token)
        
    def get_current_public_key(self) -> str:
        """RÃ©cupÃ©ration clÃ© publique courante depuis Vault"""
        response = self.vault_client.secrets.kv.v2.read_secret_version(
            path='agent-factory/signing-keys'
        )
        return response['data']['data']['public_key']
        
    def rotate_keys_if_needed(self) -> bool:
        """Rotation automatique si nÃ©cessaire"""
        # Logique rotation basÃ©e sur Ã¢ge clÃ© + mÃ©triques Ã©checs
        failure_rate = SIGNATURE_FAILURES._value.get()
        if failure_rate > 10:  # Seuil alerte
            logger.warning("Taux Ã©chec signature Ã©levÃ© - rotation recommandÃ©e")
            return True
        return False
```

#### **âœ… DEFINITION OF DONE SPRINT 2**
- âœ… Signature RSA obligatoire et fonctionnelle
- âœ… Policy OPA bloque tools dangereux
- âœ… IntÃ©gration Vault pour rotation clÃ©s
- âœ… MÃ©triques sÃ©curitÃ© exposÃ©es Prometheus
- âœ… 0 vulnÃ©rabilitÃ© critical/high Trivy

---

### **ğŸ“… SPRINT 3 - CONTROL/DATA PLANE & SANDBOX (Semaine +2)**

#### **ğŸ¯ OBJECTIF**
Architecture sÃ©parÃ©e + Sandbox pour agents Ã  risque

#### **ğŸ“¦ LIVRABLES MAJEURS**
- **Refactor Control/Data Plane** : SÃ©paration gouvernance/exÃ©cution
- **WASI sandbox prototype** : Isolation agents risquÃ©s
- **RBAC minimale FastAPI** : Authentification/autorisation

#### **ğŸ—ï¸ ARCHITECTURE SÃ‰PARÃ‰E**

```python
# orchestrator/app/planes/control_plane.py
class ControlPlane:
    """Plan contrÃ´le - Gouvernance et politiques"""
    
    def __init__(self):
        self.security_validator = ProductionSecurityValidator("keys/template_signing.pub")
        self.policy_engine = OPAPolicyEngine()
        self.audit_logger = AuditLogger()
        
    async def authorize_agent_creation(self, 
                                     template_name: str, 
                                     user_context: Dict) -> AuthResult:
        """Autorisation crÃ©ation agent avec audit"""
        
        # 1. Validation utilisateur
        if not self._validate_user_permissions(user_context):
            self.audit_logger.log_access_denied(user_context, template_name)
            raise PermissionError("Permissions insuffisantes")
            
        # 2. Validation template sÃ©curisÃ©
        template = await template_manager.get_template_async(template_name)
        if not self.security_validator.verify_template_signature(
            template.data, template.signature
        ):
            self.audit_logger.log_security_violation(template_name, "signature_invalid")
            raise SecurityError("Signature template invalide")
            
        # 3. Validation politique
        if not self.security_validator.validate_policy_opa(template.data):
            self.audit_logger.log_policy_violation(template_name, template.data.get("tools"))
            raise PolicyError("Violation politique sÃ©curitÃ©")
            
        return AuthResult(authorized=True, sandbox_required=self._requires_sandbox(template))

# orchestrator/app/planes/data_plane.py
class DataPlane:
    """Plan donnÃ©es - ExÃ©cution isolÃ©e"""
    
    def __init__(self):
        self.wasi_sandbox = WASISandbox()
        self.native_executor = NativeExecutor()
        
    async def execute_agent_creation(self, 
                                   template_name: str, 
                                   auth_result: AuthResult) -> Agent:
        """ExÃ©cution crÃ©ation avec isolation appropriÃ©e"""
        
        if auth_result.sandbox_required:
            # ExÃ©cution sandboxÃ©e WASI
            return await self.wasi_sandbox.create_agent_safely(template_name)
        else:
            # ExÃ©cution native optimisÃ©e
            return await self.native_executor.create_agent(template_name)
```

#### **ğŸ” SANDBOX WASI PROTOTYPE**

```python
# orchestrator/app/sandbox/wasi_sandbox.py
import wasmtime
from typing import Dict, Any

class WASISandbox:
    """Sandbox WASI pour agents Ã  risque"""
    
    def __init__(self):
        self.engine = wasmtime.Engine()
        self.overhead_threshold = 0.2  # 20% overhead max
        
    async def create_agent_safely(self, template_name: str) -> Agent:
        """CrÃ©ation agent en environnement isolÃ©"""
        
        start_time = time.time()
        
        # Configuration WASI avec restrictions
        wasi_config = wasmtime.WasiConfig()
        wasi_config.inherit_stdout()
        wasi_config.inherit_stderr()
        # Pas d'accÃ¨s filesystem par dÃ©faut
        
        store = wasmtime.Store(self.engine)
        store.set_wasi(wasi_config)
        
        try:
            # Chargement module WASM agent
            module = wasmtime.Module(self.engine, self._compile_agent_to_wasm(template_name))
            instance = wasmtime.Instance(store, module, [])
            
            # ExÃ©cution contrÃ´lÃ©e
            agent = self._execute_agent_creation(store, instance, template_name)
            
            # VÃ©rification overhead
            execution_time = time.time() - start_time
            native_time = await self._benchmark_native_creation(template_name)
            overhead = (execution_time - native_time) / native_time
            
            if overhead > self.overhead_threshold:
                logger.warning(f"Sandbox overhead {overhead:.1%} > {self.overhead_threshold:.1%}")
                
            return agent
            
        except Exception as e:
            logger.error(f"Ã‰chec sandbox WASI: {e}")
            raise SandboxError(f"Isolation failed: {e}")
```

#### **âœ… DEFINITION OF DONE SPRINT 3**
- âœ… Control/Data Plane sÃ©parÃ©s et opÃ©rationnels
- âœ… Sandbox WASI fonctionnel avec overhead < 20%
- âœ… RBAC FastAPI intÃ©grÃ©
- âœ… Audit trail complet
- âœ… Tests intÃ©gration Control â†” Data Plane

---

### **ğŸ“… SPRINT 4 - OBSERVABILITÃ‰ AVANCÃ‰E & PERF (Semaine +3)**

#### **ğŸ¯ OBJECTIF**
Monitoring production-grade + Optimisations performance

#### **ğŸ“¦ LIVRABLES MAJEURS**
- **Tracing OpenTelemetry** : Traces distribuÃ©es complÃ¨tes
- **Prometheus counters** : TTL, cache hits, p95
- **ThreadPool auto-tuned** : CPU Ã— 2 avec adaptation charge
- **Compression .json.zst** : RÃ©duction mÃ©moire 5-10Ã—

#### **ğŸ“Š OBSERVABILITÃ‰ OPENTELEMETRY**

```python
# orchestrator/app/monitoring/tracing.py
from opentelemetry import trace
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor

# Configuration tracing
trace.set_tracer_provider(TracerProvider())
tracer = trace.get_tracer(__name__)

jaeger_exporter = JaegerExporter(
    agent_host_name="localhost",
    agent_port=6831,
)
span_processor = BatchSpanProcessor(jaeger_exporter)
trace.get_tracer_provider().add_span_processor(span_processor)

# Instrumentation Agent Factory
class TracedAgentFactory(AgentFactory):
    
    @tracer.start_as_current_span("agent_creation")
    async def create_agent(self, template_name: str, **kwargs):
        span = trace.get_current_span()
        span.set_attribute("template.name", template_name)
        span.set_attribute("template.version", await self._get_template_version(template_name))
        
        start_time = time.time()
        try:
            agent = await super().create_agent(template_name, **kwargs)
            span.set_attribute("creation.success", True)
            return agent
        except Exception as e:
            span.set_attribute("creation.success", False)
            span.set_attribute("error.message", str(e))
            raise
        finally:
            creation_time = time.time() - start_time
            span.set_attribute("creation.duration_ms", creation_time * 1000)
            AGENT_CREATION_TIME.observe(creation_time)
```

#### **âš¡ OPTIMISATIONS PERFORMANCE**

```python
# orchestrator/app/optimization/adaptive_threading.py
import psutil
from concurrent.futures import ThreadPoolExecutor
from threading import Lock

class AdaptiveThreadPool:
    """ThreadPool auto-adaptatif selon charge CPU"""
    
    def __init__(self):
        self.base_workers = psutil.cpu_count() * 2
        self.current_workers = self.base_workers
        self.executor = ThreadPoolExecutor(max_workers=self.current_workers)
        self.adjustment_lock = Lock()
        
    def adapt_to_load(self):
        """Adaptation dynamique selon charge systÃ¨me"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory_percent = psutil.virtual_memory().percent
        
        with self.adjustment_lock:
            if cpu_percent > 80 and self.current_workers > self.base_workers // 2:
                # RÃ©duction charge CPU Ã©levÃ©e
                self.current_workers = max(self.current_workers - 2, self.base_workers // 2)
                self._resize_executor()
            elif cpu_percent < 50 and memory_percent < 70:
                # Augmentation si ressources disponibles
                self.current_workers = min(self.current_workers + 1, self.base_workers * 2)
                self._resize_executor()
                
    def _resize_executor(self):
        """Redimensionnement ThreadPool"""
        old_executor = self.executor
        self.executor = ThreadPoolExecutor(max_workers=self.current_workers)
        old_executor.shutdown(wait=False)
        logger.info(f"ThreadPool redimensionnÃ©: {self.current_workers} workers")

# orchestrator/app/optimization/compression.py
import zstandard as zstd
import json

class TemplateCompression:
    """Compression templates JSON avec Zstandard"""
    
    def __init__(self):
        self.compressor = zstd.ZstdCompressor(level=3)
        self.decompressor = zstd.ZstdDecompressor()
        
    def compress_template(self, template_data: Dict) -> bytes:
        """Compression template JSON"""
        json_bytes = json.dumps(template_data, separators=(',', ':')).encode('utf-8')
        compressed = self.compressor.compress(json_bytes)
        
        compression_ratio = len(compressed) / len(json_bytes)
        logger.debug(f"Compression ratio: {compression_ratio:.2%}")
        
        return compressed
        
    def decompress_template(self, compressed_data: bytes) -> Dict:
        """DÃ©compression template"""
        json_bytes = self.decompressor.decompress(compressed_data)
        return json.loads(json_bytes.decode('utf-8'))
```

#### **âœ… DEFINITION OF DONE SPRINT 4**
- âœ… Tracing OpenTelemetry opÃ©rationnel
- âœ… MÃ©triques Prometheus complÃ¨tes (p95, cache, TTL)
- âœ… ThreadPool adaptatif selon charge
- âœ… Compression templates active (gain mÃ©moire mesurÃ©)
- âœ… Performance < 50ms/agent validÃ©e

---

### **ğŸ“… SPRINT 5 - RELEASE CANDIDATE (Semaine +4)**

#### **ğŸ¯ OBJECTIF**
DÃ©ploiement production avec validation chaos engineering

#### **ğŸ“¦ LIVRABLES MAJEURS**
- **K8s blue-green deploy** : Helm chart production-ready
- **Chaos test** : 25% nodes off + validation rÃ©silience
- **Doc "Operator runbook"** : ProcÃ©dures opÃ©rationnelles

#### **ğŸš€ DÃ‰PLOIEMENT KUBERNETES**

```yaml
# helm/agent-factory/values.yaml
replicaCount: 3

image:
  repository: nextgeneration/agent-factory
  tag: "1.0.0-rc1"
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 8000

ingress:
  enabled: true
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
  hosts:
    - host: agent-factory.nextgen.local
      paths:
        - path: /
          pathType: Prefix

resources:
  limits:
    cpu: 2000m
    memory: 4Gi
  requests:
    cpu: 1000m
    memory: 2Gi

autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70

monitoring:
  serviceMonitor:
    enabled: true
    interval: 30s
    path: /metrics
```

#### **ğŸ’¥ CHAOS ENGINEERING**

```python
# tests/chaos/chaos_test.py
import pytest
import kubernetes
import time
import requests

class ChaosTestSuite:
    """Tests rÃ©silience avec Chaos Engineering"""
    
    def __init__(self):
        self.k8s_client = kubernetes.client.ApiClient()
        self.base_url = "http://agent-factory.nextgen.local"
        
    @pytest.mark.chaos
    def test_node_failure_resilience(self):
        """Test rÃ©silience avec 25% nodes arrÃªtÃ©s"""
        
        # 1. Baseline performance
        baseline_latency = self._measure_average_latency()
        
        # 2. ArrÃªt 25% des nodes
        nodes_to_stop = self._get_worker_nodes()[:len(self._get_worker_nodes()) // 4]
        
        for node in nodes_to_stop:
            self._cordon_and_drain_node(node)
            
        time.sleep(30)  # Stabilisation
        
        # 3. Validation service toujours opÃ©rationnel
        chaos_latency = self._measure_average_latency()
        
        # 4. Assertions
        assert chaos_latency < baseline_latency * 2  # DÃ©gradation < 100%
        assert self._check_service_health()
        
        # 5. Restauration
        for node in nodes_to_stop:
            self._uncordon_node(node)
            
    def _measure_average_latency(self, samples=100) -> float:
        """Mesure latence moyenne crÃ©ation agents"""
        latencies = []
        
        for _ in range(samples):
            start = time.time()
            response = requests.post(f"{self.base_url}/factory/agents",
                                   json={"template_name": "documentaliste"})
            latency = time.time() - start
            
            assert response.status_code == 200
            latencies.append(latency)
            
        return sum(latencies) / len(latencies)
```

#### **ğŸ“š OPERATOR RUNBOOK**

```markdown
# Agent Factory - Operator Runbook

## ğŸš¨ Alertes Critiques

### Template Signature Failures > 10/min
**SymptÃ´me**: MÃ©triques `template_signature_failures_total` Ã©levÃ©es
**Action**: 
1. VÃ©rifier rotation clÃ©s Vault
2. Analyser logs sÃ©curitÃ©
3. DÃ©clencher rotation manuelle si nÃ©cessaire

### Cache Hit Rate < 80%
**SymptÃ´me**: Performance dÃ©gradÃ©e, latence Ã©levÃ©e
**Action**:
1. VÃ©rifier TTL configuration
2. Analyser patterns d'accÃ¨s templates
3. Ajuster cache_ttl si nÃ©cessaire

### Pod Memory > 90%
**SymptÃ´me**: Risque OOMKilled
**Action**:
1. VÃ©rifier compression templates active
2. Analyser fuites mÃ©moire potentielles
3. Scale horizontal si nÃ©cessaire

## ğŸ”§ ProcÃ©dures Maintenance

### Rotation ClÃ©s Signature
```bash
# 1. GÃ©nÃ©ration nouvelle paire
openssl genrsa -out private_new.pem 2048
openssl rsa -in private_new.pem -pubout -out public_new.pem

# 2. Upload Vault
vault kv put agent-factory/signing-keys public_key=@public_new.pem

# 3. Rolling restart
kubectl rollout restart deployment/agent-factory
```

### Mise Ã  jour Templates
```bash
# 1. Signature nouveau template
python scripts/sign_template.py new_template.json

# 2. DÃ©ploiement
kubectl create configmap agent-templates --from-file=templates/ --dry-run=client -o yaml | kubectl apply -f -

# 3. Hot-reload automatique (watchdog)
```
```

#### **âœ… DEFINITION OF DONE SPRINT 5**
- âœ… DÃ©ploiement K8s blue-green fonctionnel
- âœ… Chaos test 25% nodes passant
- âœ… Runbook opÃ©rateur complet
- âœ… Monitoring production opÃ©rationnel
- âœ… SLA < 100ms p95 respectÃ© en production

---

## ğŸ¯ **BACKLOG NEXT QUARTER**
*Innovations futures hors pÃ©rimÃ¨tre MVP*

### **ğŸ“ˆ ROADMAP LONG TERME**
- **Agent Marketplace** : Ã‰cosystÃ¨me partage agents (Claude)
- **Interface NLP** : CrÃ©ation agents langage naturel
- **GNN Recommender** : Recommandations agents intelligentes
- **Multi-modal Agents** : Support images/audio/documents (Gemini)

---

## ğŸ”‘ **TÃ‚CHES TRANSVERSES**

### **ğŸ“Š QUALITÃ‰ DE CODE**
- **mypy --strict** : Fail-fast dÃ¨s Sprint 0
- **ruff** : Linting automatique
- **Coverage** : > 90% tests unitaires + intÃ©gration

### **ğŸ”’ SUPPLY CHAIN SECURITY**
- **pip-audit** : Scan vulnÃ©rabilitÃ©s intÃ©grÃ© CI
- **Trivy** : Scan containers + dÃ©pendances
- **SBOM** : Software Bill of Materials gÃ©nÃ©rÃ©

### **âš ï¸ RISQUES & MITIGATIONS**

| Risque | Mitigation | Sprint |
|--------|------------|---------|
| Hot-reload CPU intensif | TTL adaptatif + debounce watchdog | 1 |
| ClÃ© RSA compromise | Rotation Vault + alertes Prometheus | 2 |
| Sandbox overhead > 20% | Benchmark WASI vs Native, activation conditionnelle | 3 |
| Latence production > SLA | Auto-scaling + ThreadPool adaptatif | 4 |

---

## ğŸ“‰ **Ã‰CONOMIE TEMPS OBTENUE**

| Ã‰tape | Plan Original | Plan RÃ©visÃ© | Gain |
|-------|---------------|-------------|------|
| **Bases fusionnÃ©es** | 2 jours | 1 jour | -50% |
| **SÃ©curitÃ© disponible** | Semaine +2 | Semaine +1 | -1 semaine |
| **Production ready** | Semaine +2 post-Phase 4 | Semaine +4 (complet) | +monitoring |

**Gain net : ~20% dÃ©lai global sans supprimer aucune exigence business**

---

## ğŸš¦ **PROCHAINES ACTIONS IMMÃ‰DIATES**

### **âœ… VALIDATION JALONNEMENT**
- Daily team 15min pour validation nouveau planning
- CrÃ©ation branche `roadmap/v2-optimized`
- Issue Sprint 0 avec checklist dÃ©taillÃ©e

### **ğŸš€ SPRINT 0 KICKOFF**
**Checklist Sprint 0 :**
- [ ] Merge code Claude (AgentTemplate + TemplateManager)
- [ ] Config Pydantic unifiÃ©e
- [ ] CI smoke tests + lint (GitHub Actions)
- [ ] Validation imports + tests basiques
- [ ] Documentation Sprint 1 prÃ©parÃ©e

**Une fois Sprint 0 terminÃ© (J+2) :**
- Revue pipeline CI + rapport Locust
- Validation mÃ©triques baseline
- Lancement Sprint 1

---

**ğŸ¯ Plan d'action rÃ©visÃ© intÃ©grant shift-left security, optimisations temporelles et suppression des redondances pour livraison production-ready Semaine +4** 