#!/usr/bin/env python3
"""
ğŸ§ª Test des Nouveaux Composants TaskMaster Cursor
Test simple des 3 composants manquants maintenant implÃ©mentÃ©s
"""

import asyncio
import sys
import os
from datetime import datetime

async def test_cli():
    """Test CLI TaskMaster Cursor"""
    print("ğŸ§ª Test CLI TaskMaster Cursor...")
    
    try:
        from cli_taskmaster_cursor import TaskMasterCLI
        
        cli = TaskMasterCLI()
        print("âœ… CLI initialisÃ©")
        
        # Test validation infrastructure
        is_valid = await cli.validate_infrastructure()
        print(f"âœ… Infrastructure {'validÃ©e' if is_valid else 'partiellement validÃ©e'}")
        
        # Test lancement tÃ¢che
        result = await cli.launch_single_task("Test CLI simple")
        print(f"âœ… TÃ¢che lancÃ©e: {result.task_id} - {result.status.value}")
        
        # Test liste tÃ¢ches
        tasks = await cli.list_tasks(3)
        print(f"âœ… {len(tasks)} tÃ¢ches trouvÃ©es")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur CLI: {str(e)}")
        return False

async def test_dashboard():
    """Test Dashboard TaskMaster Cursor"""
    print("\nğŸ§ª Test Dashboard TaskMaster Cursor...")
    
    try:
        from dashboard_taskmaster_cursor import TaskMasterDashboard
        
        dashboard = TaskMasterDashboard(refresh_interval=1)
        print("âœ… Dashboard initialisÃ©")
        
        # Test statut infrastructure
        status = dashboard._get_infrastructure_status()
        print(f"âœ… Statut infrastructure: {status['total_score']}/{status.get('max_score', 70)}")
        
        # Test affichage (capture stdout)
        import io
        import contextlib
        
        stdout_buffer = io.StringIO()
        with contextlib.redirect_stdout(stdout_buffer):
            dashboard.print_dashboard(status)
        
        output = stdout_buffer.getvalue()
        if len(output) > 0:
            print("âœ… Affichage dashboard fonctionnel")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur Dashboard: {str(e)}")
        return False

async def test_validator():
    """Test Validator Sessions Cursor"""
    print("\nğŸ§ª Test Validator Sessions Cursor...")
    
    try:
        from validator_sessions_cursor import SessionValidator
        
        validator = SessionValidator()
        print("âœ… Validator initialisÃ©")
        
        # Test validation PostgreSQL
        pg_sessions = await validator.validate_postgresql_sessions()
        print(f"âœ… {len(pg_sessions)} sessions PostgreSQL trouvÃ©es")
        
        # Test validation tÃ¢ches
        tasks = await validator.validate_taskmaster_tasks()
        print(f"âœ… {len(tasks)} tÃ¢ches TaskMaster trouvÃ©es")
        
        # Test validation complÃ¨te
        result = await validator.run_full_validation()
        print(f"âœ… Validation complÃ¨te: {result.total_sessions} sessions totales")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur Validator: {str(e)}")
        return False

async def test_integration():
    """Test intÃ©gration des 3 composants"""
    print("\nğŸ§ª Test IntÃ©gration CLI + Dashboard + Validator...")
    
    try:
        from cli_taskmaster_cursor import TaskMasterCLI
        from dashboard_taskmaster_cursor import TaskMasterDashboard
        from validator_sessions_cursor import SessionValidator
        
        # Initialisation simultanÃ©e
        cli = TaskMasterCLI()
        dashboard = TaskMasterDashboard()
        validator = SessionValidator()
        print("âœ… 3 composants initialisÃ©s simultanÃ©ment")
        
        # Test flux CLI â†’ Validator
        task_result = await cli.launch_single_task("Test intÃ©gration")
        await asyncio.sleep(0.5)  # Attendre sauvegarde
        
        validation_result = await validator.run_full_validation()
        print(f"âœ… Flux CLI â†’ Validator: tÃ¢che crÃ©Ã©e et sessions validÃ©es")
        
        # Test Dashboard avec donnÃ©es
        dashboard_status = dashboard._get_infrastructure_status()
        print(f"âœ… Dashboard mis Ã  jour: score {dashboard_status['total_score']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ Erreur IntÃ©gration: {str(e)}")
        return False

async def main():
    """Test principal"""
    print("ğŸš€ Test des Nouveaux Composants TaskMaster Cursor")
    print("="*60)
    
    start_time = datetime.now()
    
    # Tests individuels
    cli_ok = await test_cli()
    dashboard_ok = await test_dashboard() 
    validator_ok = await test_validator()
    integration_ok = await test_integration()
    
    end_time = datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    # RÃ©sumÃ©
    print("\n" + "="*60)
    print("ğŸ“Š RÃ‰SUMÃ‰ DES TESTS")
    print("="*60)
    
    results = [
        ("CLI TaskMaster Cursor", cli_ok),
        ("Dashboard TaskMaster Cursor", dashboard_ok),
        ("Validator Sessions Cursor", validator_ok),
        ("IntÃ©gration 3 Composants", integration_ok)
    ]
    
    passed = sum(1 for _, ok in results if ok)
    total = len(results)
    
    for component, ok in results:
        emoji = "âœ…" if ok else "âŒ"
        print(f"{emoji} {component}")
    
    print(f"\nğŸ¯ SCORE: {passed}/{total} ({(passed/total)*100:.1f}%)")
    print(f"â±ï¸ DURÃ‰E: {duration:.1f}s")
    
    if passed == total:
        print("ğŸ‰ TOUS LES TESTS RÃ‰USSIS - Composants opÃ©rationnels!")
        print("ğŸ’¡ Gap Analysis rÃ©solu: CLI, Dashboard et Validator implÃ©mentÃ©s")
    else:
        print("âš ï¸ Certains tests ont Ã©chouÃ© - VÃ©rifier les composants")
    
    print("="*60)

if __name__ == "__main__":
    asyncio.run(main()) 



