#!/usr/bin/env python3
"""
üöÄ PARALLEL TASK MANAGER - Phase 2 Optimisations Performance
==============================================================

Gestionnaire de t√¢ches parall√®les pour Chef d'√âquipe Maintenance
Pattern Producer/Consumer avec int√©gration circuit breakers et cache intelligent

Architecture:
- Pool d'agents avec concurrence contr√¥l√©e (3-5 max)
- Queue asynchrone avec priorit√©s
- Circuit breakers par agent
- Cache intelligent pour √©viter re-traitement
- Monitoring temps r√©el des performances

Mission: Remplacer traitement s√©quentiel par parall√©lisme optimis√©
Objectif: -40% temps d'ex√©cution, +15% taux de succ√®s

Author: Infrastructure d'Optimisation NextGeneration
Version: 1.0.0 - Phase 2 Launch
"""

import asyncio
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Callable, Union
from dataclasses import dataclass, field
from enum import Enum
import logging
import uuid
from concurrent.futures import ThreadPoolExecutor
import threading

# Imports infrastructure optimisation Phase 1
from .config_manager import ConfigManager, AgentConfig
from .metrics_collector import AdvancedMetricsCollector
from .circuit_breaker import CircuitBreakerManager
from .cache_manager import IntelligentCache


class TaskPriority(Enum):
    """Priorit√©s des t√¢ches"""
    LOW = 1
    NORMAL = 2
    HIGH = 3
    CRITICAL = 4


class TaskStatus(Enum):
    """√âtats des t√¢ches"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    TIMEOUT = "timeout"
    CANCELLED = "cancelled"


@dataclass
class AgentTask:
    """T√¢che pour un agent de maintenance"""
    task_id: str
    agent_path: str
    agent_name: str
    task_type: str
    params: Dict[str, Any]
    priority: TaskPriority = TaskPriority.NORMAL
    timeout: float = 300.0
    retry_count: int = 0
    max_retries: int = 3
    created_at: float = field(default_factory=time.time)
    started_at: Optional[float] = None
    completed_at: Optional[float] = None
    status: TaskStatus = TaskStatus.PENDING
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    worker_id: Optional[str] = None


@dataclass
class WorkerStats:
    """Statistiques d'un worker"""
    worker_id: str
    tasks_completed: int = 0
    tasks_failed: int = 0
    total_execution_time: float = 0.0
    last_task_time: Optional[float] = None
    is_busy: bool = False
    current_task_id: Optional[str] = None


class ParallelTaskManager:
    """
    Gestionnaire de t√¢ches parall√®les pour Chef d'√âquipe Maintenance
    
    Fonctionnalit√©s:
    - Pool de workers avec concurrence contr√¥l√©e
    - Queue de t√¢ches avec priorit√©s
    - Circuit breakers par agent
    - Cache intelligent
    - Monitoring performances temps r√©el
    - Fallback mode s√©quentiel
    """
    
    def __init__(
        self,
        max_workers: int = 5,
        queue_size: int = 100,
        config_path: Optional[str] = None,
        enable_cache: bool = True,
        enable_circuit_breaker: bool = True
    ):
        self.max_workers = max_workers
        self.queue_size = queue_size
        self.enable_cache = enable_cache
        self.enable_circuit_breaker = enable_circuit_breaker
        
        # Configuration
        self.config_manager = ConfigManager(config_path) if config_path else None
        self.config = self._load_config()
        
        # Infrastructure monitoring
        self.metrics = AdvancedMetricsCollector()
        self.circuit_breaker = CircuitBreakerManager() if enable_circuit_breaker else None
        self.cache = IntelligentCache() if enable_cache else None
        
        # Task management
        self.task_queue: asyncio.PriorityQueue = None
        self.tasks: Dict[str, AgentTask] = {}
        self.workers: Dict[str, WorkerStats] = {}
        self.worker_semaphore: asyncio.Semaphore = None
        
        # State management
        self.is_running = False
        self.shutdown_event: asyncio.Event = None
        self.worker_tasks: List[asyncio.Task] = []
        
        # Logging
        self.logger = logging.getLogger(self.__class__.__name__)
        self.logger.info(f"ParallelTaskManager initialis√© - Max workers: {max_workers}")
        
    def _load_config(self) -> Dict[str, Any]:
        """Charge la configuration depuis le gestionnaire"""
        if self.config_manager:
            try:
                config = self.config_manager.get_global_settings()
                return {
                    "max_workers": min(self.max_workers, config.performance.max_concurrent_agents),
                    "task_timeout": config.performance.task_timeout_seconds,
                    "retry_attempts": config.performance.retry_attempts,
                    "enable_fallback": config.performance.enable_fallback_sequential
                }
            except Exception as e:
                self.logger.warning(f"Erreur chargement config: {e}")
        
        return {
            "max_workers": self.max_workers,
            "task_timeout": 300.0,
            "retry_attempts": 3,
            "enable_fallback": True
        }
    
    async def startup(self):
        """D√©marrage du gestionnaire de t√¢ches parall√®les"""
        if self.is_running:
            return
        
        self.logger.info("üöÄ D√©marrage ParallelTaskManager")
        
        # Initialisation infrastructure
        if self.circuit_breaker:
            await self.circuit_breaker.startup()
        
        if self.cache:
            # IntelligentCache n'a pas de m√©thode startup
            pass
        
        # Initialisation queues et workers
        self.task_queue = asyncio.PriorityQueue(maxsize=self.queue_size)
        self.worker_semaphore = asyncio.Semaphore(self.config["max_workers"])
        self.shutdown_event = asyncio.Event()
        
        # D√©marrage workers
        for i in range(self.config["max_workers"]):
            worker_id = f"worker_{i+1}"
            self.workers[worker_id] = WorkerStats(worker_id=worker_id)
            
            worker_task = asyncio.create_task(
                self._worker_loop(worker_id),
                name=f"parallel_worker_{worker_id}"
            )
            self.worker_tasks.append(worker_task)
        
        self.is_running = True
        self.logger.info(f"‚úÖ ParallelTaskManager d√©marr√© - {len(self.workers)} workers actifs")
    
    async def shutdown(self):
        """Arr√™t propre du gestionnaire"""
        if not self.is_running:
            return
        
        self.logger.info("üõë Arr√™t ParallelTaskManager")
        
        # Signal d'arr√™t
        self.shutdown_event.set()
        
        # Attendre completion des t√¢ches en cours
        if self.worker_tasks:
            await asyncio.gather(*self.worker_tasks, return_exceptions=True)
        
        # Arr√™t infrastructure
        if self.circuit_breaker:
            await self.circuit_breaker.shutdown()
        
        if self.cache:
            # IntelligentCache n'a pas de m√©thode shutdown
            pass
        
        self.is_running = False
        self.logger.info("‚úÖ ParallelTaskManager arr√™t√©")
    
    async def submit_task(
        self,
        agent_path: str,
        task_type: str,
        params: Dict[str, Any],
        priority: TaskPriority = TaskPriority.NORMAL,
        timeout: Optional[float] = None
    ) -> str:
        """
        Soumet une t√¢che pour traitement parall√®le
        
        Args:
            agent_path: Chemin vers l'agent √† traiter
            task_type: Type de t√¢che (test_code, repair_code, etc.)
            params: Param√®tres de la t√¢che
            priority: Priorit√© de la t√¢che
            timeout: Timeout sp√©cifique (sinon config par d√©faut)
        
        Returns:
            task_id: Identifiant unique de la t√¢che
        """
        if not self.is_running:
            raise RuntimeError("ParallelTaskManager non d√©marr√©")
        
        # G√©n√©ration t√¢che
        task_id = str(uuid.uuid4())
        agent_name = Path(agent_path).name
        
        task = AgentTask(
            task_id=task_id,
            agent_path=agent_path,
            agent_name=agent_name,
            task_type=task_type,
            params=params,
            priority=priority,
            timeout=timeout or self.config["task_timeout"]
        )
        
        # V√©rification cache si activ√©
        if self.cache and task_type in ["test_code", "analyze_code"]:
            cache_key = self._generate_cache_key(task)
            cached_result = await self.cache.get(cache_key)
            
            if cached_result:
                self.logger.info(f"üìã Cache HIT pour {agent_name} - {task_type}")
                task.status = TaskStatus.COMPLETED
                task.result = cached_result
                task.completed_at = time.time()
                self.tasks[task_id] = task
                
                # M√©triques cache hit
                self.metrics.record_execution(
                    agent_name, 0.001, True, 1024
                )
                
                return task_id
        
        # Ajout √† la queue
        self.tasks[task_id] = task
        priority_value = priority.value
        
        try:
            await self.task_queue.put((priority_value, time.time(), task))
            self.logger.info(f"üìã T√¢che {task_id} ajout√©e - {agent_name} ({task_type})")
            return task_id
            
        except asyncio.QueueFull:
            self.logger.error(f"‚ùå Queue pleine - T√¢che {task_id} rejet√©e")
            task.status = TaskStatus.FAILED
            task.error = "Queue pleine"
            raise RuntimeError("Queue de t√¢ches pleine")
    
    async def submit_batch_tasks(
        self,
        agents_paths: List[str],
        task_type: str,
        params_template: Dict[str, Any],
        priority: TaskPriority = TaskPriority.NORMAL
    ) -> List[str]:
        """
        Soumet un lot de t√¢ches en parall√®le
        
        Args:
            agents_paths: Liste des chemins d'agents
            task_type: Type de t√¢che commun
            params_template: Template de param√®tres
            priority: Priorit√© commune
        
        Returns:
            List des task_ids g√©n√©r√©s
        """
        task_ids = []
        
        for agent_path in agents_paths:
            # Personnalisation params par agent
            params = params_template.copy()
            params["agent_path"] = agent_path
            params["agent_name"] = Path(agent_path).name
            
            task_id = await self.submit_task(
                agent_path=agent_path,
                task_type=task_type,
                params=params,
                priority=priority
            )
            task_ids.append(task_id)
        
        self.logger.info(f"üìã Batch soumis - {len(task_ids)} t√¢ches ({task_type})")
        return task_ids
    
    async def wait_for_task(self, task_id: str, timeout: Optional[float] = None) -> AgentTask:
        """
        Attend la completion d'une t√¢che sp√©cifique
        
        Args:
            task_id: Identifiant de la t√¢che
            timeout: Timeout d'attente (optionnel)
        
        Returns:
            AgentTask compl√©t√©e
        """
        if task_id not in self.tasks:
            raise ValueError(f"T√¢che {task_id} introuvable")
        
        task = self.tasks[task_id]
        start_time = time.time()
        
        while task.status in [TaskStatus.PENDING, TaskStatus.RUNNING]:
            if timeout and (time.time() - start_time) > timeout:
                self.logger.warning(f"‚è∞ Timeout attente t√¢che {task_id}")
                raise asyncio.TimeoutError(f"Timeout attente t√¢che {task_id}")
            
            await asyncio.sleep(0.1)
        
        return task
    
    async def wait_for_batch(
        self,
        task_ids: List[str],
        timeout: Optional[float] = None,
        return_when: str = "ALL_COMPLETED"
    ) -> Dict[str, AgentTask]:
        """
        Attend la completion d'un lot de t√¢ches
        
        Args:
            task_ids: Liste des identifiants de t√¢ches
            timeout: Timeout global (optionnel)
            return_when: "ALL_COMPLETED" ou "FIRST_COMPLETED"
        
        Returns:
            Dict des t√¢ches compl√©t√©es {task_id: AgentTask}
        """
        start_time = time.time()
        completed_tasks = {}
        
        while len(completed_tasks) < len(task_ids):
            if timeout and (time.time() - start_time) > timeout:
                self.logger.warning(f"‚è∞ Timeout batch - {len(completed_tasks)}/{len(task_ids)} compl√©t√©es")
                break
            
            for task_id in task_ids:
                if task_id in completed_tasks:
                    continue
                
                if task_id not in self.tasks:
                    continue
                
                task = self.tasks[task_id]
                if task.status not in [TaskStatus.PENDING, TaskStatus.RUNNING]:
                    completed_tasks[task_id] = task
                    
                    if return_when == "FIRST_COMPLETED":
                        return completed_tasks
            
            await asyncio.sleep(0.1)
        
        self.logger.info(f"üìã Batch termin√© - {len(completed_tasks)}/{len(task_ids)} compl√©t√©es")
        return completed_tasks
    
    async def _worker_loop(self, worker_id: str):
        """Boucle principale d'un worker"""
        worker_stats = self.workers[worker_id]
        self.logger.info(f"üîÑ Worker {worker_id} d√©marr√©")
        
        while not self.shutdown_event.is_set():
            try:
                # Acquisition s√©maphore
                async with self.worker_semaphore:
                    # R√©cup√©ration t√¢che
                    try:
                        priority, timestamp, task = await asyncio.wait_for(
                            self.task_queue.get(),
                            timeout=1.0
                        )
                    except asyncio.TimeoutError:
                        continue
                    
                    # Traitement t√¢che
                    await self._process_task(task, worker_id, worker_stats)
                    
            except Exception as e:
                self.logger.error(f"‚ùå Erreur worker {worker_id}: {e}")
                await asyncio.sleep(0.5)
        
        self.logger.info(f"üõë Worker {worker_id} arr√™t√©")
    
    async def _process_task(self, task: AgentTask, worker_id: str, worker_stats: WorkerStats):
        """Traite une t√¢che sp√©cifique"""
        task.status = TaskStatus.RUNNING
        task.started_at = time.time()
        task.worker_id = worker_id
        
        worker_stats.is_busy = True
        worker_stats.current_task_id = task.task_id
        
        self.logger.info(f"üîÑ Worker {worker_id} traite {task.agent_name} ({task.task_type})")
        
        try:
            # V√©rification circuit breaker
            if self.circuit_breaker:
                breaker = await self.circuit_breaker.get_circuit_breaker(task.agent_name)
                state = breaker.get_state()
                if state["state"] == "open":
                    raise RuntimeError(f"Circuit breaker ouvert pour {task.agent_name}")
            
            # Ex√©cution avec timeout
            result = await asyncio.wait_for(
                self._execute_task_logic(task),
                timeout=task.timeout
            )
            
            # Succ√®s
            task.status = TaskStatus.COMPLETED
            task.result = result
            task.completed_at = time.time()
            
            # Mise en cache si applicable
            if self.cache and task.task_type in ["test_code", "analyze_code"]:
                cache_key = self._generate_cache_key(task)
                await self.cache.set(cache_key, result, ttl=3600)
            
            # M√©triques succ√®s
            execution_time = task.completed_at - task.started_at
            self.metrics.record_execution(
                task.agent_name, execution_time, True, 1024*1024
            )
            
            # Circuit breaker succ√®s
            if self.circuit_breaker:
                breaker = await self.circuit_breaker.get_circuit_breaker(task.agent_name)
                breaker.record_success()
            
            worker_stats.tasks_completed += 1
            worker_stats.total_execution_time += execution_time
            
            self.logger.info(f"‚úÖ {task.agent_name} compl√©t√© par {worker_id} en {execution_time:.2f}s")
            
        except asyncio.TimeoutError:
            task.status = TaskStatus.TIMEOUT
            task.error = f"Timeout apr√®s {task.timeout}s"
            task.completed_at = time.time()
            
            worker_stats.tasks_failed += 1
            
            self.logger.warning(f"‚è∞ Timeout {task.agent_name} sur {worker_id}")
            
        except Exception as e:
            task.status = TaskStatus.FAILED
            task.error = str(e)
            task.completed_at = time.time()
            
            # Circuit breaker √©chec
            if self.circuit_breaker:
                breaker = await self.circuit_breaker.get_circuit_breaker(task.agent_name)
                breaker.record_failure()
            
            # M√©triques √©chec
            execution_time = task.completed_at - task.started_at
            self.metrics.record_execution(
                task.agent_name, execution_time, False, 2*1024*1024
            )
            
            worker_stats.tasks_failed += 1
            
            self.logger.error(f"‚ùå √âchec {task.agent_name} sur {worker_id}: {e}")
        
        finally:
            worker_stats.is_busy = False
            worker_stats.current_task_id = None
            worker_stats.last_task_time = time.time()
    
    async def _execute_task_logic(self, task: AgentTask) -> Dict[str, Any]:
        """
        Logique d'ex√©cution d'une t√¢che
        √Ä surcharger par les impl√©mentations sp√©cifiques
        """
        # Simulation pour tests
        await asyncio.sleep(0.1)
        
        return {
            "success": True,
            "agent_name": task.agent_name,
            "task_type": task.task_type,
            "execution_time": 0.1,
            "message": f"T√¢che {task.task_type} simul√©e pour {task.agent_name}"
        }
    
    def _generate_cache_key(self, task: AgentTask) -> str:
        """G√©n√®re une cl√© de cache pour une t√¢che"""
        agent_path = Path(task.agent_path)
        
        # Hash bas√© sur contenu + type t√¢che
        import hashlib
        content_hash = hashlib.md5(
            f"{agent_path.stat().st_mtime}_{task.task_type}_{task.agent_name}".encode()
        ).hexdigest()
        
        return f"parallel_task_{task.task_type}_{content_hash}"
    
    def get_stats(self) -> Dict[str, Any]:
        """Statistiques du gestionnaire de t√¢ches"""
        total_tasks = len(self.tasks)
        completed_tasks = sum(1 for t in self.tasks.values() if t.status == TaskStatus.COMPLETED)
        failed_tasks = sum(1 for t in self.tasks.values() if t.status == TaskStatus.FAILED)
        
        return {
            "manager_status": "running" if self.is_running else "stopped",
            "total_workers": len(self.workers),
            "busy_workers": sum(1 for w in self.workers.values() if w.is_busy),
            "queue_size": self.task_queue.qsize() if self.task_queue else 0,
            "total_tasks": total_tasks,
            "completed_tasks": completed_tasks,
            "failed_tasks": failed_tasks,
            "success_rate": (completed_tasks / total_tasks * 100) if total_tasks > 0 else 0,
            "worker_stats": {
                worker_id: {
                    "tasks_completed": stats.tasks_completed,
                    "tasks_failed": stats.tasks_failed,
                    "avg_execution_time": (
                        stats.total_execution_time / stats.tasks_completed
                        if stats.tasks_completed > 0 else 0
                    ),
                    "is_busy": stats.is_busy
                }
                for worker_id, stats in self.workers.items()
            }
        }
    
    async def get_performance_report(self) -> Dict[str, Any]:
        """Rapport de performance d√©taill√©"""
        stats = self.get_stats()
        
        # M√©triques avanc√©es
        if hasattr(self.metrics, 'get_dashboard_data'):
            performance_metrics = self.metrics.get_dashboard_data()
            stats["performance_metrics"] = performance_metrics
        
        # Circuit breaker stats
        if self.circuit_breaker:
            cb_stats = await self.circuit_breaker.get_stats()
            stats["circuit_breaker_stats"] = cb_stats
        
        # Cache stats
        if self.cache:
            cache_stats = self.cache.get_stats()
            stats["cache_stats"] = cache_stats
        
        return stats


# Factory function
def create_parallel_task_manager(
    max_workers: int = 5,
    config_path: Optional[str] = None,
    **kwargs
) -> ParallelTaskManager:
    """
    Factory pour cr√©er un ParallelTaskManager configur√©
    
    Args:
        max_workers: Nombre maximum de workers
        config_path: Chemin vers configuration
        **kwargs: Arguments suppl√©mentaires
    
    Returns:
        ParallelTaskManager configur√©
    """
    return ParallelTaskManager(
        max_workers=max_workers,
        config_path=config_path,
        **kwargs
    ) 