"""
Gestionnaire de Cache Intelligent Multi-Niveaux
NextGeneration Maintenance Team - Cache Management

Syst√®me de cache intelligent avec:
- Cache m√©moire (LRU) pour acc√®s ultra-rapide
- Cache Redis pour persistance distribu√©e
- Statistiques de performance d√©taill√©es
- Gestion automatique TTL et √©viction
"""

from functools import lru_cache
import hashlib
import pickle
import time
import logging
from typing import Dict, Any, Optional, Union, List
from dataclasses import dataclass
from collections import defaultdict

# Import conditionnel de Redis
try:
    import redis
    REDIS_AVAILABLE = True
except ImportError:
    REDIS_AVAILABLE = False
    redis = None

@dataclass
class CacheStats:
    """Statistiques de performance du cache"""
    hits: int = 0
    misses: int = 0
    sets: int = 0
    deletes: int = 0
    memory_hits: int = 0
    redis_hits: int = 0
    total_size: int = 0
    avg_access_time: float = 0.0
    
    @property
    def hit_rate(self) -> float:
        """Calcule le taux de hit"""
        total = self.hits + self.misses
        return (self.hits / total * 100) if total > 0 else 0
    
    @property
    def memory_hit_rate(self) -> float:
        """Taux de hit du cache m√©moire"""
        return (self.memory_hits / self.hits * 100) if self.hits > 0 else 0

class IntelligentCache:
    """Cache multi-niveaux : m√©moire -> Redis -> Fallback"""
    
    def __init__(self, 
                 redis_host: str = "localhost",
                 redis_port: int = 6379,
                 redis_db: int = 0,
                 redis_password: Optional[str] = None,
                 default_ttl: int = 3600,
                 max_memory_items: int = 1000,
                 enable_redis: bool = True):
        """
        Initialise le cache intelligent
        
        Args:
            redis_host: Host Redis
            redis_port: Port Redis
            redis_db: Base de donn√©es Redis
            redis_password: Mot de passe Redis
            default_ttl: TTL par d√©faut en secondes
            max_memory_items: Nombre max d'items en m√©moire
            enable_redis: Activer le cache Redis
        """
        self.default_ttl = default_ttl
        self.max_memory_items = max_memory_items
        self.enable_redis = enable_redis and REDIS_AVAILABLE
        
        # Cache m√©moire avec LRU
        self._memory_cache: Dict[str, Dict] = {}
        self._access_times: Dict[str, float] = {}
        
        # Statistiques
        self.stats = CacheStats()
        self._operation_times = []
        
        # Logger
        self.logger = logging.getLogger(f"{__name__}.IntelligentCache")
        
        # Client Redis
        self._redis_client = None
        if self.enable_redis:
            self._setup_redis(redis_host, redis_port, redis_db, redis_password)
    
    def _setup_redis(self, host: str, port: int, db: int, password: Optional[str]):
        """Configuration du client Redis"""
        try:
            self._redis_client = redis.Redis(
                host=host,
                port=port,
                db=db,
                password=password,
                socket_timeout=5,
                socket_connect_timeout=5,
                retry_on_timeout=True,
                decode_responses=False  # Pour g√©rer les donn√©es binaires
            )
            
            # Test de connexion
            self._redis_client.ping()
            self.logger.info(f"‚úÖ Cache Redis connect√©: {host}:{port}/{db}")
            
        except Exception as e:
            self.logger.warning(f"‚ö†Ô∏è Redis non disponible: {e} - Mode cache m√©moire uniquement")
            self._redis_client = None
            self.enable_redis = False
    
    @lru_cache(maxsize=10000)
    def _get_cache_key(self, key: str, namespace: str = "default") -> str:
        """G√©n√®re une cl√© de cache avec namespace"""
        return f"nextgen:cache:{namespace}:{hashlib.sha256(key.encode()).hexdigest()[:16]}"
    
    async def get(self, key: str, namespace: str = "default") -> Optional[Any]:
        """R√©cup√©ration avec cache multi-niveaux"""
        start_time = time.time()
        cache_key = self._get_cache_key(key, namespace)
        
        try:
            # Niveau 1: Cache m√©moire
            if cache_key in self._memory_cache:
                item = self._memory_cache[cache_key]
                
                # V√©rification TTL
                if item['expires_at'] > time.time():
                    self._access_times[cache_key] = time.time()
                    self.stats.hits += 1
                    self.stats.memory_hits += 1
                    
                    self.logger.debug(f"‚ö° Cache m√©moire hit: {namespace}:{key[:20]}...")
                    return item['data']
                else:
                    # Expiration - suppression
                    del self._memory_cache[cache_key]
                    if cache_key in self._access_times:
                        del self._access_times[cache_key]
            
            # Niveau 2: Cache Redis
            if self.enable_redis and self._redis_client:
                try:
                    redis_data = self._redis_client.get(cache_key)
                    if redis_data:
                        data = pickle.loads(redis_data)
                        
                        # Promotion vers cache m√©moire
                        self._set_memory_cache(cache_key, data, self.default_ttl)
                        
                        self.stats.hits += 1
                        self.stats.redis_hits += 1
                        
                        self.logger.debug(f"üì° Cache Redis hit: {namespace}:{key[:20]}...")
                        return data
                        
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Erreur Redis get: {e}")
            
            # Cache miss
            self.stats.misses += 1
            self.logger.debug(f"‚ùå Cache miss: {namespace}:{key[:20]}...")
            return None
            
        finally:
            # Enregistrement du temps d'acc√®s
            access_time = time.time() - start_time
            self._operation_times.append(access_time)
            if len(self._operation_times) > 1000:
                self._operation_times = self._operation_times[-1000:]
            
            # Mise √† jour moyenne
            if self._operation_times:
                self.stats.avg_access_time = sum(self._operation_times) / len(self._operation_times)
    
    async def set(self, key: str, value: Any, ttl: Optional[int] = None, namespace: str = "default"):
        """Stockage multi-niveaux"""
        start_time = time.time()
        cache_key = self._get_cache_key(key, namespace)
        ttl = ttl or self.default_ttl
        
        try:
            # Stockage m√©moire
            self._set_memory_cache(cache_key, value, ttl)
            
            # Stockage Redis
            if self.enable_redis and self._redis_client:
                try:
                    serialized_data = pickle.dumps(value)
                    self._redis_client.setex(cache_key, ttl, serialized_data)
                    self.logger.debug(f"üíæ Stock√© en Redis: {namespace}:{key[:20]}... (TTL: {ttl}s)")
                    
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Erreur Redis set: {e}")
            
            self.stats.sets += 1
            self.logger.debug(f"‚úÖ Cache set: {namespace}:{key[:20]}... (TTL: {ttl}s)")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur cache set: {e}")
    
    def _set_memory_cache(self, cache_key: str, data: Any, ttl: int):
        """Stockage en cache m√©moire avec gestion LRU"""
        # √âviction LRU si n√©cessaire
        if len(self._memory_cache) >= self.max_memory_items:
            self._evict_lru()
        
        expires_at = time.time() + ttl
        self._memory_cache[cache_key] = {
            'data': data,
            'expires_at': expires_at,
            'created_at': time.time()
        }
        self._access_times[cache_key] = time.time()
    
    def _evict_lru(self):
        """√âviction LRU des √©l√©ments les moins r√©cemment utilis√©s"""
        if not self._access_times:
            return
        
        # √âviction de 10% des √©l√©ments les plus anciens
        items_to_evict = max(1, len(self._access_times) // 10)
        
        # Tri par temps d'acc√®s
        sorted_items = sorted(self._access_times.items(), key=lambda x: x[1])
        
        for cache_key, _ in sorted_items[:items_to_evict]:
            if cache_key in self._memory_cache:
                del self._memory_cache[cache_key]
            if cache_key in self._access_times:
                del self._access_times[cache_key]
        
        self.logger.debug(f"üßπ √âviction LRU: {items_to_evict} √©l√©ments supprim√©s")
    
    async def delete(self, key: str, namespace: str = "default"):
        """Suppression multi-niveaux"""
        cache_key = self._get_cache_key(key, namespace)
        
        # Suppression m√©moire
        if cache_key in self._memory_cache:
            del self._memory_cache[cache_key]
        if cache_key in self._access_times:
            del self._access_times[cache_key]
        
        # Suppression Redis
        if self.enable_redis and self._redis_client:
            try:
                self._redis_client.delete(cache_key)
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Erreur Redis delete: {e}")
        
        self.stats.deletes += 1
        self.logger.debug(f"üóëÔ∏è Cache delete: {namespace}:{key[:20]}...")
    
    async def clear(self, namespace: Optional[str] = None):
        """Nettoyage du cache"""
        if namespace:
            # Nettoyage d'un namespace sp√©cifique
            pattern = f"nextgen:cache:{namespace}:"
            keys_to_delete = [k for k in self._memory_cache.keys() if k.startswith(pattern)]
            
            for key in keys_to_delete:
                if key in self._memory_cache:
                    del self._memory_cache[key]
                if key in self._access_times:
                    del self._access_times[key]
            
            # Redis
            if self.enable_redis and self._redis_client:
                try:
                    redis_pattern = f"nextgen:cache:{namespace}:*"
                    redis_keys = self._redis_client.keys(redis_pattern)
                    if redis_keys:
                        self._redis_client.delete(*redis_keys)
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Erreur Redis clear: {e}")
            
            self.logger.info(f"üßπ Cache namespace '{namespace}' nettoy√©")
        else:
            # Nettoyage complet
            self._memory_cache.clear()
            self._access_times.clear()
            
            if self.enable_redis and self._redis_client:
                try:
                    redis_keys = self._redis_client.keys("nextgen:cache:*")
                    if redis_keys:
                        self._redis_client.delete(*redis_keys)
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Erreur Redis clear all: {e}")
            
            self.logger.info("üßπ Cache complet nettoy√©")
    
    def get_stats(self) -> Dict[str, Any]:
        """Statistiques de performance du cache"""
        memory_size = len(self._memory_cache)
        
        # Calcul de la taille approximative en m√©moire
        estimated_memory_size = sum(
            len(pickle.dumps(item['data'])) 
            for item in list(self._memory_cache.values())[:100]  # √âchantillon
        ) * (memory_size / 100) if memory_size > 0 else 0
        
        return {
            "hit_rate": f"{self.stats.hit_rate:.1f}%",
            "memory_hit_rate": f"{self.stats.memory_hit_rate:.1f}%",
            "total_hits": self.stats.hits,
            "total_misses": self.stats.misses,
            "memory_hits": self.stats.memory_hits,
            "redis_hits": self.stats.redis_hits,
            "total_sets": self.stats.sets,
            "total_deletes": self.stats.deletes,
            "memory_items": memory_size,
            "estimated_memory_size_mb": estimated_memory_size / 1024 / 1024,
            "avg_access_time_ms": self.stats.avg_access_time * 1000,
            "redis_enabled": self.enable_redis,
            "redis_connected": self._redis_client is not None
        }
    
    def get_health_status(self) -> Dict[str, Any]:
        """√âtat de sant√© du cache"""
        stats = self.get_stats()
        
        # √âvaluation de la sant√©
        health_score = 100
        issues = []
        
        # V√©rification du hit rate
        if self.stats.hit_rate < 50:
            health_score -= 20
            issues.append("Taux de hit faible (<50%)")
        
        # V√©rification de la connexion Redis
        if self.enable_redis and not self._redis_client:
            health_score -= 30
            issues.append("Redis d√©connect√©")
        
        # V√©rification de la m√©moire
        if stats["memory_items"] > self.max_memory_items * 0.9:
            health_score -= 10
            issues.append("Cache m√©moire presque plein")
        
        # V√©rification du temps d'acc√®s
        if self.stats.avg_access_time > 0.1:  # 100ms
            health_score -= 15
            issues.append("Temps d'acc√®s √©lev√©")
        
        health_status = "üü¢" if health_score >= 80 else "üü°" if health_score >= 60 else "üî¥"
        
        return {
            "health_score": health_score,
            "health_status": health_status,
            "issues": issues,
            "recommendations": self._get_recommendations(stats, issues)
        }
    
    def _get_recommendations(self, stats: Dict, issues: List[str]) -> List[str]:
        """G√©n√®re des recommandations d'optimisation"""
        recommendations = []
        
        if "Taux de hit faible" in issues:
            recommendations.append("Augmenter le TTL ou optimiser les cl√©s de cache")
        
        if "Redis d√©connect√©" in issues:
            recommendations.append("V√©rifier la connexion Redis et red√©marrer si n√©cessaire")
        
        if "Cache m√©moire presque plein" in issues:
            recommendations.append("Augmenter max_memory_items ou nettoyer le cache")
        
        if "Temps d'acc√®s √©lev√©" in issues:
            recommendations.append("Optimiser la s√©rialisation ou r√©duire la taille des donn√©es")
        
        # Recommandations g√©n√©rales
        memory_hit_rate = float(stats["memory_hit_rate"].rstrip('%'))
        if memory_hit_rate < 80 and self.enable_redis:
            recommendations.append("Consid√©rer augmenter la taille du cache m√©moire")
        
        return recommendations
    
    async def warmup(self, data_loader: callable, keys: List[str], namespace: str = "default"):
        """Pr√©chauffage du cache avec des donn√©es"""
        self.logger.info(f"üî• D√©marrage warmup cache: {len(keys)} cl√©s")
        
        successful = 0
        failed = 0
        
        for key in keys:
            try:
                data = await data_loader(key)
                if data is not None:
                    await self.set(key, data, namespace=namespace)
                    successful += 1
                else:
                    failed += 1
            except Exception as e:
                self.logger.warning(f"‚ö†Ô∏è Erreur warmup {key}: {e}")
                failed += 1
        
        self.logger.info(f"‚úÖ Warmup termin√©: {successful} succ√®s, {failed} √©checs")
        return {"successful": successful, "failed": failed}

# Instance globale
global_cache = IntelligentCache()

def get_global_cache() -> IntelligentCache:
    """R√©cup√®re l'instance globale du cache"""
    return global_cache

# D√©corateur pour mise en cache automatique
def cached(ttl: int = 3600, namespace: str = "default", key_func: Optional[callable] = None):
    """D√©corateur pour mise en cache automatique des r√©sultats"""
    
    def decorator(func: callable):
        async def wrapper(*args, **kwargs):
            # G√©n√©ration de la cl√© de cache
            if key_func:
                cache_key = key_func(*args, **kwargs)
            else:
                # Cl√© bas√©e sur les arguments
                args_str = str(args) + str(sorted(kwargs.items()))
                cache_key = f"{func.__name__}:{hashlib.sha256(args_str.encode()).hexdigest()[:16]}"
            
            # Tentative de r√©cup√©ration du cache
            cached_result = await global_cache.get(cache_key, namespace)
            if cached_result is not None:
                return cached_result
            
            # Ex√©cution et mise en cache
            result = await func(*args, **kwargs)
            await global_cache.set(cache_key, result, ttl, namespace)
            
            return result
        
        return wrapper
    return decorator

# Exemple d'usage
if __name__ == "__main__":
    import asyncio
    
    async def test_cache():
        """Test du cache intelligent"""
        cache = IntelligentCache(enable_redis=False)  # Mode m√©moire pour test
        
        # Test basique
        await cache.set("test_key", {"data": "test_value"}, ttl=60)
        result = await cache.get("test_key")
        print(f"‚úÖ Test basique: {result}")
        
        # Test avec namespace
        await cache.set("user:123", {"name": "John", "age": 30}, namespace="users")
        user = await cache.get("user:123", namespace="users")
        print(f"‚úÖ Test namespace: {user}")
        
        # Simulation de charge
        for i in range(100):
            await cache.set(f"key_{i}", f"value_{i}")
            if i % 10 == 0:
                await cache.get(f"key_{i-5}")  # Quelques hits
        
        # Statistiques
        stats = cache.get_stats()
        print(f"\nüìä Statistiques:")
        print(f"   Hit rate: {stats['hit_rate']}")
        print(f"   Items en m√©moire: {stats['memory_items']}")
        print(f"   Temps d'acc√®s moyen: {stats['avg_access_time_ms']:.2f}ms")
        
        # √âtat de sant√©
        health = cache.get_health_status()
        print(f"\nüíö Sant√© du cache: {health['health_status']} (Score: {health['health_score']})")
        if health['issues']:
            print(f"   Issues: {health['issues']}")
        if health['recommendations']:
            print(f"   Recommandations: {health['recommendations']}")
    
    # Ex√©cution du test
    asyncio.run(test_cache()) 