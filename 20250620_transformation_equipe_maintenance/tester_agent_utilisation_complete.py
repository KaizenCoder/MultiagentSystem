#!/usr/bin/env python3
"""
üéØ TEST AGENT TRANSFORM√â EN UTILISATION COMPL√àTE
Utilise l'Agent 04 MEGA-TESTEUR enrichi avec les capacit√©s des agents experts

Workflow :
1. Agent 03 transforme l'agent
2. Agent 04 MEGA-TESTEUR teste EN UTILISATION R√âELLE
3. Rapport complet avec certification
"""

import asyncio
import sys
from pathlib import Path
from datetime import datetime
import sys
from pathlib import Path
from core import logging_manager

# Ajouter le chemin vers notre √©quipe
sys.path.append("agent_equipe_maintenance")

class TesteurUtilisationComplete:
    def __init__(self):
        self.setup_logging()
        
    def setup_logging(self):
        logs_dir = Path("logs")
        logs_dir.mkdir(exist_ok=True)
        
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(logs_dir / f"test_utilisation_complete_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"),
                logging.StreamHandler()
            ]
        )
        # LoggingManager NextGeneration - Agent
        import sys
from pathlib import Path
from core import logging_manager
        self.logger = LoggingManager().get_agent_logger(
            agent_name="TesteurUtilisationComplete",
            role="ai_processor",
            domain="testing",
            async_enabled=True
        )

    async def tester_agent_utilisation_directe(self, agent_path: str) -> dict:
        """
        üéØ TEST DIRECT EN UTILISATION R√âELLE
        Teste directement un agent transform√© avec l'Agent 04 MEGA-TESTEUR
        """
        self.logger.info(f"üéØ D√âBUT TEST UTILISATION DIRECTE : {agent_path}")
        
        try:
            # Importer l'Agent 04 MEGA-TESTEUR pour tests utilisation
            from agent_MAINTENANCE_04_mega_testeur_utilisation import Agent04MegaTesteurUtilisation
            
            self.logger.info("üöÄ Initialisation Agent 04 MEGA-TESTEUR...")
            mega_testeur = Agent04MegaTesteurUtilisation()
            
            # Tests utilisation r√©elle complets
            self.logger.info(f"üéØ Tests utilisation r√©elle : {agent_path}")
            test_results = await mega_testeur.tester_agent_transforme_utilisation_complete(agent_path)
            
            # Compilation rapport final
            rapport_final = {
                'status': 'SUCC√àS_TEST_UTILISATION',
                'agent_tested': agent_path,
                'tests_utilisation': test_results,
                'certification_finale': self._generer_certification_utilisation(test_results),
                'timestamp': datetime.now().isoformat()
            }
            
            # Sauvegarde rapport
            await self._sauvegarder_rapport_final(rapport_final)
            
            self.logger.info("‚úÖ TEST UTILISATION TERMIN√â AVEC SUCC√àS")
            return rapport_final
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur test utilisation : {e}")
            return {
                'status': 'ERREUR_TEST_UTILISATION',
                'error': str(e),
                'agent_tested': agent_path
            }

    def _generer_certification_utilisation(self, test_results: dict) -> dict:
        """G√©n√®re la certification bas√©e sur les tests utilisation"""
        
        # Scores utilisation
        global_scores = test_results.get('global_scores', {})
        utilisation_score = global_scores.get('utilisation', 0)
        overall_score = global_scores.get('overall', 0)
        
        # Certification utilisation (bas√©e sur Agent 04)
        utilisation_certification = test_results.get('certification', '‚ùå NON CERTIFI√â')
        
        # Tests utilisation r√©elle d√©taill√©s
        tests_util = test_results.get('tests_results', {}).get('utilisation_reelle', {})
        tests_passed = tests_util.get('tests_passed', 0)
        tests_executed = tests_util.get('tests_executed', 0)
        
        # Certification finale
        if utilisation_score >= 9.0 and tests_passed == tests_executed:
            certification_finale = "üèÜ AGENT PARFAITEMENT OP√âRATIONNEL - Utilisation EXCELLENTE"
        elif utilisation_score >= 7.0 and tests_passed >= tests_executed * 0.8:
            certification_finale = "‚úÖ AGENT OP√âRATIONNEL - Utilisation BONNE"
        elif utilisation_score >= 5.0:
            certification_finale = "‚ö†Ô∏è AGENT PARTIELLEMENT OP√âRATIONNEL - Am√©liorations requises"
        else:
            certification_finale = "‚ùå AGENT NON OP√âRATIONNEL - D√©faillances critiques"
        
        return {
            'utilisation_certification': utilisation_certification,
            'certification_finale': certification_finale,
            'scores': {
                'utilisation_score': utilisation_score,
                'overall_score': overall_score,
                'tests_passed': tests_passed,
                'tests_executed': tests_executed,
                'success_rate': (tests_passed / tests_executed * 100) if tests_executed > 0 else 0
            },
            'recommandations': test_results.get('recommendations', [])
        }

    async def _sauvegarder_rapport_final(self, rapport: dict):
        """Sauvegarde le rapport final de test"""
        try:
            reports_dir = Path("reports")
            reports_dir.mkdir(exist_ok=True)
            
            agent_name = Path(rapport['agent_tested']).stem
            report_file = reports_dir / f"test_utilisation_{agent_name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            import json
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(rapport, f, indent=2, ensure_ascii=False, default=str)
            
            self.logger.info(f"üìÑ Rapport final sauvegard√© : {report_file}")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur sauvegarde rapport final : {e}")

    def afficher_resultats(self, rapport: dict):
        """Affichage format√© des r√©sultats"""
        print("\n" + "="*80)
        print("üéØ R√âSULTATS TEST UTILISATION R√âELLE COMPL√àTE")
        print("="*80)
        
        print(f"\nüìÅ Agent test√© : {rapport.get('agent_tested', 'N/A')}")
        print(f"‚è±Ô∏è Timestamp : {rapport.get('timestamp', 'N/A')}")
        
        # R√©sultats tests utilisation
        if 'tests_utilisation' in rapport:
            tests = rapport['tests_utilisation']
            print(f"\nüéØ TESTS UTILISATION R√âELLE :")
            
            if 'global_scores' in tests:
                scores = tests['global_scores']
                print(f"   üìä Score Utilisation : {scores.get('utilisation', 0)}/10")
                print(f"   üìä Score Performance : {scores.get('performance', 0)}/10")
                print(f"   üìä Score S√©curit√© : {scores.get('security', 0)}/10")
                print(f"   üìä Score Global : {scores.get('overall', 0)}/10")
            
            if 'tests_results' in tests:
                results = tests['tests_results']
                
                # Tests utilisation r√©elle
                if 'utilisation_reelle' in results:
                    util = results['utilisation_reelle']
                    print(f"\n   üéØ UTILISATION R√âELLE :")
                    print(f"      Tests pass√©s : {util.get('tests_passed', 0)}/{util.get('tests_executed', 0)}")
                    
                    if 'details' in util:
                        details = util['details']
                        print(f"      Import : {'‚úÖ' if details.get('import', {}).get('status') == 'SUCCESS' else '‚ùå'}")
                        print(f"      Instanciation : {'‚úÖ' if details.get('instantiation', {}).get('status') == 'SUCCESS' else '‚ùå'}")
                        print(f"      M√©thodes Pattern Factory : {'‚úÖ' if details.get('pattern_factory_methods', {}).get('status') == 'SUCCESS' else '‚ùå'}")
                        print(f"      Capacit√©s : {'‚úÖ' if details.get('capabilities', {}).get('status') == 'SUCCESS' else '‚ùå'}")
                
                # Tests performance
                if 'performance_utilisation' in results:
                    perf = results['performance_utilisation']
                    print(f"\n   ‚ö° PERFORMANCE :")
                    print(f"      Import : {perf.get('import_time_ms', 0):.1f}ms")
                    print(f"      Instanciation : {perf.get('instantiation_time_ms', 0):.1f}ms")
                    print(f"      M√©moire : {perf.get('memory_usage_mb', 0):.1f}MB")
                    print(f"      Grade : {perf.get('performance_grade', 'N/A')}")
                
                # Tests thread-safety
                if 'thread_safety_utilisation' in results:
                    thread = results['thread_safety_utilisation']
                    print(f"\n   üîí THREAD-SAFETY :")
                    print(f"      Cr√©ations parall√®les : {thread.get('parallel_creations', 0)}")
                    print(f"      Taux succ√®s : {thread.get('success_rate', 0):.1%}")
                    print(f"      Thread-safe : {'‚úÖ' if thread.get('thread_safe', False) else '‚ùå'}")
                
                # Audit s√©curit√©
                if 'security_audit' in results:
                    sec = results['security_audit']
                    print(f"\n   üîê S√âCURIT√â :")
                    print(f"      Vuln√©rabilit√©s : {sec.get('findings_count', 0)}")
                    print(f"      Critiques : {sec.get('critical_count', 0)}")
                    print(f"      Score : {sec.get('security_score', 0)}/10")
        
        # Certification finale
        if 'certification_finale' in rapport:
            cert = rapport['certification_finale']
            print(f"\nüèÜ CERTIFICATION FINALE :")
            print(f"   {cert.get('certification_finale', 'N/A')}")
            
            if 'scores' in cert:
                scores = cert['scores']
                print(f"\n   üìà SCORES D√âTAILL√âS :")
                print(f"      Taux r√©ussite : {scores.get('success_rate', 0):.1f}%")
                print(f"      Score utilisation : {scores.get('utilisation_score', 0)}/10")
                print(f"      Score global : {scores.get('overall_score', 0)}/10")
            
            if 'recommandations' in cert and cert['recommandations']:
                print(f"\nüí° RECOMMANDATIONS :")
                for rec in cert['recommandations']:
                    print(f"   ‚Ä¢ {rec}")
        
        print("\n" + "="*80)

async def main():
    """Point d'entr√©e principal"""
    print("üéØ Testeur Utilisation Compl√®te - Tests R√©els d'Agent Transform√©")
    
    # Agent √† tester
    agent_path = "../agent_factory_implementation/agents/agent_11_auditeur_qualite.py"
    
    if len(sys.argv) > 1:
        agent_path = sys.argv[1]
    
    if not Path(agent_path).exists():
        print(f"‚ùå Agent non trouv√© : {agent_path}")
        return
    
    print(f"üéØ Test utilisation r√©elle de l'agent : {agent_path}")
    
    # Initialiser testeur
    testeur = TesteurUtilisationComplete()
    
    # Ex√©cuter test utilisation
    rapport = await testeur.tester_agent_utilisation_directe(agent_path)
    
    # Afficher r√©sultats
    testeur.afficher_resultats(rapport)
    
    # Status final
    if rapport.get('status') == 'SUCC√àS_TEST_UTILISATION':
        cert = rapport.get('certification_finale', {})
        scores = cert.get('scores', {})
        success_rate = scores.get('success_rate', 0)
        
        if success_rate >= 100:
            print("üèÜ Agent PARFAITEMENT op√©rationnel en utilisation r√©elle !")
        elif success_rate >= 80:
            print("‚úÖ Agent op√©rationnel avec quelques am√©liorations possibles")
        elif success_rate >= 60:
            print("‚ö†Ô∏è Agent partiellement op√©rationnel - corrections requises")
        else:
            print("‚ùå Agent non-op√©rationnel - d√©faillances critiques")
    else:
        print(f"‚ùå Test utilisation √©chou√© : {rapport.get('status', 'Erreur inconnue')}")

if __name__ == "__main__":
    asyncio.run(main()) 



