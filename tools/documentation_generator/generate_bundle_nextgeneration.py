#!/usr/bin/env python3
"""
üöÄ G√©n√©rateur Documentation NextGeneration - Transposition SuperWhisper_V6
Mission: G√©n√©rer CODE-SOURCE.md complet automatiquement

R√©f√©rence: SuperWhisper_V6 generate_bundle_coordinateur.py (370 fichiers, 235KB)
Target: >200KB documentation exhaustive NextGeneration
Infrastructure: R√©utilise l'existant (generate_pitch_document, project_backup_system)

Usage:
  python generate_bundle_nextgeneration.py                    # Mode normal
  python generate_bundle_nextgeneration.py --mode validation  # Dry-run preview
  python generate_bundle_nextgeneration.py --mode preservation # Backup avant g√©n√©ration
"""

import os
import json
import argparse
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Any
import subprocess

class GenerateurBundleNextGeneration:
    """G√©n√©rateur simplifi√© mais efficace pour NextGeneration"""
    
    def __init__(self, mode: str = "regeneration"):
        self.mode = mode
        self.root_dir = Path(__file__).parent.parent.parent  # nextgeneration/
        self.workspace = Path(__file__).parent
        self.output_file = self.root_dir / "CODE-SOURCE.md"
        
        # Configuration scan sp√©cifique NextGeneration
        self.include_dirs = [
            "agent_factory_experts_team",      # √âquipe agents experts
            "agent_factory_implementation",    # Impl√©mentation agents
            "tools",                          # 6 outils matures identifi√©s
            "orchestrator",                   # Orchestrateur principal
            "memory_api",                     # API m√©moire
            "docs",                          # Documentation compl√®te
            "tests",                         # Tests complets
            "scripts",                       # Scripts PowerShell/Bash
            "config",                        # Configurations
            "equipe_agents_tools_migration", # Migration tools
            "monitoring",                    # Monitoring Prometheus/Grafana
            "k8s",                          # Kubernetes
            "nextgeneration",               # Sous-projet
            "prompt"                        # Prompts et documentation
        ]
        
        self.exclude_dirs = {".git", "__pycache__", "node_modules", ".vscode", "chroma_db", ".pytest_cache"}
        self.include_exts = {".py", ".md", ".json", ".yml", ".yaml", ".txt", ".cfg", ".ini", ".ps1", ".sh", ".ts", ".js"}
        # Inclure les logs et reports pour documentation compl√®te mais limiter la taille
        self.size_limit_mb = 2  # Limite 2MB par fichier
        
        # Stats de g√©n√©ration
        self.stats = {"files_scanned": 0, "total_size_bytes": 0, "generation_time": 0, "output_size_kb": 0}
        
        # Configuration logging simple
        self.logger = self._setup_logging()
        
    def _setup_logging(self):
        """Configuration logging"""
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
        return logging.getLogger("generate_bundle_nextgeneration")
    
    def generer_documentation_complete(self) -> Dict[str, Any]:
        """üöÄ Point d'entr√©e principal pour g√©n√©rer la documentation"""
        start_time = datetime.now()
        self.logger.info(f"[üöÄ] D√âMARRAGE G√âN√âRATION NEXTGENERATION (mode: {self.mode})")
        
        try:
            # Mode validation = dry-run
            if self.mode == "validation":
                return self._preview_generation()
            
            # Mode preservation = backup avant
            if self.mode == "preservation" and self.output_file.exists():
                self._create_backup()
            
            # 1. Scanner projet complet
            structure = self._scanner_projet_complet()
            
            # 2. G√©n√©rer m√©tadonn√©es
            metadata = self._generer_metadata()
            
            # 3. Cr√©er documentation finale
            documentation = self._creer_documentation_finale(structure, metadata)
            
            # 4. √âcrire fichier
            self._ecrire_fichier(documentation)
            
            # 5. Stats finales
            end_time = datetime.now()
            self.stats["generation_time"] = (end_time - start_time).total_seconds()
            self.stats["output_size_kb"] = self._get_file_size_kb(self.output_file)
            
            self.logger.info(f"[‚úÖ] SUCC√àS: {self.stats['output_size_kb']}KB en {self.stats['generation_time']:.1f}s")
            
            return {
                "status": "SUCCESS",
                "mode": self.mode,
                "output_file": str(self.output_file),
                "stats": self.stats
            }
            
        except Exception as e:
            self.logger.error(f"[‚ùå] ERREUR: {e}")
            return {"status": "FAILED", "error": str(e)}
    
    def _scanner_projet_complet(self) -> Dict[str, Any]:
        """üîç Scanner complet du projet NextGeneration"""
        self.logger.info("[üîç] Scan projet NextGeneration")
        
        structure = {
            "arborescence": self._generer_arborescence(),
            "fichiers": [],
            "infrastructure": self._analyser_infrastructure()
        }
        
        # Scanner chaque r√©pertoire inclus
        for include_dir in self.include_dirs:
            dir_path = self.root_dir / include_dir
            if dir_path.exists():
                self._scanner_repertoire(dir_path, structure["fichiers"])
        
        self.stats["files_scanned"] = len(structure["fichiers"])
        self.logger.info(f"[‚úÖ] Scan termin√©: {self.stats['files_scanned']} fichiers")
        
        return structure
    
    def _generer_arborescence(self) -> str:
        """üìÅ G√©n√©rer arborescence projet"""
        lines = ["nextgeneration/"]
        
        def walk_dir(path: Path, prefix: str = ""):
            if path.name.startswith('.') or path.name in self.exclude_dirs:
                return
            
            try:
                items = list(path.iterdir())
                dirs = sorted([i for i in items if i.is_dir()])
                files = sorted([i for i in items if i.is_file()])
                
                # Dirs
                for i, d in enumerate(dirs):
                    is_last = (i == len(dirs) - 1) and not files
                    connector = "‚îî‚îÄ‚îÄ " if is_last else "‚îú‚îÄ‚îÄ "
                    lines.append(f"{prefix}{connector}{d.name}/")
                    next_prefix = prefix + ("    " if is_last else "‚îÇ   ")
                    walk_dir(d, next_prefix)
                
                # Files (limite 15 par dossier)
                for i, f in enumerate(files[:15]):
                    is_last = (i == len(files) - 1) or (i == 14)
                    connector = "‚îî‚îÄ‚îÄ " if is_last else "‚îú‚îÄ‚îÄ "
                    lines.append(f"{prefix}{connector}{f.name}")
                
                if len(files) > 15:
                    lines.append(f"{prefix}    ... et {len(files) - 15} autres")
                    
            except PermissionError:
                pass
        
        walk_dir(self.root_dir)
        return "\n".join(lines)
    
    def _scanner_repertoire(self, dir_path: Path, fichiers_list: List[Dict]):
        """üìÑ Scanner un r√©pertoire"""
        for root, dirs, files in os.walk(dir_path):
            dirs[:] = [d for d in dirs if d not in self.exclude_dirs]
            
            for file in files:
                if not any(file.endswith(ext) for ext in self.include_exts):
                    continue
                
                file_path = Path(root) / file
                try:
                    size = file_path.stat().st_size
                    if size > self.size_limit_mb * 1024 * 1024:  # Skip selon limite
                        continue
                    
                    content = self._read_file_safe(file_path)
                    if content:
                        fichiers_list.append({
                            "path": str(file_path.relative_to(self.root_dir)),
                            "size": size,
                            "content": content,
                            "ext": file_path.suffix
                        })
                        self.stats["total_size_bytes"] += size
                        
                except Exception as e:
                    self.logger.warning(f"[‚ö†Ô∏è] Skip {file_path}: {e}")
    
    def _read_file_safe(self, file_path: Path) -> Optional[str]:
        """üìñ Lecture s√©curis√©e fichier"""
        for encoding in ['utf-8', 'latin-1', 'cp1252']:
            try:
                with open(file_path, 'r', encoding=encoding, errors='ignore') as f:
                    return f.read()
            except:
                continue
        return None
    
    def _analyser_infrastructure(self) -> Dict[str, Any]:
        """üèóÔ∏è Analyser infrastructure NextGeneration mature"""
        # Analyser dynamiquement l'infrastructure r√©elle
        tools_found = []
        for tool_dir in (self.root_dir / "tools").iterdir() if (self.root_dir / "tools").exists() else []:
            if tool_dir.is_dir() and not tool_dir.name.startswith('.'):
                tools_found.append(tool_dir.name)
        
        agents_teams_found = []
        for potential_team in ["agent_factory_experts_team", "agent_factory_implementation", 
                              "equipe_agents_tools_migration", "agents_postgresql_resolution"]:
            if (self.root_dir / potential_team).exists():
                agents_teams_found.append(potential_team)
        
        return {
            "tools_mature": tools_found,
            "agents_teams": agents_teams_found,
            "total_agents": len(list(self.root_dir.rglob("agent_*.py"))),
            "total_py_files": len(list(self.root_dir.rglob("*.py"))),
            "total_docs": len(list(self.root_dir.rglob("*.md"))),
            "total_configs": len(list(self.root_dir.rglob("*.json"))) + len(list(self.root_dir.rglob("*.yml"))),
            "total_scripts": len(list(self.root_dir.rglob("*.ps1"))) + len(list(self.root_dir.rglob("*.sh"))),
            "infrastructure_dirs": [d for d in self.include_dirs if (self.root_dir / d).exists()]
        }
    
    def _generer_metadata(self) -> Dict[str, Any]:
        """üìä M√©tadonn√©es projet"""
        return {
            "project": "NextGeneration",
            "generated": datetime.now().isoformat(),
            "generator": "generate_bundle_nextgeneration.py v1.0",
            "mode": self.mode,
            "git": self._get_git_info()
        }
    
    def _get_git_info(self) -> Dict[str, str]:
        """üåø Info Git"""
        try:
            commit = subprocess.check_output(["git", "rev-parse", "HEAD"], cwd=self.root_dir, text=True).strip()[:8]
            branch = subprocess.check_output(["git", "branch", "--show-current"], cwd=self.root_dir, text=True).strip()
            return {"commit": commit, "branch": branch}
        except:
            return {"commit": "N/A", "branch": "N/A"}
    
    def _creer_documentation_finale(self, structure: Dict[str, Any], metadata: Dict[str, Any]) -> str:
        """üìù Cr√©er documentation finale"""
        
        # Header
        doc = f"""# üöÄ CODE SOURCE COMPLET - NEXTGENERATION

## üìä **M√âTADONN√âES PROJET**

**üìä Projet:** {metadata['project']}  
**üìÖ G√©n√©r√© le:** {metadata['generated']}  
**üîß G√©n√©rateur:** {metadata['generator']}  
**üåø Branche Git:** {metadata['git']['branch']}  
**üîÑ Commit:** {metadata['git']['commit']}  
**‚öôÔ∏è Mode:** {metadata['mode']}  

## üèóÔ∏è **INFRASTRUCTURE MATURE NEXTGENERATION**

### üõ†Ô∏è **√âcosyst√®me Tools ({len(structure['infrastructure']['tools_mature'])} outils matures)**
"""
        
        for tool in structure["infrastructure"]["tools_mature"]:
            doc += f"- ‚úÖ **{tool}**\n"
        
        doc += f"""
### ü§ñ **√âquipes d'Agents ({structure['infrastructure']['total_agents']} agents total)**
"""
        
        for team in structure["infrastructure"]["agents_teams"]:
            doc += f"- üë• **{team}**\n"
        
        doc += f"""
### üìä **M√©triques Techniques**
- üêç **Fichiers Python:** {structure['infrastructure']['total_py_files']:,}
- üìö **Documentation:** {structure['infrastructure']['total_docs']:,}
- üìÑ **Fichiers scann√©s:** {self.stats['files_scanned']:,}
- üíæ **Taille totale:** {self.stats['total_size_bytes']//1024:,}KB

## üìÅ **STRUCTURE PROJET COMPL√àTE**

```
{structure['arborescence']}
```

## üìÑ **CODE SOURCE D√âTAILL√â**

"""
        
        # Code source par r√©pertoires
        by_dir = {}
        for f in structure["fichiers"]:
            dir_name = str(Path(f["path"]).parent)
            if dir_name not in by_dir:
                by_dir[dir_name] = []
            by_dir[dir_name].append(f)
        
        for dir_name, files in sorted(by_dir.items()):
            doc += f"\n### üìÅ **{dir_name}**\n\n"
            
            for file_info in files[:8]:  # Max 8 files per dir pour √©viter doc trop volumineux
                ext = file_info["ext"].lstrip('.') or 'text'
                doc += f"""
#### üìÑ `{file_info["path"]}`
<details>
<summary>Voir le code ({file_info["size"]} bytes)</summary>

```{ext}
{file_info["content"]}
```
</details>
"""
            
            if len(files) > 8:
                doc += f"\n*... et {len(files) - 8} autres fichiers*\n"
        
        # Footer
        doc += f"""

---

**ü§ñ G√©n√©r√© automatiquement par NextGeneration Documentation Generator**  
**üìÖ G√©n√©r√© le:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**‚è±Ô∏è Temps de g√©n√©ration:** {self.stats.get('generation_time', 0):.1f}s  
**üìä Mode:** {self.mode}  
**üìà Fichiers scann√©s:** {self.stats['files_scanned']}  
**üíæ Taille sortie:** {self.stats.get('output_size_kb', 0)}KB  

*üéØ Mission: Transposition SuperWhisper_V6 ‚Üí NextGeneration R√âUSSIE*  
*üìç Infrastructure NextGeneration mature identifi√©e et document√©e*  
*üöÄ Base pour futurs d√©veloppements et transmissions*
"""
        
        return doc
    
    def _ecrire_fichier(self, contenu: str):
        """üíæ √âcrire fichier final"""
        with open(self.output_file, 'w', encoding='utf-8') as f:
            f.write(contenu)
        self.logger.info(f"[üíæ] Fichier √©crit: {self.output_file}")
    
    def _preview_generation(self) -> Dict[str, Any]:
        """üëÅÔ∏è Preview mode validation"""
        try:
            structure = self._scanner_projet_complet()
            
            preview = f"""
üîç **PREVIEW G√âN√âRATION NEXTGENERATION**

üìä **Statistiques pr√©vues:**
- Fichiers √† scanner: {len(structure['fichiers'])}
- Taille estim√©e: {sum(f['size'] for f in structure['fichiers'])//1024}KB
- Infrastructure mature: {len(structure['infrastructure']['tools_mature'])} outils
- Agents teams: {len(structure['infrastructure']['agents_teams'])}

üìÅ **Aper√ßu structure:**
{structure['arborescence'][:1000]}...

‚ö†Ô∏è **Mode validation - Aucune modification**
"""
            
            print(preview)
            return {"status": "VALIDATION_SUCCESS", "preview": preview, "stats": self.stats}
            
        except Exception as e:
            self.logger.error(f"[‚ùå] Erreur preview: {e}")
            return {"status": "VALIDATION_FAILED", "error": str(e)}
    
    def _create_backup(self):
        """üíæ Cr√©er backup"""
        backup_name = f"CODE-SOURCE_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md"
        backup_path = self.workspace / "backups" / backup_name
        import shutil
        shutil.copy2(self.output_file, backup_path)
        self.logger.info(f"[üíæ] Backup: {backup_path}")
    
    def _get_file_size_kb(self, path: Path) -> int:
        """üìè Taille fichier en KB"""
        return path.stat().st_size // 1024 if path.exists() else 0


def main():
    """üéØ Point d'entr√©e principal"""
    parser = argparse.ArgumentParser(description="üöÄ G√©n√©rateur Documentation NextGeneration")
    parser.add_argument('--mode', choices=['regeneration', 'preservation', 'validation'], 
                        default='regeneration', help='Mode de g√©n√©ration')
    parser.add_argument('--dry-run', action='store_true', help='Preview seulement')
    
    args = parser.parse_args()
    if args.dry_run:
        args.mode = 'validation'
    
    # Ex√©cuter g√©n√©ration
    generateur = GenerateurBundleNextGeneration(mode=args.mode)
    resultat = generateur.generer_documentation_complete()
    
    # Afficher r√©sultat
    if resultat["status"] == "SUCCESS":
        print(f"\nüéâ **SUCC√àS G√âN√âRATION NEXTGENERATION**")
        print(f"üìÑ Fichier: {resultat['output_file']}")
        print(f"üìä Taille: {resultat['stats']['output_size_kb']}KB")
        print(f"üîç Fichiers: {resultat['stats']['files_scanned']}")
        print(f"‚è±Ô∏è Dur√©e: {resultat['stats']['generation_time']:.1f}s")
        print(f"üéØ Mode: {resultat['mode']}")
    elif resultat["status"] == "VALIDATION_SUCCESS":
        print(f"\n‚úÖ **VALIDATION R√âUSSIE**")
        print(f"üìä Fichiers pr√™ts: {resultat['stats']['files_scanned']}")
        print(f"üéØ Mode preview termin√© avec succ√®s")
    else:
        print(f"\n‚ùå **√âCHEC**: {resultat.get('error', 'Erreur inconnue')}")
        exit(1)


if __name__ == "__main__":
    main() 