# ğŸ“‹ Annexe Technique : Code Complet - Centralisation Logging TemplateManager

## ğŸ¯ **Contexte NextGeneration - Ã‰cosystÃ¨me Outils**

### ğŸ”§ **IntÃ©gration avec /tools/generate_pitch_document**

L'outil `generate_pitch_document` illustre l'architecture NextGeneration avec :

- **ğŸ“ Configuration modulaire** : `agent_factory_config.json` pour intÃ©gration avec Agent Factory
- **ğŸ”§ Logging intÃ©grÃ©** : SystÃ¨me de logs NextGeneration compatible
- **âš™ï¸ Monitoring natif** : MÃ©triques et observabilitÃ© intÃ©grÃ©es
- **ğŸ¯ Patterns standardisÃ©s** : Template de configuration rÃ©utilisable

```json
// Exemple de configuration standardisÃ©e d'outil NextGeneration
{
  "nextgeneration_integration": {
    "use_ng_logging": true,          // â† DOIT utiliser le logging centralisÃ©
    "use_ng_monitoring": true        // â† Monitoring centralisÃ©
  }
}
```

Cette intÃ©gration dÃ©montre la nÃ©cessitÃ© d'un systÃ¨me de logging centralisÃ© pour tous les composants NextGeneration.

## ğŸ¯ **Code TemplateManager AVANT Modification**

### ğŸ“„ **optimized_template_manager.py (ACTUEL)**

```python
"""
Code Expert NextGeneration - optimized_template_manager
Adapt depuis scripts experts Claude Phase 2 (Production-Ready)
"""

import asyncio
import json
import logging
import time
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor
from contextlib import asynccontextmanager
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from functools import lru_cache
from pathlib import Path
from threading import RLock
from typing import Any, Dict, List, Optional, Set, Tuple, Union

import aiofiles
from watchdog.events import FileSystemEventHandler
from watchdog.observers import Observer

from .agent_templates import AgentTemplate, TemplateValidationError
from ..agents.base_agent import BaseAgent
from ..config.agent_config import AgentFactoryConfig

logger = logging.getLogger(__name__)

@dataclass
class TemplateMetrics:
    """MÃ©triques de performance pour les templates."""
    loads_count: int = 0
    cache_hits: int = 0
    cache_misses: int = 0
    reload_count: int = 0
    creation_times: List[float] = field(default_factory=list)
    errors: Dict[str, int] = field(default_factory=lambda: defaultdict(int))
    last_accessed: Dict[str, datetime] = field(default_factory=dict)

class TemplateFileWatcher(FileSystemEventHandler):
    """Surveille les modifications des fichiers templates."""
    
    def __init__(self, manager: 'TemplateManager'):
        self.manager = manager
        
    def on_modified(self, event):
        """Callback lors de la modification d'un fichier."""
        if event.is_directory or not event.src_path.endswith('.json'):
            return
            
        template_name = Path(event.src_path).stem
        logger.info("Template modifiÃ© dÃ©tectÃ© : %s", template_name)
        
        # Invalider le cache pour ce template
        asyncio.create_task(self.manager.reload_template(template_name))

class TemplateManager:
    """Gestionnaire optimisÃ© de templates avec cache intelligent et mÃ©triques."""
    
    def __init__(
        self,
        config: Optional[AgentFactoryConfig] = None,
        enable_hot_reload: bool = True,
        preload_templates: Optional[List[str]] = None
    ):
        self.config = config or AgentFactoryConfig()
        self._lock = RLock()
        self._cache: Dict[str, AgentTemplate] = {}
        self._timestamps: Dict[str, float] = {}
        self._class_cache: Dict[str, type[BaseAgent]] = {}
        self._metrics = TemplateMetrics()
        self._executor = ThreadPoolExecutor(max_workers=4)
        
        # Configuration du hot-reload
        self._observer: Optional[Observer] = None
        if enable_hot_reload:
            self._setup_file_watcher()
        
        # PrÃ©chargement des templates critiques
        if preload_templates:
            asyncio.create_task(self._preload_templates(preload_templates))

    def create_agent(
        self,
        template_name: str,
        *,
        suffix: str = "",
        config: Optional[Dict[str, Any]] = None
    ) -> BaseAgent:
        """CrÃ©e une instance d'agent Ã  partir d'un template."""
        start_time = time.time()
        
        try:
            # Utiliser la classe en cache si disponible
            with self._lock:
                if template_name in self._class_cache:
                    agent_class = self._class_cache[template_name]
                else:
                    tmpl = self.get_template(template_name)
                    agent_class = tmpl.to_class()
                    self._class_cache[template_name] = agent_class
            
            # CrÃ©er l'instance (hors du lock)
            agent = agent_class.create(name_suffix=suffix, config=config)
            
            # MÃ©triques
            creation_time = time.time() - start_time
            with self._lock:
                self._metrics.creation_times.append(creation_time)
            
            logger.debug(
                "Agent crÃ©Ã© : %s (template=%s, temps=%.3fs)",
                agent.metadata.name,
                template_name,
                creation_time
            )
            
            return agent
            
        except Exception as e:
            self._metrics.errors[type(e).__name__] += 1
            logger.error("Erreur crÃ©ation agent '%s': %s", template_name, e)
            raise
```

---

## ğŸ”§ **Code Agent AVANT Modification**

### ğŸ“„ **agent_0_chef_equipe_coordinateur.py (ACTUEL)**

```python
#!/usr/bin/env python3
"""
ğŸ–ï¸ Agent 0 - Chef d'Ã‰quipe Coordinateur
ModÃ¨le: Claude Sonnet 4 
Mission: Orchestration centrale de l'Ã©quipe de maintenance
"""

import asyncio
import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
import sys

# Configuration des logs - PROBLÃˆME: Basique et non centralisÃ©
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

class Agent0ChefEquipeCoordinateur:
    """Agent 0 - Chef d'Ã‰quipe Coordinateur avec Claude Sonnet 4"""
    
    def __init__(self, agent_id: str = None, agent_type: str = "chef_equipe_coordinateur", 
                 target_path: str = None, workspace_path: str = None, **config):
        self.agent_id = agent_id or f"agent_0_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.agent_type = agent_type
        self.config = config
        
        # PROBLÃˆME: Logger non centralisÃ©, nom hard-codÃ©
        self.logger = logging.getLogger("Agent0ChefEquipe")
        
        # Configuration Ã©quipe
        self.target_path = Path(target_path) if target_path else Path("../agent_factory_implementation/agents")
        self.workspace_path = Path(workspace_path) if workspace_path else Path(".")
        self.equipe_agents = {}
        
        # PROBLÃˆME: Log dans rÃ©pertoire non contrÃ´lÃ©
        self.logger.info(f"ğŸ–ï¸ Agent 0 Chef d'Ã‰quipe Coordinateur initialisÃ© - ID: {self.agent_id}")
        
    async def _sauvegarder_rapport_final(self, workflow_result: Dict):
        """Sauvegarde du rapport final consolidÃ©"""
        try:
            # PROBLÃˆME: Logs et rapports mÃ©langÃ©s
            rapport_path = self.workspace_path / "reports" / f"chef_equipe_maintenance_complete_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            rapport_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(rapport_path, 'w', encoding='utf-8') as f:
                json.dump(workflow_result, f, indent=2, ensure_ascii=False, default=str)
            
            # PROBLÃˆME: Log sans catÃ©gorisation ni contrÃ´le destination
            self.logger.info(f"ğŸ’¾ Rapport final sauvegardÃ©: {rapport_path}")
            
        except Exception as e:
            # PROBLÃˆME: Logs d'erreur non centralisÃ©s
            self.logger.error(f"âŒ Erreur sauvegarde rapport final: {e}")
```

---

## ğŸ¯ **SOLUTION PROPOSÃ‰E : Code Complet**

### ğŸ“„ **1. LoggingManager CentralisÃ© (NOUVEAU)**

```python
#!/usr/bin/env python3
"""
LoggingManager CentralisÃ© NextGeneration
Gestion unifiÃ©e de tous les logs du systÃ¨me
"""

import json
import logging
import logging.handlers
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Optional, List
from dataclasses import dataclass, asdict
import threading

@dataclass
class LoggingConfig:
    """Configuration de logging pour un composant"""
    logger_name: str
    log_level: str = "INFO"
    log_dir: str = "logs"
    filename_pattern: str = "{component}_{date}.log"
    max_file_size: int = 10485760  # 10MB
    backup_count: int = 5
    console_enabled: bool = True
    file_enabled: bool = True
    format_string: str = "%(asctime)s - %(name)s - %(levelname)s - %(funcName)s:%(lineno)d - %(message)s"

class LoggingManager:
    """Gestionnaire centralisÃ© de logging pour NextGeneration"""
    
    _instance = None
    _lock = threading.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        if hasattr(self, '_initialized'):
            return
        
        self._initialized = True
        self.base_log_dir = Path("logs")
        self.config_file = Path("config/logging_centralized.json")
        self._loggers: Dict[str, logging.Logger] = {}
        self._configs: Dict[str, LoggingConfig] = {}
        
        # CrÃ©er l'arborescence de base
        self._setup_directory_structure()
        
        # Charger ou crÃ©er la configuration
        self._load_or_create_config()
    
    def _setup_directory_structure(self):
        """CrÃ©e l'arborescence de logs centralisÃ©e"""
        directories = [
            self.base_log_dir / "agents",
            self.base_log_dir / "agents" / "coordinateur", 
            self.base_log_dir / "agents" / "analyseur",
            self.base_log_dir / "agents" / "evaluateur",
            self.base_log_dir / "agents" / "adaptateur",
            self.base_log_dir / "agents" / "testeur",
            self.base_log_dir / "agents" / "documenteur",
            self.base_log_dir / "agents" / "validateur",
            self.base_log_dir / "tools",
            self.base_log_dir / "tools" / "tts_performance_monitor",
            self.base_log_dir / "tools" / "backup_system", 
            self.base_log_dir / "tools" / "excel_vba_launcher",
            self.base_log_dir / "tools" / "documentation_generator",
            self.base_log_dir / "system",
            self.base_log_dir / "errors",
            Path("config")
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
    
    def _load_or_create_config(self):
        """Charge ou crÃ©e la configuration de logging"""
        if self.config_file.exists():
            with open(self.config_file, 'r', encoding='utf-8') as f:
                config_data = json.load(f)
                for name, config in config_data.items():
                    self._configs[name] = LoggingConfig(**config)
        else:
            # Configuration par dÃ©faut
            self._create_default_configs()
            self._save_config()
    
    def _create_default_configs(self):
        """CrÃ©e les configurations par dÃ©faut"""
        default_configs = {
            "template_manager": LoggingConfig(
                logger_name="system.template_manager",
                log_dir="logs/system",
                filename_pattern="template_manager_{date}.log"
            ),
            "agent_factory": LoggingConfig(
                logger_name="system.agent_factory", 
                log_dir="logs/system",
                filename_pattern="agent_factory_{date}.log"
            ),
            "agent_coordinateur": LoggingConfig(
                logger_name="agent.coordination.chef_equipe",
                log_dir="logs/agents/coordinateur",
                filename_pattern="coordinateur_{agent_id}_{date}.log"
            ),
            "agent_analyseur": LoggingConfig(
                logger_name="agent.analysis.structure",
                log_dir="logs/agents/analyseur", 
                filename_pattern="analyseur_{agent_id}_{date}.log"
            ),
            "errors_critical": LoggingConfig(
                logger_name="errors.critical",
                log_dir="logs/errors",
                filename_pattern="critical_errors_{date}.log",
                log_level="ERROR"
            )
        }
        
        self._configs.update(default_configs)
    
    def _save_config(self):
        """Sauvegarde la configuration"""
        config_data = {name: asdict(config) for name, config in self._configs.items()}
        self.config_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(self.config_file, 'w', encoding='utf-8') as f:
            json.dump(config_data, f, indent=2, ensure_ascii=False)
    
    def generate_agent_logging_config(self, agent_name: str, role: str, domain: str, agent_id: str = None) -> Dict[str, Any]:
        """GÃ©nÃ¨re une configuration de logging pour un agent"""
        agent_id = agent_id or f"{role}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        
        return {
            "logger_name": f"agent.{domain}.{role}.{agent_name}",
            "log_level": "INFO",
            "log_dir": f"logs/agents/{role}",
            "filename_pattern": f"{role}_{agent_id}_{{date}}.log",
            "max_file_size": 10485760,
            "backup_count": 5,
            "console_enabled": True,
            "file_enabled": True,
            "format_string": "%(asctime)s - %(name)s - %(levelname)s - [%(filename)s:%(lineno)d] - %(message)s",
            "agent_metadata": {
                "agent_id": agent_id,
                "agent_name": agent_name,
                "role": role,
                "domain": domain,
                "created_at": datetime.now().isoformat()
            }
        }
    
    def get_logger(self, config_name: str, custom_config: Dict[str, Any] = None) -> logging.Logger:
        """Obtient un logger configurÃ©"""
        
        if custom_config:
            # Configuration personnalisÃ©e (pour agents gÃ©nÃ©rÃ©s)
            config = LoggingConfig(**custom_config)
            logger_name = config.logger_name
        else:
            # Configuration prÃ©dÃ©finie
            if config_name not in self._configs:
                raise ValueError(f"Configuration de logging '{config_name}' non trouvÃ©e")
            config = self._configs[config_name]
            logger_name = config.logger_name
        
        if logger_name in self._loggers:
            return self._loggers[logger_name]
        
        # CrÃ©er le logger
        logger = logging.getLogger(logger_name)
        logger.setLevel(getattr(logging, config.log_level))
        logger.handlers.clear()  # Ã‰viter les doublons
        
        # Handler fichier
        if config.file_enabled:
            log_dir = Path(config.log_dir)
            log_dir.mkdir(parents=True, exist_ok=True)
            
            current_date = datetime.now().strftime('%Y%m%d')
            filename = config.filename_pattern.format(
                component=config_name,
                date=current_date,
                **custom_config.get("agent_metadata", {}) if custom_config else {}
            )
            
            log_file = log_dir / filename
            
            file_handler = logging.handlers.RotatingFileHandler(
                log_file,
                maxBytes=config.max_file_size,
                backupCount=config.backup_count,
                encoding='utf-8'
            )
            file_handler.setFormatter(logging.Formatter(config.format_string))
            logger.addHandler(file_handler)
        
        # Handler console
        if config.console_enabled:
            console_handler = logging.StreamHandler()
            console_formatter = logging.Formatter(
                "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
            )
            console_handler.setFormatter(console_formatter)
            logger.addHandler(console_handler)
        
        self._loggers[logger_name] = logger
        return logger
    
    def get_agent_logger(self, agent_name: str, role: str, domain: str, agent_id: str = None) -> logging.Logger:
        """Obtient un logger pour un agent avec configuration automatique"""
        config = self.generate_agent_logging_config(agent_name, role, domain, agent_id)
        return self.get_logger(None, config)

# Instance globale
logging_manager = LoggingManager()
```

---

### ğŸ“„ **2. TemplateManager ModifiÃ© (APRÃˆS)**

```python
#!/usr/bin/env python3
"""
Code Expert NextGeneration - optimized_template_manager
VERSION AVEC LOGGING CENTRALISÃ‰
"""

import asyncio
import json
import time
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor
from contextlib import asynccontextmanager
from dataclasses import dataclass, field
from datetime import datetime, timedelta
from functools import lru_cache
from pathlib import Path
from threading import RLock
from typing import Any, Dict, List, Optional, Set, Tuple, Union

import aiofiles
from watchdog.events import FileSystemEventHandler
from watchdog.observers import Observer

from .agent_templates import AgentTemplate, TemplateValidationError
from ..agents.base_agent import BaseAgent
from ..config.agent_config import AgentFactoryConfig
from ..logging.centralized_logging import logging_manager  # NOUVEAU

# MODIFICATION: Logger centralisÃ© au lieu de logging.getLogger(__name__)
logger = logging_manager.get_logger("template_manager")

@dataclass
class TemplateMetrics:
    """MÃ©triques de performance pour les templates."""
    loads_count: int = 0
    cache_hits: int = 0
    cache_misses: int = 0
    reload_count: int = 0
    creation_times: List[float] = field(default_factory=list)
    errors: Dict[str, int] = field(default_factory=lambda: defaultdict(int))
    last_accessed: Dict[str, datetime] = field(default_factory=dict)

class TemplateFileWatcher(FileSystemEventHandler):
    """Surveille les modifications des fichiers templates."""
    
    def __init__(self, manager: 'TemplateManager'):
        self.manager = manager
        # MODIFICATION: Logger centralisÃ©
        self.logger = logging_manager.get_logger("template_manager")
        
    def on_modified(self, event):
        """Callback lors de la modification d'un fichier."""
        if event.is_directory or not event.src_path.endswith('.json'):
            return
            
        template_name = Path(event.src_path).stem
        # MODIFICATION: Log centralisÃ© avec catÃ©gorie spÃ©cifique
        self.logger.info("Template modifiÃ© dÃ©tectÃ© : %s", template_name)
        
        # Invalider le cache pour ce template
        asyncio.create_task(self.manager.reload_template(template_name))

class TemplateManager:
    """Gestionnaire optimisÃ© de templates avec logging centralisÃ©."""
    
    def __init__(
        self,
        config: Optional[AgentFactoryConfig] = None,
        enable_hot_reload: bool = True,
        preload_templates: Optional[List[str]] = None
    ):
        self.config = config or AgentFactoryConfig()
        self._lock = RLock()
        self._cache: Dict[str, AgentTemplate] = {}
        self._timestamps: Dict[str, float] = {}
        self._class_cache: Dict[str, type[BaseAgent]] = {}
        self._metrics = TemplateMetrics()
        self._executor = ThreadPoolExecutor(max_workers=4)
        
        # MODIFICATION: Logger centralisÃ©
        self.logger = logging_manager.get_logger("template_manager")
        
        # Configuration du hot-reload
        self._observer: Optional[Observer] = None
        if enable_hot_reload:
            self._setup_file_watcher()
        
        # PrÃ©chargement des templates critiques
        if preload_templates:
            asyncio.create_task(self._preload_templates(preload_templates))
        
        # AJOUT: Log d'initialisation centralisÃ©
        self.logger.info("TemplateManager initialisÃ© avec logging centralisÃ©")

    def create_agent(
        self,
        template_name: str,
        *,
        suffix: str = "",
        config: Optional[Dict[str, Any]] = None
    ) -> BaseAgent:
        """CrÃ©e une instance d'agent avec injection automatique de logging centralisÃ©."""
        start_time = time.time()
        
        try:
            # Utiliser la classe en cache si disponible
            with self._lock:
                if template_name in self._class_cache:
                    agent_class = self._class_cache[template_name]
                else:
                    tmpl = self.get_template(template_name)
                    agent_class = tmpl.to_class()
                    self._class_cache[template_name] = agent_class
            
            # MODIFICATION: Injection automatique de la configuration logging
            if config is None:
                config = {}
            
            # Obtenir les informations du template pour la configuration logging
            template = self.get_template(template_name)
            agent_name = f"{template_name}{suffix}"
            agent_id = f"{template_name}_{suffix}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            
            # AJOUT: GÃ©nÃ©ration automatique de la configuration logging
            if "logging" not in config:
                config["logging"] = logging_manager.generate_agent_logging_config(
                    agent_name=agent_name,
                    role=template.role,
                    domain=template.domain,
                    agent_id=agent_id
                )
                
                # Log de l'injection de configuration
                self.logger.debug(
                    "Configuration logging injectÃ©e pour agent %s (template=%s, role=%s, domain=%s)",
                    agent_name, template_name, template.role, template.domain
                )
            
            # CrÃ©er l'instance (hors du lock)
            agent = agent_class.create(name_suffix=suffix, config=config)
            
            # MÃ©triques
            creation_time = time.time() - start_time
            with self._lock:
                self._metrics.creation_times.append(creation_time)
                if len(self._metrics.creation_times) > 1000:
                    self._metrics.creation_times = self._metrics.creation_times[-1000:]
            
            # MODIFICATION: Log centralisÃ© avec informations enrichies
            self.logger.info(
                "Agent crÃ©Ã© avec logging centralisÃ© : %s (template=%s, role=%s, domain=%s, temps=%.3fs)",
                agent.metadata.name,
                template_name,
                template.role,
                template.domain,
                creation_time
            )
            
            return agent
            
        except Exception as e:
            self._metrics.errors[type(e).__name__] += 1
            # MODIFICATION: Log d'erreur centralisÃ© avec contexte enrichi
            self.logger.error(
                "Erreur crÃ©ation agent '%s' (template=%s): %s",
                f"{template_name}{suffix}",
                template_name,
                e,
                exc_info=True
            )
            raise
    
    def bulk_create_agents(
        self,
        specs: List[Dict[str, Any]]
    ) -> Dict[str, BaseAgent]:
        """CrÃ©e plusieurs agents en lot avec logging centralisÃ©."""
        agents = {}
        
        # AJOUT: Log de dÃ©but de crÃ©ation en masse
        self.logger.info("DÃ©but crÃ©ation en masse de %d agents", len(specs))
        
        for i, spec in enumerate(specs, 1):
            template_name = spec.get('template')
            if not template_name:
                # MODIFICATION: Log d'avertissement centralisÃ©
                self.logger.warning("Spec %d/%d ignorÃ©e (pas de 'template') : %s", i, len(specs), spec)
                continue
            
            suffix = spec.get('suffix', '')
            config = spec.get('config')
            
            try:
                agent = self.create_agent(
                    template_name,
                    suffix=suffix,
                    config=config
                )
                agents[agent.metadata.name] = agent
                
                # AJOUT: Log de progression
                self.logger.debug("Agent %d/%d crÃ©Ã©: %s", i, len(specs), agent.metadata.name)
                
            except Exception as e:
                # MODIFICATION: Log d'erreur centralisÃ© avec contexte
                self.logger.error(
                    "Erreur crÃ©ation agent %d/%d (template=%s, suffix=%s): %s",
                    i, len(specs), template_name, suffix, e
                )
        
        # AJOUT: Log de fin avec rÃ©sumÃ©
        self.logger.info("CrÃ©ation en masse terminÃ©e: %d/%d agents crÃ©Ã©s avec succÃ¨s", len(agents), len(specs))
        
        return agents

    def get_metrics(self) -> Dict[str, Any]:
        """Retourne les mÃ©triques de performance avec informations de logging."""
        with self._lock:
            base_metrics = {
                "loads_count": self._metrics.loads_count,
                "cache_hits": self._metrics.cache_hits,
                "cache_misses": self._metrics.cache_misses,
                "hit_rate": self._metrics.hit_rate,
                "reload_count": self._metrics.reload_count,
                "avg_creation_time": self._metrics.avg_creation_time,
                "total_agents_created": len(self._metrics.creation_times),
                "errors": dict(self._metrics.errors),
                "cache_size": len(self._cache),
                "templates_available": len(self.list_templates())
            }
            
            # AJOUT: MÃ©triques de logging
            base_metrics["logging_info"] = {
                "centralized_logging_enabled": True,
                "logger_name": self.logger.name,
                "log_handlers_count": len(self.logger.handlers),
                "log_level": self.logger.level
            }
            
            return base_metrics
```

---

### ğŸ“„ **3. Agent ModifiÃ© (APRÃˆS)**

```python
#!/usr/bin/env python3
"""
ğŸ–ï¸ Agent 0 - Chef d'Ã‰quipe Coordinateur
VERSION AVEC LOGGING CENTRALISÃ‰
"""

import asyncio
import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional
import sys

# MODIFICATION: Import du LoggingManager centralisÃ©
from ..logging.centralized_logging import logging_manager

class Agent0ChefEquipeCoordinateur:
    """Agent 0 - Chef d'Ã‰quipe Coordinateur avec logging centralisÃ©"""
    
    def __init__(self, agent_id: str = None, agent_type: str = "chef_equipe_coordinateur", 
                 target_path: str = None, workspace_path: str = None, **config):
        self.agent_id = agent_id or f"agent_0_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.agent_type = agent_type
        self.config = config
        
        # MODIFICATION: Utilisation du logger centralisÃ© avec configuration spÃ©cialisÃ©e
        if "logging" in config:
            # Configuration injectÃ©e par le TemplateManager
            self.logger = logging_manager.get_logger(None, config["logging"])
        else:
            # Configuration par dÃ©faut pour coordination
            self.logger = logging_manager.get_agent_logger(
                agent_name="chef_equipe_coordinateur",
                role="coordinateur", 
                domain="coordination",
                agent_id=self.agent_id
            )
        
        # Configuration Ã©quipe
        self.target_path = Path(target_path) if target_path else Path("../agent_factory_implementation/agents")
        self.workspace_path = Path(workspace_path) if workspace_path else Path(".")
        self.equipe_agents = {}
        
        # MODIFICATION: Log centralisÃ© avec mÃ©tadonnÃ©es enrichies
        self.logger.info(
            "ğŸ–ï¸ Agent 0 Chef d'Ã‰quipe Coordinateur initialisÃ© avec logging centralisÃ© - ID: %s, Type: %s",
            self.agent_id, self.agent_type,
            extra={
                "agent_id": self.agent_id,
                "agent_type": self.agent_type,
                "target_path": str(self.target_path),
                "workspace_path": str(self.workspace_path),
                "logging_centralized": True
            }
        )
        
    async def startup(self):
        """DÃ©marrage Agent 0 Chef d'Ã‰quipe avec logging centralisÃ©"""
        # MODIFICATION: Log structurÃ© avec niveau appropriÃ©
        self.logger.info(
            "ğŸš€ Agent 0 Chef d'Ã‰quipe %s - DÃ‰MARRAGE",
            self.agent_id,
            extra={"operation": "startup", "agent_id": self.agent_id}
        )
        
        # VÃ©rification des chemins
        if not self.target_path.exists():
            # MODIFICATION: Log d'avertissement centralisÃ©
            self.logger.warning(
                "âš ï¸ Chemin cible non trouvÃ©: %s - CrÃ©ation automatique",
                self.target_path,
                extra={"operation": "path_creation", "path": str(self.target_path)}
            )
            self.target_path.mkdir(parents=True, exist_ok=True)
        
        # MODIFICATION: Log structurÃ© de configuration
        self.logger.info(
            "âœ… Configuration Chef d'Ã‰quipe validÃ©e",
            extra={
                "operation": "configuration",
                "target_path": str(self.target_path),
                "workspace_path": str(self.workspace_path),
                "workflows_available": len(self.workflows_disponibles)
            }
        )
        
        # MODIFICATION: Log de fin de dÃ©marrage
        self.logger.info(
            "âœ… Chef d'Ã‰quipe prÃªt Ã  coordonner l'Ã©quipe",
            extra={"operation": "startup_complete", "status": "ready"}
        )
        
        return {"status": "started", "agent_id": self.agent_id}
        
    async def _sauvegarder_rapport_final(self, workflow_result: Dict):
        """Sauvegarde du rapport final avec logging centralisÃ©"""
        try:
            # MODIFICATION: SÃ©paration claire logs/rapports avec structure centralisÃ©e
            rapport_path = self.workspace_path / "reports" / f"chef_equipe_maintenance_complete_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            rapport_path.parent.mkdir(parents=True, exist_ok=True)
            
            with open(rapport_path, 'w', encoding='utf-8') as f:
                json.dump(workflow_result, f, indent=2, ensure_ascii=False, default=str)
            
            # MODIFICATION: Log centralisÃ© avec mÃ©tadonnÃ©es complÃ¨tes
            self.logger.info(
                "ğŸ’¾ Rapport final sauvegardÃ© avec succÃ¨s",
                extra={
                    "operation": "report_save",
                    "rapport_path": str(rapport_path),
                    "workflow_status": workflow_result.get("status", "unknown"),
                    "file_size": rapport_path.stat().st_size if rapport_path.exists() else 0,
                    "duration_sec": workflow_result.get("duree_totale_sec", 0)
                }
            )
            
        except Exception as e:
            # MODIFICATION: Log d'erreur centralisÃ© avec contexte complet
            self.logger.error(
                "âŒ Erreur sauvegarde rapport final",
                extra={
                    "operation": "report_save_error",
                    "error_type": type(e).__name__,
                    "error_message": str(e),
                    "workflow_status": workflow_result.get("status", "unknown")
                },
                exc_info=True
            )
            
    async def health_check(self) -> Dict[str, Any]:
        """VÃ©rification santÃ© avec logging centralisÃ©"""
        health_status = {
            "chef_equipe_id": self.agent_id,
            "agent_type": self.agent_type,
            "status": "healthy",
            "agents_disponibles": len(self.equipe_agents),
            "workflows_disponibles": len(self.workflows_disponibles),
            "logging_centralized": True,
            "logger_name": self.logger.name,
            "timestamp": datetime.now().isoformat()
        }
        
        # MODIFICATION: Log de health check avec mÃ©triques
        self.logger.info(
            "ğŸ¥ Health Check Agent 0 Chef d'Ã‰quipe: %s",
            health_status['status'],
            extra={
                "operation": "health_check",
                "health_status": health_status,
                "agents_count": len(self.equipe_agents),
                "workflows_count": len(self.workflows_disponibles)
            }
        )
        
        return health_status
```

---

## ğŸ“Š **Plan de DÃ©veloppement DÃ©taillÃ©**

### ğŸ¯ **Phase 1 : Infrastructure (1 semaine)**

#### **Jour 1-2 : LoggingManager**
- [ ] CrÃ©ation classe `LoggingManager` centralisÃ©
- [ ] Tests unitaires configuration et injection
- [ ] Validation arborescence de dossiers

#### **Jour 3-4 : Configuration**
- [ ] Fichier `logging_centralized.json`
- [ ] Templates de configuration par type d'agent
- [ ] Validation JSON Schema

#### **Jour 5-7 : Tests Infrastructure**
- [ ] Tests d'intÃ©gration LoggingManager
- [ ] Benchmarks de performance
- [ ] Documentation API

### ğŸ¯ **Phase 2 : Migration TemplateManager (1 semaine)**

#### **Jour 1-3 : Modification TemplateManager**
- [ ] IntÃ©gration LoggingManager dans TemplateManager
- [ ] Injection automatique configuration logging
- [ ] Tests crÃ©ation d'agents avec logging centralisÃ©

#### **Jour 4-5 : Optimisations**
- [ ] Cache configuration logging
- [ ] Optimisation performance injection
- [ ] Gestion erreurs et fallbacks

#### **Jour 6-7 : Validation**
- [ ] Tests de non-rÃ©gression
- [ ] Tests de performance
- [ ] Documentation modifications

### ğŸ¯ **Phase 3 : Migration Agents (2 semaines)**

#### **Semaine 1 : Agents Core**
- [ ] Migration Agent 0 (Coordinateur)
- [ ] Migration Agent 1 (Analyseur)
- [ ] Migration Agent 2 (Ã‰valuateur)
- [ ] Tests fonctionnels

#### **Semaine 2 : Agents ComplÃ©mentaires**
- [ ] Migration Agents 3-6 (Adaptateur, Testeur, Documenteur, Validateur)
- [ ] Migration outils `/tools/`
- [ ] Tests d'intÃ©gration globaux

### ğŸ¯ **Phase 4 : Validation & DÃ©ploiement (1 semaine)**

#### **Jour 1-3 : Tests Complets**
- [ ] Tests de charge avec logging centralisÃ©
- [ ] Validation rotation et archivage
- [ ] Tests de rÃ©cupÃ©ration aprÃ¨s erreur

#### **Jour 4-5 : Documentation**
- [ ] Documentation utilisateur
- [ ] Guide de migration
- [ ] Runbook opÃ©rationnel

#### **Jour 6-7 : DÃ©ploiement**
- [ ] DÃ©ploiement en staging
- [ ] Validation monitoring
- [ ] Migration production

---

## ğŸš€ **Pistes d'AmÃ©liorations**

### ğŸ“Š **Monitoring AvancÃ©**
- Dashboard temps rÃ©el des logs par agent
- Alertes automatiques sur logs d'erreur
- MÃ©triques de performance logging

### ğŸ”§ **Optimisations Performance**
- Logging asynchrone pour haute charge
- Compression automatique des anciens logs
- Indexation pour recherche rapide

### ğŸŒ **IntÃ©gration Ecosystem**
- Export logs vers Elasticsearch/Splunk
- IntÃ©gration Prometheus pour mÃ©triques
- Support logging distribuÃ© multi-instance

### ğŸ”’ **SÃ©curitÃ©**
- Chiffrement logs sensibles
- Audit trail complet
- ContrÃ´le d'accÃ¨s par rÃ´le

---

**ğŸ“… DurÃ©e totale estimÃ©e** : 5 semaines  
**ğŸ‘¥ Ressources requises** : 2 dÃ©veloppeurs senior  
**ğŸ¯ Objectif** : Logging centralisÃ© 100% opÃ©rationnel 