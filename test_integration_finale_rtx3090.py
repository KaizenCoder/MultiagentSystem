#!/usr/bin/env python3
"""
ğŸ® Test Final IntÃ©gration Orchestrateur RTX3090 - NextGeneration
Validation finale de l'intÃ©gration complÃ¨te
"""

import asyncio
import sys
import os
from pathlib import Path

# Configuration RTX3090
os.environ['CUDA_VISIBLE_DEVICES'] = '1'
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'

# Ajouter chemins
sys.path.append('./orchestrator')
sys.path.append('./orchestrator/app')

async def test_integration_finale():
    """Test final de l'intÃ©gration orchestrateur RTX3090"""
    
    print("ğŸ® TEST FINAL INTÃ‰GRATION ORCHESTRATEUR RTX3090")
    print("=" * 55)
    
    # Test 1: Import configuration optimisÃ©e
    print("ğŸ§ª Test 1: Configuration RTX3090 optimisÃ©e")
    try:
        from orchestrator.app.config_rtx3090_optimized import settings
        
        print("âœ… Configuration RTX3090 importÃ©e avec succÃ¨s")
        print(f"ğŸ“Š ModÃ¨les configurÃ©s: {len(settings.OLLAMA_MODELS)}")
        print(f"ğŸ® GPU: RTX3090 Device {settings.GPU_CONFIG['device_id']}")
        print(f"ğŸ’¾ VRAM disponible: {settings.GPU_CONFIG['available_vram_gb']}GB")
        
        # Afficher modÃ¨les configurÃ©s
        for category, model_info in settings.OLLAMA_MODELS.items():
            print(f"   {category}: {model_info['model']} ({model_info['performance']})")
        
        config_test = True
    except Exception as e:
        print(f"âŒ Erreur configuration: {e}")
        config_test = False
    
    print()
    
    # Test 2: Import OllamaLocalWorker RTX3090
    print("ğŸ§ª Test 2: OllamaLocalWorker RTX3090 optimisÃ©")
    try:
        from orchestrator.app.agents.ollama_worker import ollama_worker_rtx3090
        
        print("âœ… OllamaLocalWorker RTX3090 importÃ© avec succÃ¨s")
        print(f"ğŸ“‹ ModÃ¨les worker: {len(ollama_worker_rtx3090.models)}")
        
        # Test santÃ© du worker
        health = await ollama_worker_rtx3090.health_check()
        if health.get("success", False):
            print(f"âœ… Worker santÃ©: {health['status']}")
            print(f"ğŸ“Š ModÃ¨les Ollama: {health['models_count']}")
        else:
            print(f"âš ï¸ Worker santÃ©: {health.get('error', 'Unknown')}")
        
        worker_test = True
    except Exception as e:
        print(f"âŒ Erreur worker: {e}")
        worker_test = False
    
    print()
    
    # Test 3: SÃ©lection intelligente de modÃ¨les
    print("ğŸ§ª Test 3: SÃ©lection intelligente de modÃ¨les")
    try:
        if worker_test:
            # Test sÃ©lections diffÃ©rentes
            test_cases = [
                ("quick", "RÃ©ponse rapide", "speed"),
                ("code", "Ã‰crire une fonction Python", "code"),
                ("analysis", "Analyse complexe des donnÃ©es", "quality"),
                ("default", "Question gÃ©nÃ©rale", "balanced")
            ]
            
            for task_type, description, expected_category in test_cases:
                selected_model = ollama_worker_rtx3090.select_optimal_model(task_type, description)
                print(f"   {task_type}: {selected_model}")
            
            print("âœ… SÃ©lection intelligente fonctionnelle")
        
        selection_test = True
    except Exception as e:
        print(f"âŒ Erreur sÃ©lection: {e}")
        selection_test = False
    
    print()
    
    # Test 4: GÃ©nÃ©ration test avec nouveau worker
    print("ğŸ§ª Test 4: GÃ©nÃ©ration test optimisÃ©e RTX3090")
    try:
        if worker_test:
            result = await ollama_worker_rtx3090.generate_response(
                prompt="Test final intÃ©gration orchestrateur RTX3090",
                task_type="quick"
            )
            
            if result.get("success", False):
                print(f"âœ… GÃ©nÃ©ration rÃ©ussie")
                print(f"ğŸ¯ ModÃ¨le utilisÃ©: {result['model_used']}")
                print(f"â±ï¸ Temps traitement: {result['processing_time']:.2f}s") 
                print(f"ğŸ“Š Performance: {result['tokens_per_sec']:.1f} tokens/s")
                print(f"ğŸ® GPU: {result['gpu_device']}")
            else:
                print(f"âŒ GÃ©nÃ©ration Ã©chouÃ©e: {result.get('error', 'Unknown')}")
        
        generation_test = result.get("success", False) if worker_test else False
    except Exception as e:
        print(f"âŒ Erreur gÃ©nÃ©ration: {e}")
        generation_test = False
    
    print()
    
    # RÃ©sumÃ© final
    tests = [config_test, worker_test, selection_test, generation_test]
    score = sum(tests)
    
    print("ğŸ¯ RÃ‰SUMÃ‰ FINAL INTÃ‰GRATION RTX3090")
    print("=" * 55)
    print(f"âœ… Configuration optimisÃ©e: {'âœ…' if config_test else 'âŒ'}")
    print(f"âœ… Worker RTX3090: {'âœ…' if worker_test else 'âŒ'}")
    print(f"âœ… SÃ©lection intelligente: {'âœ…' if selection_test else 'âŒ'}")
    print(f"âœ… GÃ©nÃ©ration test: {'âœ…' if generation_test else 'âŒ'}")
    print()
    print(f"ğŸ¯ Score intÃ©gration: {score}/4 ({(score/4)*100:.0f}%)")
    
    if score == 4:
        print("ğŸ‰ INTÃ‰GRATION ORCHESTRATEUR RTX3090 - SUCCÃˆS TOTAL")
        print("âœ… PrÃªt pour production avec modÃ¨les optimisÃ©s")
    elif score >= 3:
        print("âœ… INTÃ‰GRATION ORCHESTRATEUR RTX3090 - RÃ‰USSIE")
        print("âš ï¸ Optimisations mineures possibles")
    else:
        print("âš ï¸ INTÃ‰GRATION ORCHESTRATEUR RTX3090 - INCOMPLÃˆTE") 
        print("ğŸ”§ Corrections nÃ©cessaires")
    
    print(f"\nğŸ® Configuration finale RTX3090 validÃ©e et opÃ©rationnelle")

if __name__ == "__main__":
    asyncio.run(test_integration_finale()) 