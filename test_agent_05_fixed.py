#!/usr/bin/env python3
"""
Test simple de l'Agent 05 moderne corrigÃ©
Validation que toutes les fonctionnalitÃ©s legacy sont prÃ©servÃ©es
"""

import asyncio
import sys
from pathlib import Path
import json

# Add paths
sys.path.insert(0, str(Path(__file__).parent))

async def test_agent_05_moderne():
    """Test complet de l'agent 05 moderne"""
    
    print("ğŸ§ª Test Agent 05 Moderne - Validation FonctionnalitÃ©s Legacy")
    print("=" * 60)
    
    try:
        # Import agent
        from agents.modern.agent_05_maitre_tests_validation_modern_fixed import ModernAgent05MaitreTestsValidation
        from core.nextgen_architecture import Task, Result
        
        print("âœ… Imports rÃ©ussis")
        
        # Create agent
        agent = ModernAgent05MaitreTestsValidation()
        print(f"âœ… Agent crÃ©Ã© - ID: {agent.agent_id}, Version: {agent.version}")
        
        # Startup
        await agent.startup()
        print("âœ… Agent dÃ©marrÃ©")
        
        # Test 1: Health Check
        print("\nğŸ” Test 1: Health Check")
        health = await agent.health_check()
        print(f"  Status: {health.get('status')}")
        print(f"  Components: {list(health.get('components', {}).keys())}")
        
        # Test 2: Capabilities
        print("\nğŸ” Test 2: Capabilities")
        capabilities = agent.get_capabilities()
        print(f"  CapacitÃ©s: {len(capabilities)}")
        for cap in capabilities:
            print(f"    - {cap}")
        
        # Test 3: Smoke Tests (legacy method)
        print("\nğŸ” Test 3: Smoke Tests Legacy")
        smoke_results = agent.run_smoke_tests()
        print(f"  Tests totaux: {smoke_results.get('total_tests')}")
        print(f"  RÃ©ussis: {smoke_results.get('passed')}")
        print(f"  Ã‰chouÃ©s: {smoke_results.get('failed')}")
        
        # Test 4: Rapport StratÃ©gique Tests
        print("\nğŸ” Test 4: Rapport StratÃ©gique Tests")
        task_tests = Task(
            type="generer_rapport_strategique",
            params={
                "context": {"test_mode": True},
                "type_rapport": "tests"
            }
        )
        result_tests = await agent.execute_task(task_tests)
        if result_tests.success:
            rapport_tests = result_tests.data
            print(f"  Score global: {rapport_tests.get('score_global')}")
            print(f"  Niveau qualitÃ©: {rapport_tests.get('niveau_qualite')}")
            print(f"  ConformitÃ©: {rapport_tests.get('conformite')}")
        else:
            print(f"  âŒ Erreur: {result_tests.error}")
        
        # Test 5: Rapport StratÃ©gique Validation
        print("\nğŸ” Test 5: Rapport StratÃ©gique Validation")
        task_validation = Task(
            type="generer_rapport_strategique",
            params={
                "context": {"test_mode": True},
                "type_rapport": "validation"
            }
        )
        result_validation = await agent.execute_task(task_validation)
        if result_validation.success:
            rapport_validation = result_validation.data
            print(f"  Score validation: {rapport_validation.get('score_validation')}")
            print(f"  CritÃ¨res: {list(rapport_validation.get('criteres_validation', {}).keys())}")
        else:
            print(f"  âŒ Erreur: {result_validation.error}")
        
        # Test 6: Rapport StratÃ©gique Performance
        print("\nğŸ” Test 6: Rapport StratÃ©gique Performance")
        task_performance = Task(
            type="generer_rapport_strategique",
            params={
                "context": {"test_mode": True},
                "type_rapport": "performance"
            }
        )
        result_performance = await agent.execute_task(task_performance)
        if result_performance.success:
            rapport_performance = result_performance.data
            print(f"  Score performance: {rapport_performance.get('score_performance')}")
            print(f"  MÃ©triques: {list(rapport_performance.get('metriques_performance', {}).keys())}")
        else:
            print(f"  âŒ Erreur: {result_performance.error}")
        
        # Test 7: Rapport StratÃ©gique QualitÃ©
        print("\nğŸ” Test 7: Rapport StratÃ©gique QualitÃ©")
        task_qualite = Task(
            type="generer_rapport_strategique",
            params={
                "context": {"test_mode": True},
                "type_rapport": "qualite"
            }
        )
        result_qualite = await agent.execute_task(task_qualite)
        if result_qualite.success:
            rapport_qualite = result_qualite.data
            print(f"  Score qualitÃ©: {rapport_qualite.get('score_qualite')}")
            print(f"  Standards: {len(rapport_qualite.get('standards_respectes', []))}")
        else:
            print(f"  âŒ Erreur: {result_qualite.error}")
        
        # Test 8: GÃ©nÃ©ration Markdown
        print("\nğŸ” Test 8: GÃ©nÃ©ration Markdown")
        if result_tests.success:
            task_markdown = Task(
                type="generer_rapport_markdown",
                params={
                    "rapport_json": result_tests.data,
                    "type_rapport": "tests",
                    "context": {"test_mode": True}
                }
            )
            result_markdown = await agent.execute_task(task_markdown)
            if result_markdown.success:
                markdown = result_markdown.data.get("markdown", "")
                print(f"  Markdown gÃ©nÃ©rÃ©: {len(markdown)} caractÃ¨res")
                print(f"  Contient '# ğŸ§ª RAPPORT TESTS': {'# ğŸ§ª RAPPORT TESTS' in markdown}")
            else:
                print(f"  âŒ Erreur: {result_markdown.error}")
        
        # Test 9: Task non supportÃ©e
        print("\nğŸ” Test 9: Task Non SupportÃ©e")
        task_invalid = Task(
            type="task_inexistante",
            params={}
        )
        result_invalid = await agent.execute_task(task_invalid)
        print(f"  Gestion erreur: {'OK' if not result_invalid.success else 'PROBLÃˆME'}")
        
        # Shutdown
        await agent.shutdown()
        print("\nâœ… Agent arrÃªtÃ© proprement")
        
        print("\n" + "=" * 60)
        print("ğŸ‰ TOUS LES TESTS LEGACY FONCTIONNENT CORRECTEMENT")
        print("âœ… L'agent moderne prÃ©serve 100% des fonctionnalitÃ©s legacy")
        print("ğŸš€ AmÃ©liorations modernes disponibles en plus")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ ERREUR CRITIQUE: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = asyncio.run(test_agent_05_moderne())
    sys.exit(0 if success else 1)