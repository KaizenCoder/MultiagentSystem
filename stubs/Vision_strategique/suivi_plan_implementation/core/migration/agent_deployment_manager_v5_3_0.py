#!/usr/bin/env python3
"""
ğŸš€ Agent Deployment Manager - NextGeneration v5.3.0
Version enterprise Wave 4 avec CI/CD automation intelligent

Migration Pattern: DEPLOYMENT_AUTOMATION + CI_CD + LLM_ENHANCED
Author: Claude Sonnet 4
Date: 30 Juin 2025
"""

import asyncio
import json
import time
import hashlib
import yaml
import subprocess
import tempfile
import shutil
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Optional, Any, Union, Callable, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import logging
import threading
import queue
import uuid

# Imports NextGeneration Architecture
try:
    from core.services import (
        LLMGatewayHybrid, create_llm_gateway,
        MessageBusA2A, create_envelope, MessageType, Priority,
        OptimizedContextStore, create_agent_context, ContextType
    )
    from core.agent_factory_architecture import Task, Result
except ImportError:
    # Fallback pour dÃ©veloppement isolÃ©
    print("âš ï¸ NextGeneration services not available - running in development mode")
    class Task:
        def __init__(self, task_type, params=None):
            self.type = task_type
            self.params = params or {}
    
    class Result:
        def __init__(self, success, data=None, error=None, metrics=None):
            self.success = success
            self.data = data
            self.error = error
            self.metrics = metrics or {}

class DeploymentStrategy(str, Enum):
    """StratÃ©gies de dÃ©ploiement"""
    ROLLING = "ROLLING"
    BLUE_GREEN = "BLUE_GREEN"
    CANARY = "CANARY"
    IMMUTABLE = "IMMUTABLE"
    FEATURE_FLAG = "FEATURE_FLAG"
    AI_OPTIMIZED = "AI_OPTIMIZED"

class DeploymentStatus(str, Enum):
    """Statuts de dÃ©ploiement"""
    PENDING = "PENDING"
    BUILDING = "BUILDING"
    TESTING = "TESTING"
    DEPLOYING = "DEPLOYING"
    DEPLOYED = "DEPLOYED"
    FAILED = "FAILED"
    ROLLED_BACK = "ROLLED_BACK"
    CANCELLED = "CANCELLED"

class Environment(str, Enum):
    """Environnements de dÃ©ploiement"""
    DEVELOPMENT = "DEVELOPMENT"
    STAGING = "STAGING"
    PRODUCTION = "PRODUCTION"
    CANARY = "CANARY"
    BLUE = "BLUE"
    GREEN = "GREEN"

@dataclass
class DeploymentConfig:
    """Configuration de dÃ©ploiement"""
    deployment_id: str
    name: str
    application: str
    version: str
    environment: Environment
    strategy: DeploymentStrategy
    source_branch: str
    build_config: Dict[str, Any]
    deployment_config: Dict[str, Any]
    rollback_config: Optional[Dict[str, Any]] = None
    health_checks: List[Dict[str, Any]] = None
    notifications: List[str] = None
    created_at: datetime = None

@dataclass
class BuildArtifact:
    """Artefact de build"""
    artifact_id: str
    deployment_id: str
    type: str  # docker_image, package, binary
    location: str
    checksum: str
    size_bytes: int
    metadata: Dict[str, Any]
    created_at: datetime

@dataclass
class DeploymentMetrics:
    """MÃ©triques de dÃ©ploiement"""
    deployment_id: str
    build_time_seconds: float
    test_time_seconds: float
    deployment_time_seconds: float
    total_time_seconds: float
    success_rate: float
    rollback_time_seconds: float = 0.0
    health_check_results: List[Dict[str, Any]] = None

class IntelligentDeploymentOptimizer:
    """Optimiseur de dÃ©ploiement intelligent avec IA"""
    
    def __init__(self, llm_gateway: Optional[LLMGatewayHybrid] = None):
        self.llm_gateway = llm_gateway
        self.deployment_history = []
        self.performance_patterns = {}
        self.risk_assessments = {}
    
    async def optimize_deployment_strategy(self, config: DeploymentConfig) -> DeploymentConfig:
        """Optimisation stratÃ©gie dÃ©ploiement avec IA"""
        optimized_config = config
        
        # Analyse historique
        historical_data = self._get_historical_data(config.application, config.environment)
        
        # Enhancement IA si disponible
        if self.llm_gateway:
            try:
                ai_optimization = await self.llm_gateway.process_request(
                    "Optimize deployment strategy based on application and environment",
                    context={
                        "role": "deployment_strategy_expert",
                        "application": config.application,
                        "environment": config.environment.value,
                        "current_strategy": config.strategy.value,
                        "historical_performance": historical_data,
                        "deployment_config": asdict(config),
                        "task": "deployment_strategy_optimization"
                    }
                )
                
                if ai_optimization.get("success"):
                    suggestions = ai_optimization.get("optimizations", {})
                    optimized_config = self._apply_ai_optimizations(config, suggestions)
                    
            except Exception as e:
                self.logger = logging.getLogger(f"DeploymentOptimizer_{id(self)}")
                self.logger.warning(f"âš ï¸ Erreur optimisation IA: {e}")
        
        return optimized_config
    
    def _get_historical_data(self, application: str, environment: Environment) -> Dict[str, Any]:
        """RÃ©cupÃ©ration donnÃ©es historiques"""
        # Filtrage historique pour application/environnement
        relevant_deployments = [
            d for d in self.deployment_history 
            if d.get("application") == application and d.get("environment") == environment.value
        ]
        
        if not relevant_deployments:
            return {"deployments_count": 0}
        
        # Calcul statistiques
        success_rate = len([d for d in relevant_deployments if d.get("success")]) / len(relevant_deployments)
        avg_duration = sum(d.get("duration", 0) for d in relevant_deployments) / len(relevant_deployments)
        
        return {
            "deployments_count": len(relevant_deployments),
            "success_rate": success_rate,
            "average_duration_seconds": avg_duration,
            "last_deployment": relevant_deployments[-1] if relevant_deployments else None
        }
    
    def _apply_ai_optimizations(self, config: DeploymentConfig, 
                               suggestions: Dict[str, Any]) -> DeploymentConfig:
        """Application optimisations IA"""
        optimized = config
        
        # StratÃ©gie de dÃ©ploiement suggÃ©rÃ©e
        if suggestions.get("strategy"):
            suggested_strategy = suggestions["strategy"]
            if suggested_strategy in [s.value for s in DeploymentStrategy]:
                optimized.strategy = DeploymentStrategy(suggested_strategy)
        
        # Configuration build optimisÃ©e
        if suggestions.get("build_optimizations"):
            build_opts = suggestions["build_optimizations"]
            optimized.build_config.update(build_opts)
        
        # Health checks suggÃ©rÃ©s
        if suggestions.get("health_checks"):
            optimized.health_checks = suggestions["health_checks"]
        
        return optimized
    
    async def assess_deployment_risk(self, config: DeploymentConfig) -> Dict[str, Any]:
        """Ã‰valuation risques dÃ©ploiement"""
        risk_factors = {
            "environment_risk": self._assess_environment_risk(config.environment),
            "application_risk": self._assess_application_risk(config.application),
            "strategy_risk": self._assess_strategy_risk(config.strategy),
            "timing_risk": self._assess_timing_risk()
        }
        
        # Enhancement IA si disponible
        if self.llm_gateway:
            try:
                ai_risk_assessment = await self.llm_gateway.process_request(
                    "Assess deployment risk factors",
                    context={
                        "role": "deployment_risk_analyst",
                        "deployment_config": asdict(config),
                        "risk_factors": risk_factors,
                        "task": "deployment_risk_assessment"
                    }
                )
                
                if ai_risk_assessment.get("success"):
                    ai_risks = ai_risk_assessment.get("risk_assessment", {})
                    risk_factors.update(ai_risks)
                    
            except Exception:
                pass
        
        # Calcul score risque global
        overall_risk = sum(risk_factors.values()) / len(risk_factors)
        
        return {
            "overall_risk_score": overall_risk,
            "risk_factors": risk_factors,
            "risk_level": "HIGH" if overall_risk > 0.7 else "MEDIUM" if overall_risk > 0.4 else "LOW",
            "recommendations": self._generate_risk_recommendations(risk_factors)
        }
    
    def _assess_environment_risk(self, environment: Environment) -> float:
        """Ã‰valuation risque environnement"""
        risk_mapping = {
            Environment.DEVELOPMENT: 0.1,
            Environment.STAGING: 0.3,
            Environment.CANARY: 0.4,
            Environment.BLUE: 0.5,
            Environment.GREEN: 0.5,
            Environment.PRODUCTION: 0.8
        }
        return risk_mapping.get(environment, 0.5)
    
    def _assess_application_risk(self, application: str) -> float:
        """Ã‰valuation risque application"""
        # Analyse basÃ©e sur historique
        app_history = [d for d in self.deployment_history if d.get("application") == application]
        if not app_history:
            return 0.5  # Risque moyen pour nouvelle application
        
        # Calcul basÃ© sur taux d'Ã©chec rÃ©cent
        recent_failures = len([d for d in app_history[-10:] if not d.get("success")])
        return min(recent_failures / 10, 1.0)
    
    def _assess_strategy_risk(self, strategy: DeploymentStrategy) -> float:
        """Ã‰valuation risque stratÃ©gie"""
        risk_mapping = {
            DeploymentStrategy.ROLLING: 0.3,
            DeploymentStrategy.BLUE_GREEN: 0.2,
            DeploymentStrategy.CANARY: 0.1,
            DeploymentStrategy.IMMUTABLE: 0.4,
            DeploymentStrategy.FEATURE_FLAG: 0.2,
            DeploymentStrategy.AI_OPTIMIZED: 0.15
        }
        return risk_mapping.get(strategy, 0.5)
    
    def _assess_timing_risk(self) -> float:
        """Ã‰valuation risque timing"""
        current_hour = datetime.now().hour
        
        # Heures de pointe (risque Ã©levÃ©)
        if 9 <= current_hour <= 17:  # Heures bureau
            return 0.8
        elif 18 <= current_hour <= 22:  # SoirÃ©e
            return 0.4
        else:  # Nuit/weekend
            return 0.2
    
    def _generate_risk_recommendations(self, risk_factors: Dict[str, float]) -> List[str]:
        """GÃ©nÃ©ration recommandations basÃ©es sur risques"""
        recommendations = []
        
        if risk_factors.get("environment_risk", 0) > 0.7:
            recommendations.append("ConsidÃ©rer dÃ©ploiement canary pour production")
        
        if risk_factors.get("timing_risk", 0) > 0.6:
            recommendations.append("Reporter dÃ©ploiement en dehors heures bureau")
        
        if risk_factors.get("application_risk", 0) > 0.5:
            recommendations.append("Renforcer tests et health checks")
        
        return recommendations

class CICDPipeline:
    """Pipeline CI/CD intelligent"""
    
    def __init__(self, deployment_manager):
        self.manager = deployment_manager
        self.running_pipelines = {}
        self.build_queue = asyncio.Queue()
    
    async def execute_pipeline(self, config: DeploymentConfig) -> DeploymentMetrics:
        """ExÃ©cution pipeline CI/CD complet"""
        pipeline_id = config.deployment_id
        start_time = time.time()
        
        metrics = DeploymentMetrics(
            deployment_id=pipeline_id,
            build_time_seconds=0,
            test_time_seconds=0,
            deployment_time_seconds=0,
            total_time_seconds=0,
            success_rate=0.0,
            health_check_results=[]
        )
        
        try:
            self.manager.logger.info(f"ğŸš€ DÃ©marrage pipeline CI/CD: {config.name}")
            self.running_pipelines[pipeline_id] = config
            
            # Ã‰tape 1: Build
            build_start = time.time()
            artifact = await self._build_stage(config)
            metrics.build_time_seconds = time.time() - build_start
            
            if not artifact:
                raise Exception("Build failed")
            
            # Ã‰tape 2: Tests
            test_start = time.time()
            test_results = await self._test_stage(config, artifact)
            metrics.test_time_seconds = time.time() - test_start
            
            if not test_results.get("success"):
                raise Exception(f"Tests failed: {test_results.get('errors')}")
            
            # Ã‰tape 3: DÃ©ploiement
            deploy_start = time.time()
            deployment_result = await self._deployment_stage(config, artifact)
            metrics.deployment_time_seconds = time.time() - deploy_start
            
            if not deployment_result.get("success"):
                raise Exception(f"Deployment failed: {deployment_result.get('error')}")
            
            # Ã‰tape 4: Health checks
            health_results = await self._health_check_stage(config)
            metrics.health_check_results = health_results
            
            if not all(h.get("success", False) for h in health_results):
                # Rollback automatique
                await self._rollback_stage(config)
                raise Exception("Health checks failed, rollback executed")
            
            metrics.success_rate = 1.0
            self.manager.logger.info(f"âœ… Pipeline complÃ©tÃ©: {config.name}")
            
        except Exception as e:
            self.manager.logger.error(f"âŒ Pipeline failed: {e}")
            metrics.success_rate = 0.0
            
        finally:
            metrics.total_time_seconds = time.time() - start_time
            if pipeline_id in self.running_pipelines:
                del self.running_pipelines[pipeline_id]
        
        return metrics
    
    async def _build_stage(self, config: DeploymentConfig) -> Optional[BuildArtifact]:
        """Ã‰tape build avec optimisations"""
        self.manager.logger.info(f"ğŸ”¨ Build stage: {config.application}")
        
        try:
            # Simulation build (en production: intÃ©gration Docker/Build tools)
            build_commands = config.build_config.get("commands", [])
            
            # ExÃ©cution build
            for command in build_commands:
                self.manager.logger.debug(f"Executing: {command}")
                # await self._execute_command(command)
            
            # CrÃ©ation artefact
            artifact = BuildArtifact(
                artifact_id=str(uuid.uuid4()),
                deployment_id=config.deployment_id,
                type=config.build_config.get("artifact_type", "docker_image"),
                location=f"/artifacts/{config.application}:{config.version}",
                checksum=hashlib.sha256(f"{config.application}:{config.version}".encode()).hexdigest(),
                size_bytes=1024 * 1024 * 100,  # Simulation 100MB
                metadata={"build_config": config.build_config},
                created_at=datetime.now()
            )
            
            return artifact
            
        except Exception as e:
            self.manager.logger.error(f"âŒ Build failed: {e}")
            return None
    
    async def _test_stage(self, config: DeploymentConfig, 
                         artifact: BuildArtifact) -> Dict[str, Any]:
        """Ã‰tape tests automatisÃ©s"""
        self.manager.logger.info(f"ğŸ§ª Test stage: {config.application}")
        
        try:
            test_config = config.deployment_config.get("tests", {})
            test_types = test_config.get("types", ["unit", "integration"])
            
            results = {"success": True, "tests": {}, "errors": []}
            
            for test_type in test_types:
                # Simulation exÃ©cution tests
                test_result = {
                    "type": test_type,
                    "passed": 95,
                    "failed": 2,
                    "skipped": 3,
                    "success": True
                }
                results["tests"][test_type] = test_result
            
            # VÃ©rification seuils qualitÃ©
            quality_gate = test_config.get("quality_gate", {"min_coverage": 80})
            if quality_gate.get("min_coverage", 0) > 85:  # Simulation
                results["errors"].append("Coverage below threshold")
                results["success"] = False
            
            return results
            
        except Exception as e:
            return {"success": False, "errors": [str(e)]}
    
    async def _deployment_stage(self, config: DeploymentConfig, 
                               artifact: BuildArtifact) -> Dict[str, Any]:
        """Ã‰tape dÃ©ploiement selon stratÃ©gie"""
        self.manager.logger.info(f"ğŸš€ Deployment stage: {config.strategy.value}")
        
        try:
            if config.strategy == DeploymentStrategy.ROLLING:
                return await self._rolling_deployment(config, artifact)
            elif config.strategy == DeploymentStrategy.BLUE_GREEN:
                return await self._blue_green_deployment(config, artifact)
            elif config.strategy == DeploymentStrategy.CANARY:
                return await self._canary_deployment(config, artifact)
            else:
                return await self._standard_deployment(config, artifact)
                
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _rolling_deployment(self, config: DeploymentConfig, 
                                 artifact: BuildArtifact) -> Dict[str, Any]:
        """DÃ©ploiement rolling mise Ã  jour progressive"""
        instances = config.deployment_config.get("instances", 3)
        batch_size = config.deployment_config.get("batch_size", 1)
        
        for i in range(0, instances, batch_size):
            batch_end = min(i + batch_size, instances)
            self.manager.logger.info(f"Deploying batch {i+1}-{batch_end}/{instances}")
            
            # Simulation dÃ©ploiement batch
            await asyncio.sleep(0.5)  # Simulation temps dÃ©ploiement
            
            # Health check batch
            # await self._check_batch_health(i, batch_end)
        
        return {"success": True, "strategy": "rolling", "instances": instances}
    
    async def _blue_green_deployment(self, config: DeploymentConfig, 
                                   artifact: BuildArtifact) -> Dict[str, Any]:
        """DÃ©ploiement blue-green"""
        current_env = config.deployment_config.get("current_environment", "blue")
        target_env = "green" if current_env == "blue" else "blue"
        
        self.manager.logger.info(f"Blue-Green: {current_env} -> {target_env}")
        
        # DÃ©ploiement environnement cible
        # await self._deploy_to_environment(target_env, artifact)
        
        # Basculement trafic
        # await self._switch_traffic(current_env, target_env)
        
        return {"success": True, "strategy": "blue_green", "target_environment": target_env}
    
    async def _canary_deployment(self, config: DeploymentConfig, 
                               artifact: BuildArtifact) -> Dict[str, Any]:
        """DÃ©ploiement canary progressif"""
        traffic_percentages = config.deployment_config.get("canary_stages", [10, 25, 50, 100])
        
        for percentage in traffic_percentages:
            self.manager.logger.info(f"Canary stage: {percentage}% traffic")
            
            # DÃ©ploiement canary
            # await self._deploy_canary(artifact, percentage)
            
            # Monitoring mÃ©triques
            # metrics = await self._monitor_canary_metrics()
            
            # Pause observation
            await asyncio.sleep(1)  # Simulation observation
        
        return {"success": True, "strategy": "canary", "stages": traffic_percentages}
    
    async def _standard_deployment(self, config: DeploymentConfig, 
                                 artifact: BuildArtifact) -> Dict[str, Any]:
        """DÃ©ploiement standard"""
        # Simulation dÃ©ploiement direct
        await asyncio.sleep(0.5)
        return {"success": True, "strategy": "standard"}
    
    async def _health_check_stage(self, config: DeploymentConfig) -> List[Dict[str, Any]]:
        """Ã‰tape health checks"""
        health_checks = config.health_checks or []
        results = []
        
        for check in health_checks:
            check_type = check.get("type", "http")
            result = await self._execute_health_check(check)
            results.append(result)
        
        return results
    
    async def _execute_health_check(self, check: Dict[str, Any]) -> Dict[str, Any]:
        """ExÃ©cution health check spÃ©cifique"""
        check_type = check.get("type", "http")
        
        if check_type == "http":
            url = check.get("url", "http://localhost/health")
            timeout = check.get("timeout", 30)
            
            # Simulation health check HTTP
            await asyncio.sleep(0.1)
            
            return {
                "type": "http",
                "url": url,
                "success": True,
                "status_code": 200,
                "response_time_ms": 45
            }
        
        elif check_type == "tcp":
            host = check.get("host", "localhost")
            port = check.get("port", 8080)
            
            return {
                "type": "tcp",
                "host": host,
                "port": port,
                "success": True,
                "connection_time_ms": 12
            }
        
        return {"type": check_type, "success": False, "error": "Unknown check type"}
    
    async def _rollback_stage(self, config: DeploymentConfig):
        """Ã‰tape rollback automatique"""
        self.manager.logger.warning(f"ğŸ”„ Rollback: {config.application}")
        
        rollback_config = config.rollback_config or {}
        strategy = rollback_config.get("strategy", "previous_version")
        
        if strategy == "previous_version":
            # Rollback vers version prÃ©cÃ©dente
            pass
        elif strategy == "blue_green_switch":
            # Basculement environnement
            pass
        
        # Simulation rollback
        await asyncio.sleep(0.3)

class AgentDeploymentManager_Enterprise:
    """
    ğŸš€ Agent Deployment Manager - Enterprise NextGeneration v5.3.0
    
    Gestionnaire dÃ©ploiement CI/CD intelligent avec automation et optimisation IA.
    
    Patterns NextGeneration v5.3.0:
    - DEPLOYMENT_AUTOMATION: CI/CD pipeline intelligent
    - CI_CD: IntÃ©gration et dÃ©ploiement continus
    - LLM_ENHANCED: Optimisation et risk assessment IA
    - PATTERN_FACTORY: Architecture modulaire Ã©prouvÃ©e
    """
    
    def __init__(self, agent_id: str = "deployment_manager", 
                 workspace_root: Path = None):
        # MÃ©tadonnÃ©es NextGeneration v5.3.0
        self.agent_id = agent_id
        self.version = "5.3.0"
        self.wave_version = "Wave 4 - Extensions Core"
        self.migration_status = "modern_active"
        self.compatibility_mode = True
        
        # Patterns NextGeneration appliquÃ©s
        self.__version__ = "5.3.0"
        self.__wave_version__ = "Wave 4 - Extensions Core"
        self.__nextgen_patterns__ = [
            "DEPLOYMENT_AUTOMATION",
            "CI_CD",
            "LLM_ENHANCED",
            "PATTERN_FACTORY"
        ]
        
        # Configuration agent
        self.name = "Deployment Manager Enterprise"
        self.mission = "CI/CD automation intelligent avec optimisation IA"
        self.agent_type = "deployment_enterprise"
        
        # Configuration workspace
        self.workspace_root = workspace_root or Path("/var/lib/nextgeneration/deployments")
        self.workspace_root.mkdir(parents=True, exist_ok=True)
        
        # Services NextGeneration (injectÃ©s Ã  l'initialisation)
        self.llm_gateway: Optional[LLMGatewayHybrid] = None
        self.message_bus: Optional[MessageBusA2A] = None
        self.context_store: Optional[OptimizedContextStore] = None
        
        # Composants deployment intelligents
        self.optimizer = IntelligentDeploymentOptimizer()
        self.cicd_pipeline = CICDPipeline(self)
        
        # Configuration deployment
        self.deployment_config = {
            "max_concurrent_deployments": 3,
            "default_timeout_minutes": 30,
            "retry_attempts": 2,
            "health_check_timeout": 60,
            "rollback_enabled": True,
            "ai_optimization_enabled": True
        }
        
        # Ã‰tat deployments
        self.active_deployments: Dict[str, DeploymentConfig] = {}
        self.deployment_history: List[DeploymentMetrics] = []
        self.artifacts: Dict[str, BuildArtifact] = {}
        
        # MÃ©triques deployment
        self.deployment_metrics = {
            "deployments_total": 0,
            "deployments_successful": 0,
            "deployments_failed": 0,
            "average_deployment_time_minutes": 0.0,
            "success_rate": 0.0,
            "rollbacks_count": 0,
            "ai_optimizations_applied": 0
        }
        
        # Background tasks
        self._scheduler_task = None
        self._monitor_task = None
        
        # Setup logging
        self._setup_logging()
        
        # DÃ©marrage background tasks
        asyncio.create_task(self._start_background_tasks())
    
    def _setup_logging(self):
        """Configuration logging NextGeneration"""
        try:
            from core.manager import LoggingManager
            logging_manager = LoggingManager()
            self.logger = logging_manager.get_logger(
                config_name="deployment",
                custom_config={
                    "logger_name": f"nextgen.deployment.manager.{self.agent_id}",
                    "log_dir": "logs/deployment",
                    "metadata": {
                        "agent_type": "deployment_manager",
                        "agent_role": "ci_cd",
                        "system": "nextgeneration"
                    }
                }
            )
        except ImportError:
            # Fallback logging
            logging.basicConfig(
                level=logging.INFO,
                format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
            )
            self.logger = logging.getLogger(f"DeploymentManager_{self.agent_id}")
    
    async def inject_nextgen_services(self, 
                                    llm_gateway: LLMGatewayHybrid,
                                    message_bus: MessageBusA2A, 
                                    context_store: OptimizedContextStore):
        """Injection des services NextGeneration v5.3.0"""
        self.llm_gateway = llm_gateway
        self.message_bus = message_bus  
        self.context_store = context_store
        
        # Configuration composants avec IA
        self.optimizer.llm_gateway = llm_gateway
        
        # Configuration contexte deployment IA
        await self._setup_deployment_context()
        
        self.logger.info("âœ… Services NextGeneration injectÃ©s - Deployment IA actif")
    
    async def _setup_deployment_context(self):
        """Configuration contexte deployment IA spÃ©cialisÃ©"""
        if not self.llm_gateway:
            return
        
        deployment_context = {
            "role": "deployment_automation_expert",
            "domain": "enterprise_ci_cd_deployment",
            "capabilities": [
                "CI/CD pipeline optimization",
                "Deployment strategy selection",
                "Risk assessment automation",
                "Performance optimization",
                "Rollback automation"
            ],
            "patterns": [
                "DEPLOYMENT_AUTOMATION",
                "CI_CD",
                "LLM_ENHANCED"
            ]
        }
        
        # Chargement expertise deployment depuis LLM
        try:
            response = await self.llm_gateway.process_request(
                "Load deployment automation expertise",
                context=deployment_context
            )
            
            if response.get("success"):
                self.logger.info("ğŸ§  Expertise deployment IA chargÃ©e")
        except Exception as e:
            self.logger.warning(f"âš ï¸ Erreur chargement contexte IA: {e}")
    
    async def create_deployment(self, config_data: Dict[str, Any]) -> Optional[str]:
        """CrÃ©ation dÃ©ploiement avec optimisation IA"""
        try:
            # CrÃ©ation configuration
            config = DeploymentConfig(
                deployment_id=str(uuid.uuid4()),
                name=config_data["name"],
                application=config_data["application"],
                version=config_data["version"],
                environment=Environment(config_data["environment"]),
                strategy=DeploymentStrategy(config_data.get("strategy", "ROLLING")),
                source_branch=config_data["source_branch"],
                build_config=config_data.get("build_config", {}),
                deployment_config=config_data.get("deployment_config", {}),
                rollback_config=config_data.get("rollback_config"),
                health_checks=config_data.get("health_checks", []),
                notifications=config_data.get("notifications", []),
                created_at=datetime.now()
            )
            
            # Optimisation IA si activÃ©e
            if self.deployment_config["ai_optimization_enabled"]:
                config = await self.optimizer.optimize_deployment_strategy(config)
                self.deployment_metrics["ai_optimizations_applied"] += 1
            
            # Assessment risques
            risk_assessment = await self.optimizer.assess_deployment_risk(config)
            
            if risk_assessment["risk_level"] == "HIGH":
                self.logger.warning(f"âš ï¸ High risk deployment: {config.name}")
                # Notifications risque Ã©levÃ©
                if self.message_bus:
                    await self.message_bus.publish(
                        create_envelope(
                            message_type=MessageType.ALERT,
                            payload={
                                "type": "high_risk_deployment",
                                "deployment_id": config.deployment_id,
                                "risk_assessment": risk_assessment,
                                "timestamp": datetime.now().isoformat()
                            },
                            priority=Priority.HIGH
                        )
                    )
            
            # Enregistrement deployment
            self.active_deployments[config.deployment_id] = config
            self.logger.info(f"ğŸš€ Deployment crÃ©Ã©: {config.name} ({config.deployment_id})")
            
            return config.deployment_id
            
        except Exception as e:
            self.logger.error(f"âŒ Erreur crÃ©ation deployment: {e}")
            return None
    
    async def execute_deployment(self, deployment_id: str) -> Optional[DeploymentMetrics]:
        """ExÃ©cution dÃ©ploiement CI/CD"""
        if deployment_id not in self.active_deployments:
            self.logger.error(f"âŒ Deployment non trouvÃ©: {deployment_id}")
            return None
        
        config = self.active_deployments[deployment_id]
        
        try:
            # VÃ©rification limite concurrence
            if len([d for d in self.active_deployments.values() 
                   if hasattr(d, 'status') and d.status == DeploymentStatus.DEPLOYING]) >= self.deployment_config["max_concurrent_deployments"]:
                self.logger.warning(f"âš ï¸ Max concurrent deployments reached")
                return None
            
            # ExÃ©cution pipeline
            metrics = await self.cicd_pipeline.execute_pipeline(config)
            
            # Mise Ã  jour mÃ©triques globales
            self.deployment_metrics["deployments_total"] += 1
            
            if metrics.success_rate > 0.8:
                self.deployment_metrics["deployments_successful"] += 1
            else:
                self.deployment_metrics["deployments_failed"] += 1
                if metrics.rollback_time_seconds > 0:
                    self.deployment_metrics["rollbacks_count"] += 1
            
            self._update_average_deployment_time(metrics.total_time_seconds / 60)
            
            # Stockage historique
            self.deployment_history.append(metrics)
            self.optimizer.deployment_history.append({
                "deployment_id": deployment_id,
                "application": config.application,
                "environment": config.environment.value,
                "strategy": config.strategy.value,
                "success": metrics.success_rate > 0.8,
                "duration": metrics.total_time_seconds
            })
            
            # Notification completion
            if self.message_bus:
                await self.message_bus.publish(
                    create_envelope(
                        message_type=MessageType.STATUS,
                        payload={
                            "type": "deployment_completed",
                            "deployment_id": deployment_id,
                            "success": metrics.success_rate > 0.8,
                            "metrics": asdict(metrics),
                            "timestamp": datetime.now().isoformat()
                        },
                        priority=Priority.MEDIUM
                    )
                )
            
            return metrics
            
        except Exception as e:
            self.logger.error(f"âŒ Erreur exÃ©cution deployment {deployment_id}: {e}")
            return None
    
    async def rollback_deployment(self, deployment_id: str) -> bool:
        """Rollback dÃ©ploiement"""
        if deployment_id not in self.active_deployments:
            return False
        
        config = self.active_deployments[deployment_id]
        
        try:
            self.logger.info(f"ğŸ”„ Rollback deployment: {config.name}")
            
            # ExÃ©cution rollback
            await self.cicd_pipeline._rollback_stage(config)
            
            # Mise Ã  jour mÃ©triques
            self.deployment_metrics["rollbacks_count"] += 1
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ Erreur rollback: {e}")
            return False
    
    async def _start_background_tasks(self):
        """DÃ©marrage tÃ¢ches background"""
        self._scheduler_task = asyncio.create_task(self._deployment_scheduler())
        self._monitor_task = asyncio.create_task(self._deployment_monitor())
    
    async def _deployment_scheduler(self):
        """Scheduler dÃ©ploiements"""
        while True:
            try:
                await asyncio.sleep(30)  # VÃ©rification toutes les 30s
                
                # Traitement queue dÃ©ploiements
                # En production: intÃ©gration avec systÃ¨me scheduling
                
            except Exception as e:
                self.logger.error(f"âŒ Erreur scheduler: {e}")
    
    async def _deployment_monitor(self):
        """Monitoring dÃ©ploiements actifs"""
        while True:
            try:
                await asyncio.sleep(60)  # Monitoring chaque minute
                
                # Monitoring santÃ© dÃ©ploiements
                for deployment_id, config in self.active_deployments.items():
                    if hasattr(config, 'status') and config.status == DeploymentStatus.DEPLOYED:
                        # VÃ©rification santÃ© continue
                        health_results = await self.cicd_pipeline._health_check_stage(config)
                        
                        if not all(h.get("success", False) for h in health_results):
                            self.logger.warning(f"âš ï¸ Health degradation detected: {deployment_id}")
                            
                            # Alert santÃ© dÃ©gradÃ©e
                            if self.message_bus:
                                await self.message_bus.publish(
                                    create_envelope(
                                        message_type=MessageType.ALERT,
                                        payload={
                                            "type": "deployment_health_degradation",
                                            "deployment_id": deployment_id,
                                            "health_results": health_results,
                                            "timestamp": datetime.now().isoformat()
                                        },
                                        priority=Priority.HIGH
                                    )
                                )
                    
            except Exception as e:
                self.logger.error(f"âŒ Erreur monitoring: {e}")
    
    def _update_average_deployment_time(self, deployment_time_minutes: float):
        """Mise Ã  jour temps dÃ©ploiement moyen"""
        count = self.deployment_metrics["deployments_total"]
        avg = self.deployment_metrics["average_deployment_time_minutes"]
        
        self.deployment_metrics["average_deployment_time_minutes"] = (
            (avg * (count - 1) + deployment_time_minutes) / count
        )
        
        # Mise Ã  jour success rate
        total = self.deployment_metrics["deployments_total"]
        successful = self.deployment_metrics["deployments_successful"]
        self.deployment_metrics["success_rate"] = (successful / max(1, total)) * 100
    
    async def get_deployment_stats(self) -> Dict[str, Any]:
        """Statistiques deployment dÃ©taillÃ©es"""
        return {
            "deployment_metrics": self.deployment_metrics,
            "active_deployments": len(self.active_deployments),
            "deployment_history_count": len(self.deployment_history),
            "artifacts_count": len(self.artifacts),
            "patterns": self.__nextgen_patterns__,
            "version": self.version,
            "timestamp": datetime.now().isoformat()
        }
    
    async def health_check(self) -> Dict[str, Any]:
        """Health check NextGeneration"""
        return {
            "agent_id": self.agent_id,
            "version": self.version,
            "status": "healthy",
            "patterns": self.__nextgen_patterns__,
            "services": {
                "llm_gateway": self.llm_gateway is not None,
                "message_bus": self.message_bus is not None,
                "context_store": self.context_store is not None
            },
            "deployment": {
                "active_deployments": len(self.active_deployments),
                "deployments_total": self.deployment_metrics["deployments_total"],
                "success_rate": self.deployment_metrics["success_rate"],
                "ai_optimizations": self.deployment_metrics["ai_optimizations_applied"]
            },
            "timestamp": datetime.now().isoformat()
        }

# Factory function pour compatibilitÃ©
def create_deployment_manager(**config) -> AgentDeploymentManager_Enterprise:
    """Factory function pour crÃ©er l'agent"""
    return AgentDeploymentManager_Enterprise(**config)

# Test standalone
async def main():
    """Test de l'agent Deployment Manager"""
    print("ğŸš€ Test Agent Deployment Manager NextGeneration v5.3.0")
    
    agent = create_deployment_manager(agent_id="test_deployment")
    
    # Health check
    health = await agent.health_check()
    print(f"ğŸ¥ Health: {health['status']}")
    
    # CrÃ©ation dÃ©ploiement test
    deployment_config = {
        "name": "Test App Deployment",
        "application": "test-app",
        "version": "1.2.3",
        "environment": "STAGING",
        "strategy": "ROLLING",
        "source_branch": "main",
        "build_config": {
            "commands": ["npm install", "npm run build"],
            "artifact_type": "docker_image"
        },
        "deployment_config": {
            "instances": 3,
            "batch_size": 1
        },
        "health_checks": [
            {"type": "http", "url": "http://localhost:8080/health"}
        ]
    }
    
    deployment_id = await agent.create_deployment(deployment_config)
    if deployment_id:
        print(f"ğŸš€ Deployment crÃ©Ã©: {deployment_id}")
        
        # ExÃ©cution dÃ©ploiement
        metrics = await agent.execute_deployment(deployment_id)
        if metrics:
            print(f"âœ… Deployment complÃ©tÃ© en {metrics.total_time_seconds:.1f}s")
    
    # Statistiques
    stats = await agent.get_deployment_stats()
    print(f"ğŸ“Š Deployments total: {stats['deployment_metrics']['deployments_total']}")

if __name__ == "__main__":
    asyncio.run(main())