"""
üîí ANALYSEUR DE S√âCURIT√â - Agent 09
====================================

ÔøΩÔøΩ Mission : D√©tecter et analyser les vuln√©rabilit√©s de s√©curit√© dans le code et les syst√®mes.
‚ö° Capacit√©s : 
- Analyse statique de code Python
- Audit de s√©curit√© universel de fichiers/r√©pertoires
- D√©tection de secrets et donn√©es sensibles
- Analyse des d√©pendances et configurations
- G√©n√©ration de rapports d√©taill√©s
- Recommandations de correction automatis√©es

üè¢ √âquipe : NextGeneration Tools Migration
üìä Int√©gration : Compatible avec le syst√®me de logging centralis√©

Author: √âquipe de Maintenance NextGeneration
Version: 2.0.0 (S√©curit√© renforc√©e)
"""

import ast
import re
import hashlib
import logging
import json
import uuid
import os
import sys
from typing import List, Dict, Any, Optional, Union, Set
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass, asdict, field
from enum import Enum
import subprocess
from concurrent.futures import ThreadPoolExecutor
import asyncio
import yaml

from core.agent_factory_architecture import Agent, Task, Result
# Gestion du logging avec fallback
try:
    from core.manager import LoggingManager
except ImportError:
    LoggingManager = None

# Imports optionnels pour fonctionnalit√©s avanc√©es
try:
    import bandit
    BANDIT_AVAILABLE = True
except ImportError:
    BANDIT_AVAILABLE = False

try:
    from safety import safety
    SAFETY_CHECK_AVAILABLE = True
except ImportError:
    SAFETY_CHECK_AVAILABLE = False

# --- D√©but: √âl√©ments int√©gr√©s depuis Agent 18 ---
class SecurityLevel(Enum):
    """Niveaux de s√©curit√© √©tendus"""
    CRITICAL = "critique"
    HIGH = "haut"
    MEDIUM = "moyen"
    LOW = "bas"
    INFO = "information"
    SECURE = "s√©curis√©"

    @classmethod
    def from_cvss(cls, score: float) -> 'SecurityLevel':
        """Convertit un score CVSS en niveau de s√©curit√©"""
        if score >= 9.0: return cls.CRITICAL
        elif score >= 7.0: return cls.HIGH
        elif score >= 4.0: return cls.MEDIUM
        elif score >= 0.1: return cls.LOW
        return cls.INFO

class VulnerabilityType(Enum):
    """Types de vuln√©rabilit√©s √©tendus"""
    # Vuln√©rabilit√©s OWASP Top 10
    INJECTION = "injection"
    XSS = "xss"
    BROKEN_AUTH = "authentification_cass√©e"
    SENSITIVE_DATA = "donn√©es_sensibles"
    XXE = "xxe"
    BROKEN_ACCESS = "contr√¥le_acc√®s_cass√©"
    MISCONFIGURATION = "mauvaise_configuration"
    INSECURE_DESERIALIZATION = "d√©s√©rialisation_non_s√©curis√©e"
    VULNERABLE_COMPONENTS = "composants_vuln√©rables"
    INSUFFICIENT_LOGGING = "journalisation_insuffisante"
    
    # Vuln√©rabilit√©s sp√©cifiques
    HARDCODED_SECRET = "secret_en_dur"
    WEAK_CRYPTO = "cryptographie_faible"
    FILE_TRAVERSAL = "travers√©e_de_fichier"
    DANGEROUS_FUNCTION = "fonction_dangereuse"
    PATH_INJECTION = "injection_de_chemin"
    XML_VULNERABILITIES = "vuln√©rabilit√©s_xml"
    INSECURE_PROTOCOLS = "protocoles_non_s√©curis√©s"
    INSECURE_FILE_OPERATION = "operation_fichier_non_securisee"
    INSECURE_FILE_PERMISSION = "permission_fichier_non_securisee"
    BROAD_EXCEPTION = "exception_large"
    ASSERTION_ISSUE = "probleme_assertion"
    
    # Nouvelles cat√©gories
    DEPENDENCY_VULNERABILITY = "vuln√©rabilit√©_d√©pendance"
    CONFIG_VULNERABILITY = "vuln√©rabilit√©_configuration"
    API_VULNERABILITY = "vuln√©rabilit√©_api"
    DOCKER_VULNERABILITY = "vuln√©rabilit√©_docker"
    CI_CD_VULNERABILITY = "vuln√©rabilit√©_ci_cd"
    OTHER = "autre"


@dataclass
class SecurityFinding:
    """R√©sultat d'audit de s√©curit√© enrichi"""
    finding_id: str
    vulnerability_type: VulnerabilityType
    security_level: SecurityLevel
    title: str
    description: str
    location: str
    line_number: Optional[int] = None
    cwe_id: Optional[str] = None
    cvss_score: Optional[float] = None
    remediation: Optional[str] = ""
    evidence: Optional[str] = ""
    context: Optional[Dict[str, Any]] = field(default_factory=dict)
    references: List[str] = field(default_factory=list)
    affected_components: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        """Convertit le finding en dictionnaire"""
        return {
            **asdict(self),
            'vulnerability_type': self.vulnerability_type.value,
            'security_level': self.security_level.value
        }

@dataclass
class SecurityReport:
    """Rapport complet d'audit de s√©curit√© enrichi"""
    audit_id: str
    target: str
    timestamp: datetime
    findings: List[SecurityFinding] = field(default_factory=list)
    security_score: float = 10.0
    compliance_status: Dict[str, bool] = field(default_factory=dict)
    recommendations: List[str] = field(default_factory=list)
    summary: Dict[str, int] = field(default_factory=dict)
    context: Optional[Dict[str, Any]] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def add_finding(self, finding: SecurityFinding):
        """Ajoute un finding et met √† jour le score"""
        self.findings.append(finding)
        self._update_score()
        self._update_summary()
    
    def _update_score(self):
        """Met √† jour le score de s√©curit√©"""
        if not self.findings:
            self.security_score = 10.0
            return
        
        weights = {
            SecurityLevel.CRITICAL: 1.0,
            SecurityLevel.HIGH: 0.7,
            SecurityLevel.MEDIUM: 0.4,
            SecurityLevel.LOW: 0.2,
            SecurityLevel.INFO: 0.1
        }
        
        total_weight = sum(weights[f.security_level] for f in self.findings)
        self.security_score = max(0.0, 10.0 - total_weight)
    
    def _update_summary(self):
        """Met √† jour le r√©sum√© des findings"""
        self.summary = {level.value: 0 for level in SecurityLevel}
        for finding in self.findings:
            self.summary[finding.security_level.value] += 1
    
    def to_dict(self) -> Dict[str, Any]:
        """Convertit le rapport en dictionnaire"""
        return {
            'audit_id': self.audit_id,
            'target': self.target,
            'timestamp': self.timestamp.isoformat(),
            'findings': [f.to_dict() for f in self.findings],
            'security_score': self.security_score,
            'compliance_status': self.compliance_status,
            'recommendations': self.recommendations,
            'summary': self.summary,
            'metadata': self.metadata
        }

# --- Fin: √âl√©ments int√©gr√©s depuis Agent 18 ---


class AgentMAINTENANCE09AnalyseurSecurite(Agent):
    """
    Agent avanc√© charg√© de la s√©curit√© du code Python et des audits universels:
    - D√©tection des vuln√©rabilit√©s de s√©curit√© communes
    - Identification des pratiques non s√©curis√©es
    - Analyse des injections potentielles
    - V√©rification de l'usage s√©curis√© des fonctions
    - Analyse des patterns de gestion des secrets
    - Audit de s√©curit√© des fichiers et r√©pertoires
    - Analyse des d√©pendances et configurations
    - Int√©gration avec des outils tiers (Bandit, Safety)
    """

    def __init__(self, **kwargs):
        super().__init__(agent_type="security_analyzer", **kwargs)
        self.agent_id = "agent_MAINTENANCE_09_Analyseur_Securite"
        self.version = "2.0.0"
        self.description = "Agent avanc√© d'analyse et de s√©curisation du code"
        self.status = "enabled"
        self._setup_logging()

        # Configuration de base
        self.workspace_root = Path(kwargs.get('workspace_root', os.getcwd()))
        self.excluded_paths = {
            '.git', '__pycache__', 'node_modules', 'venv',
            'env', '.env', '.venv', 'dist', 'build'
        }
        
        # Patterns de s√©curit√© √©tendus
        self._init_security_patterns()
        
        # Base de donn√©es des rapports
        self.security_reports_db = {}
        
        # Configuration des analyses
        self.config = {
            'max_file_size': 1024 * 1024,  # 1MB
            'max_files_per_scan': 1000,
            'enable_bandit': BANDIT_AVAILABLE,
            'enable_safety': SAFETY_CHECK_AVAILABLE,
            'parallel_scans': True,
            'max_workers': 4
        }

    def _init_security_patterns(self):
        """Initialise les patterns de s√©curit√© √©tendus"""
        # Fonctions dangereuses
        self.dangerous_functions = {
            'eval': {
                'severity': 'CRITICAL',
                'reason': 'Ex√©cution de code arbitraire',
                'alternatives': 'ast.literal_eval() pour donn√©es s√ªres',
                'cwe': 'CWE-95'
            },
            'exec': {
                'severity': 'CRITICAL',
                'reason': 'Ex√©cution de code arbitraire',
                'alternatives': 'Restructurer le code',
                'cwe': 'CWE-95'
            },
            'compile': {
                'severity': 'HIGH',
                'reason': 'Compilation de code potentiellement malveillant',
                'alternatives': 'Valider les entr√©es',
                'cwe': 'CWE-94'
            },
            '__import__': {
                'severity': 'HIGH',
                'reason': 'Import dynamique non contr√¥l√©',
                'alternatives': 'importlib avec validation',
                'cwe': 'CWE-470'
            }
        }

        # Modules dangereux
        self.dangerous_modules = {
            'os.system': {
                'severity': 'CRITICAL',
                'reason': 'Injection de commandes shell',
                'alternatives': 'subprocess.run() avec shell=False',
                'cwe': 'CWE-78'
            },
            'subprocess.call': {
                'severity': 'HIGH',
                'reason': 'Injection potentielle si shell=True',
                'alternatives': 'subprocess.run() avec liste arguments',
                'cwe': 'CWE-78'
            },
            'pickle.loads': {
                'severity': 'HIGH',
                'reason': 'D√©s√©rialisation non s√©curis√©e',
                'alternatives': 'json ou validation pickle',
                'cwe': 'CWE-502'
            },
            'yaml.load': {
                'severity': 'HIGH',
                'reason': 'D√©s√©rialisation YAML non s√©curis√©e',
                'alternatives': 'yaml.safe_load()',
                'cwe': 'CWE-502'
            }
        }

        # Patterns de secrets
        self.secret_patterns = {
            'api_key': {
                'pattern': r'(?i)(api[_-]key|apikey|api[_-]token)["\s]*[:=]["\s]*([\'"][^\'\"]+[\'"])',
                'severity': 'HIGH',
                'cwe': 'CWE-798'
            },
            'password': {
                'pattern': r'(?i)(password|passwd|pwd)["\s]*[:=]["\s]*([\'"][^\'\"]+[\'"])',
                'severity': 'HIGH',
                'cwe': 'CWE-798'
            },
            'private_key': {
                'pattern': r'-----BEGIN.*PRIVATE KEY-----',
                'severity': 'CRITICAL',
                'cwe': 'CWE-798'
            },
            'token': {
                'pattern': r'(?i)(token|secret|auth)["\s]*[:=]["\s]*([\'"][^\'\"]+[\'"])',
                'severity': 'HIGH',
                'cwe': 'CWE-798'
            }
        }

        # Patterns d'injection
        self.injection_patterns = {
            'sql': {
                'patterns': [
                    r'execute\s*\(\s*["\'].*%s.*["\']',
                    r'execute\s*\(\s*f["\'].*\{.*\}.*["\']',
                    r'cursor\.execute\s*\(\s*["\'].*\+.*["\']'
                ],
                'severity': 'CRITICAL',
                'cwe': 'CWE-89'
            },
            'command': {
                'patterns': [
                    r'subprocess\.call\s*\(\s*.*shell\s*=\s*True',
                    r'os\.system\s*\(\s*["\'].*\+.*["\']',
                    r'os\.popen\s*\(\s*["\'].*\+.*["\']'
                ],
                'severity': 'CRITICAL',
                'cwe': 'CWE-78'
            },
            'path': {
                'patterns': [
                    r'open\s*\(\s*["\'].*\+.*["\']',
                    r'os\.path\.join\s*\(\s*.*\+.*\)',
                    r'pathlib\.Path\s*\(\s*.*\+.*\)'
                ],
                'severity': 'HIGH',
                'cwe': 'CWE-73'
            }
        }

        # Patterns de configuration
        self.config_patterns = {
            'debug': {
                'pattern': r'(?i)(DEBUG|DEVELOPMENT|TEST)["\s]*[:=]["\s]*True',
                'severity': 'MEDIUM',
                'cwe': 'CWE-489'
            },
            'cors': {
                'pattern': r'(?i)(CORS_ALLOW_ALL|ALLOW_ALL_ORIGINS)["\s]*[:=]["\s]*True',
                'severity': 'HIGH',
                'cwe': 'CWE-942'
            },
            'ssl_verify': {
                'pattern': r'(?i)(VERIFY_SSL|SSL_VERIFY)["\s]*[:=]["\s]*False',
                'severity': 'HIGH',
                'cwe': 'CWE-295'
            }
        }

    def _setup_logging(self):
        """Configure le syst√®me de logging avec fallback"""
        if LoggingManager:
            try:
                logging_manager = LoggingManager()
                custom_log_config = {
                    "logger_name": f"agent.{self.agent_id.replace('_', '.').lower()}",
                    "metadata": {
                        "agent_name": self.agent_id,
                        "role": "security_analyzer",
                        "domain": "security_audit",
                        "version": self.version
                    },
                    "async_enabled": True
                }
                self.logger = logging_manager.get_logger(
                    config_name="default",
                    custom_config=custom_log_config
                )
                self.logger.info(f"Logging centralis√© configur√© pour {self.agent_id}")
            except Exception as e:
                self.logger = logging.getLogger(self.__class__.__name__)
                self.logger.warning(f"Fallback sur logging standard: {e}")
        else:
            self.logger = logging.getLogger(self.__class__.__name__)
            self.logger.info("Logging standard configur√© (LoggingManager non trouv√©)")

    async def startup(self):
        """Initialisation de l'agent"""
        await super().startup()
        self.logger.info(f"{self.agent_id} v{self.version} d√©marr√©")
        
        # V√©rification des d√©pendances
        if BANDIT_AVAILABLE:
            self.logger.info("Bandit disponible pour analyse approfondie")
        if SAFETY_CHECK_AVAILABLE:
            self.logger.info("Safety disponible pour analyse des d√©pendances")
            
        # Cr√©ation du contexte de s√©curit√©
        self.security_context = SecurityContext(
            workspace_root=self.workspace_root,
            current_file=None,
            excluded_paths=self.excluded_paths
        )
        
        self.logger.info("Agent pr√™t pour les analyses de s√©curit√©")

    async def execute_task(self, task: Task) -> Result:
        """Ex√©cute une t√¢che d'analyse de s√©curit√©"""
        self.logger.info(f"Ex√©cution de la t√¢che: {task.type} (ID: {task.id})")
        
        try:
            if task.type == "security_scan":
                return await self._handle_security_scan(task)
            elif task.type == "audit_universel_securite":
                return await self._handle_universal_audit(task)
            elif task.type == "dependency_check":
                return await self._handle_dependency_check(task)
            elif task.type == "config_audit":
                return await self._handle_config_audit(task)
            else:
                self.logger.warning(f"Type de t√¢che non support√©: {task.type}")
                return Result(success=False, error=f"Type de t√¢che non support√©: {task.type}")
        except Exception as e:
            self.logger.error(f"Erreur lors de l'ex√©cution de {task.type}: {e}", exc_info=True)
            return Result(success=False, error=str(e))

    async def _handle_security_scan(self, task: Task) -> Result:
        """G√®re l'analyse de s√©curit√© du code"""
        code = task.params.get("code")
        file_path = task.params.get("file_path", "unknown_file")
        
        if not code:
            return Result(success=False, error="Code non fourni")
            
        self.logger.info(f"üîê Analyse de s√©curit√© pour: {file_path}")
        
        try:
            # Analyse AST
            ast_vulnerabilities = await self._analyze_ast_security(code)
            
            # Analyse des patterns
            pattern_vulnerabilities = await self._analyze_text_patterns(code)
            
            # Analyse des secrets
            secret_vulnerabilities = await self._detect_secrets(code)
            
            # Analyse des injections
            injection_vulnerabilities = await self._detect_injections(code)
            
            # Analyse Bandit si disponible
            bandit_vulnerabilities = []
            if self.config['enable_bandit']:
                bandit_vulnerabilities = await self._run_bandit_analysis(code, file_path)
            
            # Combinaison des r√©sultats
            all_vulnerabilities = (
                ast_vulnerabilities +
                pattern_vulnerabilities +
                secret_vulnerabilities +
                injection_vulnerabilities +
                bandit_vulnerabilities
            )
            
            # G√©n√©ration du rapport
            security_score = self._calculate_security_score(all_vulnerabilities)
            recommendations = self._generate_security_recommendations(all_vulnerabilities)
            secured_suggestions = await self._generate_secured_code_suggestions(code, all_vulnerabilities)
            
            report = {
                "file_path": file_path,
                "security_score": security_score,
                "vulnerabilities": all_vulnerabilities,
                "recommendations": recommendations,
                "secured_suggestions": secured_suggestions,
                "total_issues": len(all_vulnerabilities)
            }
            
            self.logger.info(f"Analyse termin√©e - Score: {security_score}/10, Issues: {len(all_vulnerabilities)}")
            return Result(success=True, data=report)
            
        except Exception as e:
            self.logger.error(f"Erreur lors de l'analyse: {e}", exc_info=True)
            return Result(success=False, error=str(e))

    async def _handle_universal_audit(self, task: Task) -> Result:
        """G√®re l'audit universel de s√©curit√©"""
        target_path = task.params.get("target_path")
        if not target_path:
            return Result(success=False, error="Chemin cible non fourni")
            
        self.logger.info(f"üõ°Ô∏è Audit universel pour: {target_path}")
        
        try:
            # Cr√©ation du contexte
            self.security_context.current_file = Path(target_path)
            
            # Ex√©cution de l'audit
            report = await self.auditer_securite_complete(target_path)
            
            # Sauvegarde du rapport
            await self._save_security_report(report)
            
            self.logger.info(f"Audit termin√© - Score: {report.security_score}/10")
            return Result(success=True, data=report.to_dict())
            
        except Exception as e:
            self.logger.error(f"Erreur lors de l'audit: {e}", exc_info=True)
            return Result(success=False, error=str(e))

    async def _handle_dependency_check(self, task: Task) -> Result:
        """G√®re l'analyse des d√©pendances"""
        requirements_file = task.params.get("requirements_file")
        if not requirements_file or not Path(requirements_file).exists():
            return Result(success=False, error="Fichier requirements.txt non trouv√©")
            
        self.logger.info(f"üì¶ Analyse des d√©pendances: {requirements_file}")
        
        try:
            vulnerabilities = []
            
            # Analyse avec Safety si disponible
            if SAFETY_CHECK_AVAILABLE:
                safety_vulns = await self._run_safety_check(requirements_file)
                vulnerabilities.extend(safety_vulns)
            
            # Analyse des versions obsol√®tes
            version_vulns = await self._check_outdated_dependencies(requirements_file)
            vulnerabilities.extend(version_vulns)
            
            report = {
                "file": requirements_file,
                "vulnerabilities": vulnerabilities,
                "total_issues": len(vulnerabilities),
                "recommendations": self._generate_dependency_recommendations(vulnerabilities)
            }
            
            self.logger.info(f"Analyse des d√©pendances termin√©e - {len(vulnerabilities)} probl√®mes trouv√©s")
            return Result(success=True, data=report)
            
        except Exception as e:
            self.logger.error(f"Erreur lors de l'analyse des d√©pendances: {e}", exc_info=True)
            return Result(success=False, error=str(e))

    async def _handle_config_audit(self, task: Task) -> Result:
        """G√®re l'audit des fichiers de configuration"""
        config_path = task.params.get("config_path")
        if not config_path:
            return Result(success=False, error="Chemin de configuration non fourni")
            
        self.logger.info(f"‚öôÔ∏è Audit de configuration: {config_path}")
        
        try:
            # Analyse des fichiers de configuration
            findings = await self._analyze_config_files(config_path)
            
            report = {
                "path": config_path,
                "findings": findings,
                "total_issues": len(findings),
                "recommendations": self._generate_config_recommendations(findings)
            }
            
            self.logger.info(f"Audit de configuration termin√© - {len(findings)} probl√®mes trouv√©s")
            return Result(success=True, data=report)
            
        except Exception as e:
            self.logger.error(f"Erreur lors de l'audit de configuration: {e}", exc_info=True)
            return Result(success=False, error=str(e))

    async def shutdown(self):
        """Arr√™t propre de l'agent"""
        self.logger.info(f"Arr√™t de {self.agent_id}")
        await super().shutdown()

    def get_capabilities(self) -> List[str]:
        """Retourne les capacit√©s de l'agent"""
        capabilities = [
            "security_scan",
            "audit_universel_securite",
            "dependency_check",
            "config_audit"
        ]
        if BANDIT_AVAILABLE:
            capabilities.append("bandit_analysis")
        if SAFETY_CHECK_AVAILABLE:
            capabilities.append("safety_check")
        return capabilities

    async def health_check(self) -> Dict[str, Any]:
        """V√©rifie l'√©tat de l'agent"""
        return {
            "status": "healthy",
            "version": self.version,
            "bandit_available": BANDIT_AVAILABLE,
            "safety_available": SAFETY_CHECK_AVAILABLE
        }


def create_agent_MAINTENANCE_09_analyseur_securite(**kwargs) -> AgentMAINTENANCE09AnalyseurSecurite:
    """Factory function pour cr√©er une instance de l'analyseur de s√©curit√©."""
    return AgentMAINTENANCE09AnalyseurSecurite(**kwargs)


async def main():
    # Cr√©ation de l'agent
    agent = create_agent_MAINTENANCE_09_analyseur_securite()
    await agent.startup()
    agent.logger.info("Agent de test d√©marr√©.")

    # Test 1: Scan de s√©curit√© sur une cha√Æne de code
    sample_code_string = "import os\npassword = 'secret123'\neval('print(1)')\nos.system('ls')"
    task1 = Task(id="test_scan_1", type="security_scan", params={"code": sample_code_string, "file_path": "test_code.py"})
    result1 = await agent.execute_task(task1)
    if result1.success:
        agent.logger.info(f"R√©sultat security_scan: Score {result1.data['security_score']}, {result1.data['total_issues']} issues.")
        # agent.export_security_report_md(result1.data['security_report'], "test_security_scan_report.md")
    else:
        agent.logger.error(f"Erreur security_scan: {result1.error}")

    # Cr√©er un fichier de test pour l'audit universel
    test_dir = Path("temp_audit_dir_agent09")
    test_dir.mkdir(exist_ok=True)
    user_name = "TestUser' OR '1'='1"  # D√©finition de user_name pour le test
    test_file_path = test_dir / "test_vuln_file.py"
    with open(test_file_path, "w", encoding="utf-8") as f:
        f.write("# Fichier de test pour Agent 09\n")
        f.write('api_key = "THIS_IS_A_VERY_SECRET_API_KEY"\n')  # Secret en dur
        f.write("import pickle\n")  # Import dangereux
        f.write("def unsafe_load(data): return pickle.loads(data)\n")  # Utilisation de pickle.loads
        f.write('eval(\'print("eval test")\')\n')  # Utilisation de eval
        f.write(f'db.execute("SELECT * FROM users WHERE name = \'{user_name}\'")\n')  # SQL Injection

    # Test 2: Audit universel de s√©curit√© sur un fichier
    task2 = Task(id="test_audit_file_1", type="audit_universel_securite", params={"target_path": str(test_file_path)})
    result2 = await agent.execute_task(task2)
    if result2.success:
        report_data = result2.data
        agent.logger.info(f"R√©sultat audit_universel_securite (fichier): Score {report_data['security_score']:.1f}/10, {len(report_data['findings'])} d√©couvertes.")
    else:
        agent.logger.error(f"Erreur audit_universel_securite (fichier): {result2.error}")

    # Test 3: Audit universel de s√©curit√© sur un r√©pertoire
    task3 = Task(id="test_audit_dir_1", type="audit_universel_securite", params={"target_path": str(test_dir)})
    result3 = await agent.execute_task(task3)
    if result3.success:
        report_data_dir = result3.data
        agent.logger.info(f"R√©sultat audit_universel_securite (r√©pertoire): Score {report_data_dir['security_score']:.1f}/10, {len(report_data_dir['findings'])} d√©couvertes.")
    else:
        agent.logger.error(f"Erreur audit_universel_securite (r√©pertoire): {result3.error}")

    # Nettoyage
    try:
        # Correction: Importer os pour remove et rmdir
        import os 
        os.remove(test_file_path)
        os.rmdir(test_dir)
        agent.logger.info("Fichiers et r√©pertoire de test nettoy√©s.")
    except OSError as e:
        agent.logger.error(f"Erreur lors du nettoyage des fichiers de test: {e}")
        
    await agent.shutdown()

if __name__ == '__main__':
    import asyncio
    # Configuration du logging de base pour voir les messages de l'agent pendant le test
    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    asyncio.run(main())