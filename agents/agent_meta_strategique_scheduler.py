#!/usr/bin/env python3
"""

# üîß CONVERTI AUTOMATIQUEMENT SYNC ‚Üí ASYNC
# Date: 2025-06-19 19h35 - Correction architecture Pattern Factory
# Raison: Harmonisation async/sync avec core/agent_factory_architecture.py

üöß DRAFT VERSION üöß
Planificateur pour l'Agent M√©ta-Strat√©gique - VERSION DRAFT/PROTOTYPE
Mission: Ex√©cuter p√©riodiquement l'analyse strat√©gique et g√©n√©rer les rapports

‚ö†Ô∏è ATTENTION: CETTE VERSION EST UN PROTOTYPE EN D√âVELOPPEMENT
- Ne pas utiliser en production
- Fonctionnalit√©s en cours de test et validation
- Rapports g√©n√©r√©s √† titre exp√©rimental uniquement

Fonctionnalit√©s:
- Planification automatique des analyses
- Int√©gration avec l'API GitHub pour les m√©triques CI/CD
- Notifications des insights critiques
- Archivage des rapports historiques
"""

import asyncio
import json
import sys
from pathlib import Path
from core import logging_manager
import schedule
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import logging
import time
import importlib

# Import de notre agent m√©ta-strat√©gique
sys.path.insert(0, str(Path(__file__).parent.parent / '20250621_1527_agent_racine_repertoire'))
try:
    from agent_meta_strategique import AgentMetaStrategique
except ImportError as e:
    print(f"ERREUR CRITIQUE: Impossible d'importer AgentMetaStrategique. V√©rifiez le chemin. {e}")
    sys.exit(1)

class AgentMetaStrategiqueScheduler:
    """Planificateur pour l'ex√©cution p√©riodique de l'Agent M√©ta-Strat√©gique"""
    
    def __init__(self, workspace_root: Path = None, config_path: str = "config/meta_strategique_config.json", agent_class_name: str = "Agent111AuditeurQualite", agent_module_path: str = "agents.agent_111_auditeur_qualite", task_method: str = "execute_task", task_params: dict = None):
        
        # ‚úÖ MIGRATION SYST√àME LOGGING UNIFI√â
        try:
            from core.manager import LoggingManager
            logging_manager = LoggingManager()
            self.logger = logging_manager.get_logger(
                config_name="general",
                custom_config={
                    "logger_name": f"nextgen.general.meta_strategique_scheduler.{self.agent_id if hasattr(self, 'agent_id') else self.id if hasattr(self, 'id') else 'unknown'}",
                    "log_dir": "logs/general",
                    "metadata": {
                        "agent_type": "meta_strategique_scheduler",
                        "agent_role": "general",
                        "system": "nextgeneration"
                    }
                }
            )
        except ImportError:
            # Fallback en cas d'indisponibilit√© du LoggingManager
            self.logger = logging.getLogger(self.__class__.__name__)

        self.workspace_root = workspace_root if workspace_root else Path(__file__).parent.parent
        self.config_path = self.workspace_root / config_path
        self.logger = self._setup_logging()
        self.default_config = {
            "execution_schedule": {
                "daily_report": "09:00",
                "weekly_deep_analysis": "MON:08:00",
                "critical_monitoring": 30
            },
            "notifications": {
                "email_enabled": False,
                "email_recipients": [],
                "smtp_server": "smtp.gmail.com",
                "smtp_port": 587,
                "webhook_url": None
            },
            "github_integration": {
                "enabled": False,
                "api_token": None,
                "repo_owner": "nextgeneration",
                "repo_name": "nextgeneration"
            },
            "analysis_settings": {
                "retention_days": 30,
                "critical_threshold": 0.8,
                "archive_reports": True
            }
        }
        self.config = self.load_config()
        self.task_method = task_method
        self.task_params = task_params or {"task": None}
        try:
            agent_module = importlib.import_module(agent_module_path)
            agent_class = getattr(agent_module, agent_class_name)
            self.agent = agent_class(workspace_root=self.workspace_root)
        except Exception as e:
            self.logger.critical(f"Impossible d'instancier {agent_class_name} depuis {agent_module_path}: {e}")
            sys.exit(1)
        self.last_analysis_results = None

    def _setup_logging(self):
        """Configuration du logging pour le scheduler."""
        logger = logging.getLogger(self.__class__.__name__)
        logger.setLevel(logging.INFO)

        if not logger.handlers:
            log_dir = self.workspace_root / "logs" / "agents" / "meta_strategique_scheduler"
            log_dir.mkdir(parents=True, exist_ok=True)
            log_file = log_dir / "scheduler.log"

            # Handler Fichier
            file_handler = logging.FileHandler(log_file, encoding='utf-8')
            file_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
            file_handler.setFormatter(file_formatter)
            logger.addHandler(file_handler)

            # Handler Console
            console_handler = logging.StreamHandler(sys.stdout)
            console_formatter = logging.Formatter('üìÖ (Scheduler) - %(levelname)s - %(message)s')
            console_handler.setFormatter(console_formatter)
            logger.addHandler(console_handler)

        return logger
        
    def load_config(self) -> Dict[str, Any]:
        """Chargement de la configuration"""
        if self.config_path.exists():
            try:
                with open(self.config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    # Fusion avec la config par d√©faut
                    merged_config = self.default_config.copy()
                    merged_config.update(config)
                    return merged_config
            except Exception as e:
                self.logger.error(f"Erreur chargement config: {e}")
        
        # Cr√©er la configuration par d√©faut
        self.save_config(self.default_config)
        return self.default_config
    
    def save_config(self, config: Dict[str, Any]):
        """Sauvegarde de la configuration"""
        self.config_path.parent.mkdir(parents=True, exist_ok=True)
        with open(self.config_path, 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
    
    def start_scheduler(self):
        """D√©marrage du planificateur"""
        self.logger.info("üöß D√©marrage du planificateur Agent M√©ta-Strat√©gique DRAFT/PROTOTYPE")
        
        # Planification des t√¢ches
        self.setup_schedules()
        
        # Ex√©cution imm√©diate pour test
        self.logger.info("üîç Ex√©cution d'analyse initiale...")
        self.execute_daily_analysis()
        
        # Boucle principale
        try:
            while True:
                schedule.run_pending()
                time.sleep(60)  # V√©rification chaque minute
        except KeyboardInterrupt:
            self.logger.info("üõë Arr√™t du planificateur")
    
    def setup_schedules(self):
        """Configuration des planifications"""
        config = self.config["execution_schedule"]
        
        # Rapport quotidien
        daily_time = config["daily_report"]
        schedule.every().day.at(daily_time).do(self.execute_daily_analysis)
        self.logger.info(f"üìÖ Rapport quotidien planifi√© √† {daily_time}")
        
        # Analyse hebdomadaire approfondie
        weekly_schedule = config["weekly_deep_analysis"]
        if ":" in weekly_schedule:
            day, time_str = weekly_schedule.split(":")
            getattr(schedule.every(), day.lower()).at(time_str).do(self.execute_weekly_deep_analysis)
            self.logger.info(f"üìä Analyse hebdomadaire planifi√©e {day} √† {time_str}")
        
        # Monitoring critique
        critical_interval = config["critical_monitoring"]
        schedule.every(critical_interval).minutes.do(self.execute_critical_monitoring)
        self.logger.info(f"üö® Monitoring critique toutes les {critical_interval} minutes")
    
    def execute_daily_analysis(self):
        """Ex√©cution de l'analyse quotidienne"""
        self.logger.info("üìä D√©but analyse quotidienne")
        
        try:
            # Ex√©cution de l'analyse
            results = self.agent.analyser_performance_globale()
            self.last_analysis_results = results
            
            # Sauvegarde du rapport
            rapport_path = self.agent.sauvegarder_rapport_strategique()
            
            # V√©rification des insights critiques
            critical_insights = [i for i in results["strategic_insights"] 
                               if i["severity"] in ["HIGH", "CRITICAL"]]
            
            if critical_insights:
                self.handle_critical_insights(critical_insights)
            
            # Nettoyage des anciens rapports
            self.cleanup_old_reports()
            
            self.logger.info(f"‚úÖ Analyse quotidienne termin√©e - Rapport: {rapport_path}")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur analyse quotidienne: {e}")
    
    def execute_weekly_deep_analysis(self):
        """Ex√©cution de l'analyse hebdomadaire approfondie"""
        self.logger.info("üîç D√©but analyse hebdomadaire approfondie")
        
        try:
            # Analyse standard
            self.execute_daily_analysis()
            
            # Analyse des tendances sur 7 jours
            trends_analysis = self.analyze_weekly_trends()
            
            # G√©n√©ration du rapport hebdomadaire
            weekly_report = self.generate_weekly_executive_report(trends_analysis)
            
            # Sauvegarde du rapport hebdomadaire
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            weekly_report_path = self.agent.reports_path / f"RAPPORT_HEBDOMADAIRE_{timestamp}.md"
            
            with open(weekly_report_path, 'w', encoding='utf-8') as f:
                f.write(weekly_report)
            
            self.logger.info(f"‚úÖ Analyse hebdomadaire termin√©e - Rapport: {weekly_report_path}")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur analyse hebdomadaire: {e}")
    
    def execute_critical_monitoring(self):
        """Monitoring critique pour d√©tection rapide des probl√®mes"""
        try:
            # V√©rification rapide des m√©triques critiques
            critical_metrics = self.check_critical_metrics()
            
            if critical_metrics["alerts"]:
                self.logger.warning(f"üö® {len(critical_metrics['alerts'])} alertes critiques d√©tect√©es")
                
                # Notification imm√©diate si configur√©e
                if self.config["notifications"]["email_enabled"]:
                    self.send_critical_alert(critical_metrics["alerts"])
                
                # Ex√©cution d'une analyse d'urgence
                self.execute_emergency_analysis(critical_metrics)
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur monitoring critique: {e}")
    
    def check_critical_metrics(self) -> Dict[str, Any]:
        """V√©rification rapide des m√©triques critiques"""
        alerts = []
        
        # V√©rification des logs r√©cents
        recent_logs = list(self.agent.logs_path.glob("*.log"))
        for log_file in recent_logs[-5:]:  # 5 derniers logs
            if log_file.stat().st_size > 1024 * 1024:  # > 1MB
                try:
                    with open(log_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        error_count = content.count("ERROR")
                        if error_count > 10:
                            alerts.append({
                                "type": "high_error_rate",
                                "source": log_file.name,
                                "error_count": error_count,
                                "severity": "CRITICAL"
                            })
                except Exception:
                    continue
        
        # V√©rification des m√©triques de performance r√©centes
        recent_metrics = list(self.agent.metrics_path.glob("*.json"))
        if recent_metrics:
            latest_metric = max(recent_metrics, key=lambda x: x.stat().st_mtime)
            if datetime.now() - datetime.fromtimestamp(latest_metric.stat().st_mtime) > timedelta(hours=2):
                alerts.append({
                    "type": "stale_metrics",
                    "message": "Aucune m√©trique r√©cente d√©tect√©e",
                    "severity": "HIGH"
                })
        
        return {"alerts": alerts, "timestamp": datetime.now().isoformat()}
    
    def handle_critical_insights(self, critical_insights: List[Dict[str, Any]]):
        """Gestion des insights critiques"""
        self.logger.warning(f"üö® {len(critical_insights)} insights critiques d√©tect√©s")
        
        # Notification par email si configur√©e
        if self.config["notifications"]["email_enabled"]:
            self.send_critical_insights_notification(critical_insights)
        
        # Webhook si configur√©
        webhook_url = self.config["notifications"].get("webhook_url")
        if webhook_url:
            self.send_webhook_notification(critical_insights, webhook_url)
        
        # Log d√©taill√©
        for insight in critical_insights:
            self.logger.critical(f"INSIGHT CRITIQUE: {insight['title']} - {insight['description']}")
    
    def send_critical_alert(self, alerts: List[Dict[str, Any]]):
        """Envoi d'alerte critique par email"""
        if not self.config["notifications"]["email_enabled"]:
            return
        
        try:
            subject = f"üö® ALERTE CRITIQUE - NextGeneration - {datetime.now().strftime('%Y-%m-%d %H:%M')}"
            
            body = f"""
ALERTE CRITIQUE D√âTECT√âE

Nombre d'alertes: {len(alerts)}
Timestamp: {datetime.now().isoformat()}

D√âTAILS DES ALERTES:
"""
            
            for alert in alerts:
                body += f"""
- Type: {alert['type']}
- S√©v√©rit√©: {alert['severity']}
- D√©tails: {alert.get('message', 'N/A')}
"""
            
            body += """
Action requise: V√©rifier imm√©diatement le syst√®me NextGeneration.

---
Alerte g√©n√©r√©e automatiquement par l'Agent M√©ta-Strat√©gique
"""
            
            self.send_email(subject, body)
            
        except Exception as e:
            self.logger.error(f"Erreur envoi alerte email: {e}")
    
    def send_email(self, subject: str, body: str):
        """Envoi d'email"""
        config = self.config["notifications"]
        
        msg = MIMEMultipart()
        msg['From'] = config.get("email_from", "agent-meta@nextgeneration.com")
        msg['To'] = ", ".join(config["email_recipients"])
        msg['Subject'] = subject
        
        msg.attach(MIMEText(body, 'plain', 'utf-8'))
        
        server = smtplib.SMTP(config["smtp_server"], config["smtp_port"])
        server.starttls()
        
        # Authentification si configur√©e
        email_user = config.get("email_user")
        email_password = config.get("email_password")
        if email_user and email_password:
            server.login(email_user, email_password)
        
        server.send_message(msg)
        server.quit()
    
    def analyze_weekly_trends(self) -> Dict[str, Any]:
        """Analyse des tendances hebdomadaires"""
        # Collecte des rapports de la semaine
        week_ago = datetime.now() - timedelta(days=7)
        
        weekly_reports = []
        for report_file in self.agent.reports_path.glob("REVUE_STRATEGIQUE_*.md"):
            file_time = datetime.fromtimestamp(report_file.stat().st_mtime)
            if file_time >= week_ago:
                weekly_reports.append({
                    "file": report_file.name,
                    "timestamp": file_time,
                    "size": report_file.stat().st_size
                })
        
        return {
            "reports_analyzed": len(weekly_reports),
            "period_start": week_ago.isoformat(),
            "period_end": datetime.now().isoformat(),
            "trend_summary": "Analyse des tendances hebdomadaires en cours de d√©veloppement"
        }
    
    def generate_weekly_executive_report(self, trends: Dict[str, Any]) -> str:
        """G√©n√©ration du rapport ex√©cutif hebdomadaire"""
        return f"""# üöß RAPPORT EX√âCUTIF HEBDOMADAIRE - VERSION DRAFT üöß
## Agent M√©ta-Strat√©gique PROTOTYPE - Semaine du {datetime.now().strftime('%Y-%m-%d')}

‚ö†Ô∏è **ATTENTION: RAPPORT G√âN√âR√â PAR VERSION EXP√âRIMENTALE**
- **Statut**: DRAFT/PROTOTYPE v0.1.0-draft
- **Usage**: Tests et validation uniquement

---

## üéØ R√âSUM√â DE LA SEMAINE

### Activit√© de Monitoring
- **Rapports g√©n√©r√©s**: {trends['reports_analyzed']}
- **P√©riode analys√©e**: {trends['period_start']} ‚Üí {trends['period_end']}

### Tendances Identifi√©es
{trends['trend_summary']}

---

## üìà √âVOLUTION DES M√âTRIQUES

*Analyse des tendances hebdomadaires en d√©veloppement*

---

## üí° RECOMMANDATIONS STRAT√âGIQUES

1. **Maintenir la surveillance continue** - Le syst√®me de monitoring fonctionne correctement
2. **Analyser les patterns √©mergents** - Identifier les tendances √† long terme
3. **Optimiser les processus** - Am√©liorer l'efficacit√© bas√©e sur les donn√©es collect√©es

---

*Rapport g√©n√©r√© automatiquement par l'Agent M√©ta-Strat√©gique*
*Prochaine analyse: {(datetime.now() + timedelta(days=7)).strftime('%Y-%m-%d')}*
"""
    
    def cleanup_old_reports(self):
        """Nettoyage des anciens rapports"""
        retention_days = self.config["analysis_settings"]["retention_days"]
        cutoff_date = datetime.now() - timedelta(days=retention_days)
        
        cleaned_count = 0
        for report_file in self.agent.reports_path.glob("REVUE_STRATEGIQUE_*.md"):
            file_time = datetime.fromtimestamp(report_file.stat().st_mtime)
            if file_time < cutoff_date:
                if self.config["analysis_settings"]["archive_reports"]:
                    # Archiver au lieu de supprimer
                    archive_path = self.agent.reports_path / "archive"
                    archive_path.mkdir(exist_ok=True)
                    report_file.rename(archive_path / report_file.name)
                else:
                    report_file.unlink()
                cleaned_count += 1
        
        if cleaned_count > 0:
            self.logger.info(f"üßπ {cleaned_count} anciens rapports nettoy√©s/archiv√©s")
    
    def execute_emergency_analysis(self, critical_metrics: Dict[str, Any]):
        """Analyse d'urgence en cas de probl√®me critique"""
        self.logger.critical("üö® Ex√©cution d'analyse d'urgence")
        
        try:
            # Analyse focalis√©e sur le probl√®me
            emergency_analysis = self.agent.analyser_performance_globale()
            
            # Ajout du contexte d'urgence
            emergency_analysis["emergency_context"] = {
                "trigger": "critical_monitoring",
                "alerts": critical_metrics["alerts"],
                "timestamp": datetime.now().isoformat()
            }
            
            # Sauvegarde du rapport d'urgence
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            emergency_report_path = self.agent.reports_path / f"URGENCE_STRATEGIQUE_{timestamp}.json"
            
            with open(emergency_report_path, 'w', encoding='utf-8') as f:
                json.dump(emergency_analysis, f, indent=2, ensure_ascii=False)
            
            self.logger.critical(f"üö® Rapport d'urgence sauvegard√©: {emergency_report_path}")
            
        except Exception as e:
            self.logger.error(f"‚ùå Erreur analyse d'urgence: {e}")

def main():
    """Fonction principale"""
    # Cr√©ation et d√©marrage du planificateur
    try:
        scheduler = AgentMetaStrategiqueScheduler()
        scheduler.start_scheduler()
    except Exception as e:
        print(f"Une erreur fatale est survenue: {e}")
    # ‚úÖ M√âTHODES STANDARDIS√âES DE RAPPORT

    def _calculate_report_score(self, metrics: Dict[str, Any]) -> int:
        """Calcule le score global du rapport bas√© sur les m√©triques."""
        score = 0
        issues_critiques = []
        
        # Logique de scoring sp√©cifique √† l'agent
        # √Ä adapter selon le type d'agent
        
        return score
    
    def _assess_conformity(self, score: int) -> str:
        """√âvalue la conformit√© bas√©e sur le score."""
        if score >= 90:
            return "‚úÖ CONFORME - OPTIMAL"
        elif score >= 70:
            return "‚úÖ CONFORME - ACCEPTABLE"
        else:
            return "‚ùå NON CONFORME - CRITIQUE"
    
    def _get_quality_level(self, score: int) -> str:
        """D√©termine le niveau de qualit√©."""
        if score >= 90:
            return "OPTIMAL"
        elif score >= 70:
            return "ACCEPTABLE"
        else:
            return "CRITIQUE"
    
    def _generate_recommendations(self, metrics: Dict[str, Any], issues: List[str]) -> List[str]:
        """G√©n√®re les recommandations bas√©es sur l'analyse."""
        recommendations = []
        
        # Logique de g√©n√©ration de recommandations
        # √Ä adapter selon le type d'agent
        
        return recommendations
    
    def _generate_standard_report(self, context: Dict, metrics: Dict, timestamp) -> Dict[str, Any]:
        """G√©n√®re un rapport selon le format standard de l'agent 06."""
        
        score = self._calculate_report_score(metrics)
        conformity = self._assess_conformity(score)
        quality_level = self._get_quality_level(score)
        
        agent_filename = Path(__file__).name
        
        # Issues critiques (√† personnaliser selon l'agent)
        issues_critiques = []
        
        return {
            'agent_id': getattr(self, 'agent_id', 'unknown'),
            'agent_file_name': agent_filename,
            'type_rapport': 'standard',  # √Ä personnaliser
            'timestamp': timestamp.isoformat(),
            'specialisation': 'Agent Sp√©cialis√©',  # √Ä personnaliser
            'score_global': score,
            'niveau_qualite': quality_level,
            'conformite': conformity,
            'signature_cryptographique': 'N/A (Fonctionnalit√© non impl√©ment√©e pour cet agent)',
            'issues_critiques_identifies': len(issues_critiques),
            'architecture': {
                'description': "Description de l'architecture de l'agent",
                'statut_operationnel': f"Syst√®me {getattr(self, 'agent_id', 'unknown')} op√©rationnel.",
                'confirmation_specialisation': f"{getattr(self, 'agent_id', 'unknown')} confirm√© comme sp√©cialiste.",
                'objectifs_principaux': [
                    "Objectif principal 1",
                    "Objectif principal 2",
                    "Objectif principal 3"
                ],
                'technologies_cles': ["Technologie 1", "Technologie 2"]
            },
            'recommandations': self._generate_recommendations(metrics, issues_critiques),
            'issues_critiques_details': issues_critiques if issues_critiques else [
                "Aucun issue critique majeur d√©tect√©. Le syst√®me fonctionne dans les param√®tres attendus."
            ],
            'details_techniques': {
                'strategie': "Strat√©gie technique de l'agent",
                'composants_actifs': [],
                'metriques_collectees': metrics
            },
            'metriques_detaillees': {
                'score_global': {'actuel': score, 'cible': 100},
                'conformite_pourcentage': {'actuel': score, 'cible': 100, 'unite': '%'}
            },
            'impact_business': {
                'criticite': 'MOYENNE' if score >= 70 else 'HAUTE',
                'domaines_impactes': [],
                'actions_requises': []
            }
        }


    def _generate_markdown_report(self, rapport_json: Dict, context: Dict, timestamp) -> str:
        """G√©n√®re un rapport Markdown selon le format standard."""
        
        agent_name = rapport_json.get('agent_id', 'Agent Inconnu')
        type_rapport = rapport_json.get('type_rapport', 'standard')
        score = rapport_json.get('score_global', 0)
        quality = rapport_json.get('niveau_qualite', 'UNKNOWN')
        conformity = rapport_json.get('conformite', 'NON √âVALU√â')
        
        markdown_content = f"""# üìä RAPPORT STRAT√âGIQUE : {agent_name.upper()}

## üéØ R√âSUM√â EX√âCUTIF

**Agent :** {agent_name}  
**Type de Rapport :** {type_rapport}  
**Date de G√©n√©ration :** {timestamp.strftime('%Y-%m-%d %H:%M:%S')}  
**Score Global :** {score}/100  
**Niveau de Qualit√© :** {quality}  
**Conformit√© :** {conformity}  

## üìà ANALYSE GLOBALE

### Score de Performance
- **Score Actuel :** {score}/100
- **Objectif :** 100/100
- **Statut :** {'üü¢ ACCEPTABLE' if score >= 70 else 'üî¥ CRITIQUE'}

### Architecture
{rapport_json.get('architecture', {}).get('description', 'Description non disponible')}

**Objectifs Principaux :**
"""
        
        # Ajouter les objectifs
        for obj in rapport_json.get('architecture', {}).get('objectifs_principaux', []):
            markdown_content += f"- {obj}\n"
        
        markdown_content += f"""
**Technologies Cl√©s :**
"""
        
        # Ajouter les technologies
        for tech in rapport_json.get('architecture', {}).get('technologies_cles', []):
            markdown_content += f"- {tech}\n"
        
        markdown_content += f"""

## üîç RECOMMANDATIONS

"""
        
        # Ajouter les recommandations
        for reco in rapport_json.get('recommandations', []):
            markdown_content += f"- {reco}\n"
        
        markdown_content += f"""

## ‚ö†Ô∏è ISSUES CRITIQUES

"""
        
        # Ajouter les issues critiques
        for issue in rapport_json.get('issues_critiques_details', []):
            markdown_content += f"- {issue}\n"
        
        markdown_content += f"""

## üìä M√âTRIQUES D√âTAILL√âES

### Performance Globale
- **Score Global :** {rapport_json.get('metriques_detaillees', {}).get('score_global', {}).get('actuel', 0)}/{rapport_json.get('metriques_detaillees', {}).get('score_global', {}).get('cible', 100)}
- **Conformit√© :** {rapport_json.get('metriques_detaillees', {}).get('conformite_pourcentage', {}).get('actuel', 0)}%

## üéØ IMPACT BUSINESS

**Criticit√© :** {rapport_json.get('impact_business', {}).get('criticite', 'NON √âVALU√â')}

### Domaines Impact√©s
"""
        
        # Ajouter les domaines impact√©s
        for domaine in rapport_json.get('impact_business', {}).get('domaines_impactes', []):
            markdown_content += f"- {domaine}\n"
        
        markdown_content += f"""

### Actions Requises
"""
        
        # Ajouter les actions requises
        for action in rapport_json.get('impact_business', {}).get('actions_requises', []):
            markdown_content += f"- {action}\n"
        
        markdown_content += f"""

---
*Rapport g√©n√©r√© automatiquement par {agent_name} - NextGeneration System*  
*Timestamp: {timestamp.isoformat()}*
"""
        
        return markdown_content



if __name__ == "__main__":
    main() 
