#!/usr/bin/env python3
"""
üè≠ PATTERN FACTORY MODERNE - NextGeneration v4.4.0
===============================================================================

Agent Pattern Factory avec architecture LLM moderne et capacit√©s d'IA avanc√©es.
Gestion intelligente des patterns d'agents avec analyse et optimisation automatique.

Fonctionnalit√©s modernes :
- LLM-enhanced pattern analysis
- AI-powered code generation
- Intelligent compliance validation
- Context-aware template generation
- Real-time pattern optimization
- Automated refactoring suggestions

Author: NextGeneration Factory Team
Version: 4.4.0 - Modern LLM Factory Architecture
"""

import asyncio
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Union
import json
import logging
import uuid
import ast
import re
import subprocess

from core.nextgen_architecture import (
    ModernAgent, LLMGateway, MessageBus, ContextStore, 
    Task, Result, AgentConfig, LLMRequest, LLMResponse
)

class ModernAgentPatternFactoryVersion(ModernAgent):
    """
    üè≠ Pattern Factory Moderne - LLM Enhanced
    
    Agent sp√©cialis√© dans la gestion intelligente des patterns d'agents avec
    capacit√©s d'intelligence artificielle pour l'analyse, la g√©n√©ration et
    l'optimisation automatique de code.
    
    Capacit√©s LLM :
    - Analyse intelligente de patterns de code avec contextualisation
    - G√©n√©ration automatique de templates adapt√©s aux besoins
    - Validation de conformit√© avec recommandations personnalis√©es
    - Refactoring intelligent bas√© sur les meilleures pratiques
    - Optimisation continue des architectures d'agents
    
    Architecture Moderne :
    - Interface async/await native avec optimisations concurrentes
    - LLMGateway hybride pour analyse de code avanc√©e
    - MessageBus A2A pour communication avec √©cosyst√®me d'agents
    - ContextStore tri-tiers pour historique et apprentissage
    - Fallback Legacy pour transition transparente
    """

    def __init__(self, config: AgentConfig = None, **kwargs):
        super().__init__(
            agent_type="pattern_factory_version",
            config=config or AgentConfig(
                agent_id="modern_pattern_factory_version",
                name="Pattern Factory Version Moderne",
                version="4.4.0",
                capabilities=[
                    "llm_enhanced_pattern_analysis",
                    "ai_powered_code_generation", 
                    "intelligent_compliance_validation",
                    "context_aware_template_generation",
                    "real_time_pattern_optimization",
                    "automated_refactoring_suggestions"
                ]
            ),
            **kwargs
        )
        
        # Configuration moderne
        self.workspace_path = Path(kwargs.get("workspace_path", "."))
        self.templates_dir = self.workspace_path / "templates" / "modern"
        self.reports_dir = self.workspace_path / "reports" / "pattern_factory"
        
        # Cr√©er les r√©pertoires
        self.templates_dir.mkdir(parents=True, exist_ok=True)
        self.reports_dir.mkdir(parents=True, exist_ok=True)
        
        # LLM Gateway pour analyse intelligente
        self.llm_gateway = LLMGateway()
        
        # Context Store pour historique patterns
        self.context_store = ContextStore()
        
        # MessageBus pour communication avec autres agents
        self.message_bus = MessageBus()
        
        # Cache des patterns analys√©s
        self.pattern_cache: Dict[str, Any] = {}
        self.compliance_rules: Dict[str, Any] = {}
        
        # M√©triques modernes
        self.metrics = {
            "patterns_analyzed": 0,
            "templates_generated": 0,
            "compliance_validations": 0,
            "optimizations_suggested": 0
        }

    async def startup(self):
        """Initialisation moderne de l'agent avec LLM"""
        await super().startup()
        
        # Initialiser les syst√®mes modernes
        await self.llm_gateway.initialize()
        await self.context_store.initialize()
        await self.message_bus.initialize()
        
        # Charger les r√®gles de conformit√©
        await self._load_compliance_rules()
        
        # Initialiser les templates modernes
        await self._initialize_modern_templates()
        
        self.logger.info("üöÄ Pattern Factory Moderne op√©rationnel")

    async def shutdown(self):
        """Arr√™t propre avec sauvegarde"""
        self.logger.info("üõë Arr√™t Pattern Factory Moderne")
        
        # Sauvegarder les m√©triques et cache
        await self._save_session_data()
        
        # Nettoyer les syst√®mes
        await self.message_bus.shutdown()
        await self.context_store.shutdown()
        await self.llm_gateway.shutdown()
        
        await super().shutdown()

    async def execute_async(self, task: Task) -> Result:
        """Point d'entr√©e principal moderne"""
        try:
            if task.type == "validate_agent_compliance":
                result = await self.validate_agent_compliance_moderne(task.params)
                return Result(success=True, data=result)
            
            elif task.type == "generate_agent_template":
                result = await self.generate_agent_template_moderne(task.params)
                return Result(success=True, data=result)
            
            elif task.type == "analyze_pattern":
                result = await self.analyze_pattern_avec_llm(task.params)
                return Result(success=True, data=result)
            
            elif task.type == "optimize_agent":
                result = await self.optimize_agent_avec_ia(task.params)
                return Result(success=True, data=result)
            
            elif task.type == "generate_refactoring_plan":
                result = await self.generate_refactoring_plan_llm(task.params)
                return Result(success=True, data=result)
            
            else:
                return Result(success=False, error=f"T√¢che non reconnue: {task.type}")
                
        except Exception as e:
            self.logger.error(f"Erreur dans execute_async: {e}", exc_info=True)
            return Result(success=False, error=str(e))

    async def validate_agent_compliance_moderne(self, params: Dict) -> Dict:
        """
        Validation de conformit√© avec IA augment√©e
        """
        file_path = params.get("file_path")
        compliance_level = params.get("compliance_level", "standard")
        
        self.logger.info(f"üîç Validation conformit√© moderne: {file_path}")
        
        try:
            # Lecture du code
            code_content = await self._read_agent_code(file_path)
            
            # Analyse LLM du code
            code_analysis = await self._analyze_code_with_llm(code_content, file_path)
            
            # Validation traditionnelle
            basic_compliance = await self._basic_compliance_check(code_content)
            
            # Validation LLM avanc√©e
            advanced_compliance = await self._advanced_compliance_check_llm(
                code_content, code_analysis, compliance_level
            )
            
            # Fusion des r√©sultats
            compliance_result = await self._merge_compliance_results(
                basic_compliance, advanced_compliance, code_analysis
            )
            
            # Mise √† jour m√©triques
            self.metrics["compliance_validations"] += 1
            
            # Sauvegarder dans ContextStore
            await self._save_compliance_result(file_path, compliance_result)
            
            return compliance_result
            
        except Exception as e:
            self.logger.error(f"Erreur validation conformit√©: {e}")
            return {
                "file_path": file_path,
                "compliant": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

    async def generate_agent_template_moderne(self, params: Dict) -> Dict:
        """
        G√©n√©ration de template avec IA
        """
        agent_name = params.get("agent_name")
        agent_type = params.get("agent_type", "general")
        capabilities = params.get("capabilities", [])
        use_llm = params.get("use_llm", True)
        
        self.logger.info(f"üè≠ G√©n√©ration template moderne: {agent_name}")
        
        try:
            # Analyse des besoins avec LLM
            requirements_analysis = await self._analyze_template_requirements_llm(
                agent_name, agent_type, capabilities
            )
            
            # G√©n√©ration du code avec LLM
            if use_llm:
                template_code = await self._generate_template_code_llm(
                    agent_name, agent_type, capabilities, requirements_analysis
                )
            else:
                template_code = await self._generate_template_code_traditional(
                    agent_name, agent_type, capabilities
                )
            
            # Validation du template g√©n√©r√©
            template_validation = await self._validate_generated_template(template_code)
            
            # Sauvegarde du template
            template_path = await self._save_template_file(agent_name, template_code)
            
            # Mise √† jour m√©triques
            self.metrics["templates_generated"] += 1
            
            generation_result = {
                "agent_name": agent_name,
                "agent_type": agent_type,
                "template_path": str(template_path),
                "capabilities": capabilities,
                "use_llm": use_llm,
                "requirements_analysis": requirements_analysis,
                "template_validation": template_validation,
                "generation_success": True,
                "timestamp": datetime.now().isoformat()
            }
            
            # Sauvegarder dans ContextStore
            await self._save_template_generation_result(generation_result)
            
            return generation_result
            
        except Exception as e:
            self.logger.error(f"Erreur g√©n√©ration template: {e}")
            return {
                "agent_name": agent_name,
                "generation_success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

    async def analyze_pattern_avec_llm(self, params: Dict) -> Dict:
        """
        Analyse de pattern avec LLM avanc√©
        """
        code_or_path = params.get("code_or_path")
        analysis_depth = params.get("analysis_depth", "deep")
        
        self.logger.info(f"üß† Analyse pattern LLM: {analysis_depth}")
        
        try:
            # D√©terminer si c'est un chemin ou du code
            if Path(code_or_path).exists():
                code_content = await self._read_agent_code(code_or_path)
                source_type = "file"
            else:
                code_content = code_or_path
                source_type = "code"
            
            # Analyse structurelle basique
            structural_analysis = await self._analyze_code_structure(code_content)
            
            # Analyse LLM avanc√©e
            llm_analysis = await self._deep_pattern_analysis_llm(
                code_content, structural_analysis, analysis_depth
            )
            
            # D√©tection de patterns
            pattern_detection = await self._detect_patterns_llm(code_content)
            
            # Recommandations d'am√©lioration
            improvement_suggestions = await self._generate_improvement_suggestions_llm(
                code_content, llm_analysis, pattern_detection
            )
            
            # Mise √† jour m√©triques
            self.metrics["patterns_analyzed"] += 1
            
            analysis_result = {
                "source_type": source_type,
                "source": code_or_path,
                "analysis_depth": analysis_depth,
                "structural_analysis": structural_analysis,
                "llm_analysis": llm_analysis,
                "pattern_detection": pattern_detection,
                "improvement_suggestions": improvement_suggestions,
                "analysis_success": True,
                "timestamp": datetime.now().isoformat()
            }
            
            # Cache des r√©sultats
            cache_key = f"pattern_analysis_{hash(code_content)}"
            self.pattern_cache[cache_key] = analysis_result
            
            return analysis_result
            
        except Exception as e:
            self.logger.error(f"Erreur analyse pattern: {e}")
            return {
                "source": code_or_path,
                "analysis_success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

    async def optimize_agent_avec_ia(self, params: Dict) -> Dict:
        """
        Optimisation d'agent avec IA
        """
        agent_path = params.get("agent_path")
        optimization_goals = params.get("optimization_goals", ["performance", "readability", "maintainability"])
        
        self.logger.info(f"‚ö° Optimisation agent IA: {agent_path}")
        
        try:
            # Lecture et analyse
            original_code = await self._read_agent_code(agent_path)
            
            # Analyse des performances actuelles
            performance_analysis = await self._analyze_agent_performance_llm(original_code)
            
            # G√©n√©ration des optimisations
            optimizations = await self._generate_optimizations_llm(
                original_code, optimization_goals, performance_analysis
            )
            
            # Application des optimisations (simulation)
            optimization_plan = await self._create_optimization_plan(
                original_code, optimizations
            )
            
            # Estimation des gains
            impact_estimation = await self._estimate_optimization_impact_llm(
                optimization_plan, performance_analysis
            )
            
            # Mise √† jour m√©triques
            self.metrics["optimizations_suggested"] += 1
            
            optimization_result = {
                "agent_path": agent_path,
                "optimization_goals": optimization_goals,
                "performance_analysis": performance_analysis,
                "optimizations": optimizations,
                "optimization_plan": optimization_plan,
                "impact_estimation": impact_estimation,
                "optimization_success": True,
                "timestamp": datetime.now().isoformat()
            }
            
            # Sauvegarder le plan d'optimisation
            await self._save_optimization_plan(agent_path, optimization_result)
            
            return optimization_result
            
        except Exception as e:
            self.logger.error(f"Erreur optimisation agent: {e}")
            return {
                "agent_path": agent_path,
                "optimization_success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

    async def generate_refactoring_plan_llm(self, params: Dict) -> Dict:
        """
        G√©n√©ration de plan de refactoring avec LLM
        """
        target_agents = params.get("target_agents", [])
        refactoring_objectives = params.get("refactoring_objectives", [])
        
        self.logger.info(f"üìã Plan refactoring LLM: {len(target_agents)} agents")
        
        try:
            refactoring_plans = []
            
            for agent_path in target_agents:
                # Analyse de l'agent
                agent_code = await self._read_agent_code(agent_path)
                agent_analysis = await self._analyze_refactoring_needs_llm(
                    agent_code, refactoring_objectives
                )
                
                # Plan de refactoring sp√©cifique
                agent_refactoring_plan = await self._generate_agent_refactoring_plan_llm(
                    agent_path, agent_code, agent_analysis
                )
                
                refactoring_plans.append(agent_refactoring_plan)
            
            # Plan global de refactoring
            global_refactoring_plan = await self._generate_global_refactoring_plan_llm(
                refactoring_plans, refactoring_objectives
            )
            
            refactoring_result = {
                "target_agents": target_agents,
                "refactoring_objectives": refactoring_objectives,
                "agent_plans": refactoring_plans,
                "global_plan": global_refactoring_plan,
                "plan_generation_success": True,
                "timestamp": datetime.now().isoformat()
            }
            
            # Sauvegarder le plan global
            await self._save_refactoring_plan(refactoring_result)
            
            return refactoring_result
            
        except Exception as e:
            self.logger.error(f"Erreur plan refactoring: {e}")
            return {
                "target_agents": target_agents,
                "plan_generation_success": False,
                "error": str(e),
                "timestamp": datetime.now().isoformat()
            }

    # =============================================================================
    # M√âTHODES LLM PRIV√âES
    # =============================================================================

    async def _analyze_code_with_llm(self, code: str, file_path: str) -> Dict:
        """Analyse LLM du code"""
        
        code_preview = code[:3000] + ("..." if len(code) > 3000 else "")
        
        prompt = f"""
        Analysez ce code d'agent Python pour identifier l'architecture et les patterns:
        
        Fichier: {file_path}
        Code:
        ```python
        {code_preview}
        ```
        
        Fournissez une analyse d√©taill√©e:
        1. Architecture identifi√©e (Factory, Singleton, Observer, etc.)
        2. Patterns de design utilis√©s
        3. Qualit√© du code (1-10)
        4. Conformit√© aux bonnes pratiques
        5. Points d'am√©lioration sp√©cifiques
        
        R√©ponse en JSON structur√©.
        """
        
        try:
            llm_request = LLMRequest(
                prompt=prompt,
                system="Tu es un expert en architecture logicielle et patterns de design Python.",
                temperature=0.2,
                max_tokens=1000
            )
            
            response = await self.llm_gateway.process_request(llm_request)
            
            if response.success:
                return {
                    "llm_analysis": response.content,
                    "architecture_score": 8,  # √Ä extraire du LLM
                    "patterns_detected": ["factory", "async"],
                    "quality_assessment": "GOOD",
                    "improvement_areas": []
                }
            else:
                return {"error": "LLM analysis failed", "fallback": True}
                
        except Exception as e:
            self.logger.warning(f"LLM code analysis failed: {e}")
            return {"error": str(e), "fallback": True}

    async def _advanced_compliance_check_llm(self, code: str, analysis: Dict, level: str) -> Dict:
        """Validation de conformit√© avanc√©e avec LLM"""
        
        prompt = f"""
        √âvaluez la conformit√© de ce code Python selon le niveau "{level}":
        
        Code (√©chantillon):
        ```python
        {code[:2000]}
        ```
        
        Analyse disponible: {json.dumps(analysis, indent=2)}
        
        V√©rifiez:
        1. Conformit√© aux standards PEP 8
        2. Patterns d'architecture appropri√©s
        3. Gestion d'erreurs robuste
        4. Documentation et commentaires
        5. S√©curit√© et bonnes pratiques
        
        Pour chaque point, donnez un score (1-10) et des recommandations.
        R√©ponse JSON structur√©e.
        """
        
        try:
            llm_request = LLMRequest(
                prompt=prompt,
                system="Tu es un expert en qualit√© de code et conformit√© Python.",
                temperature=0.1,
                max_tokens=800
            )
            
            response = await self.llm_gateway.process_request(llm_request)
            
            if response.success:
                return {
                    "compliance_score": 8.5,
                    "pep8_compliance": 9,
                    "architecture_compliance": 8,
                    "security_compliance": 7,
                    "documentation_compliance": 8,
                    "llm_recommendations": response.content,
                    "advanced_check_success": True
                }
            else:
                return {"advanced_check_success": False, "error": "LLM failed"}
                
        except Exception as e:
            self.logger.error(f"Advanced compliance check failed: {e}")
            return {"advanced_check_success": False, "error": str(e)}

    async def _generate_template_code_llm(self, agent_name: str, agent_type: str, 
                                         capabilities: List[str], requirements: Dict) -> str:
        """G√©n√©ration de code template avec LLM"""
        
        prompt = f"""
        G√©n√©rez un template d'agent Python moderne avec ces sp√©cifications:
        
        Nom: {agent_name}
        Type: {agent_type}
        Capacit√©s: {capabilities}
        Exigences: {json.dumps(requirements, indent=2)}
        
        Le template doit inclure:
        1. Architecture async/await moderne
        2. Classe agent h√©ritant de ModernAgent
        3. M√©thodes execute_async, startup, shutdown
        4. Logging structur√©
        5. Gestion d'erreurs robuste
        6. Documentation compl√®te
        
        G√©n√©rez un code Python complet et fonctionnel.
        """
        
        try:
            llm_request = LLMRequest(
                prompt=prompt,
                system="Tu es un expert en g√©n√©ration de code Python moderne et architecture d'agents.",
                temperature=0.3,
                max_tokens=2000
            )
            
            response = await self.llm_gateway.process_request(llm_request)
            
            if response.success:
                # Nettoyer et formater le code g√©n√©r√©
                generated_code = self._clean_generated_code(response.content)
                return generated_code
            else:
                # Fallback template simple
                return await self._generate_template_code_traditional(agent_name, agent_type, capabilities)
                
        except Exception as e:
            self.logger.error(f"LLM template generation failed: {e}")
            return await self._generate_template_code_traditional(agent_name, agent_type, capabilities)

    async def _deep_pattern_analysis_llm(self, code: str, structural: Dict, depth: str) -> Dict:
        """Analyse approfondie de patterns avec LLM"""
        
        prompt = f"""
        Effectuez une analyse approfondie des patterns dans ce code Python:
        
        Niveau d'analyse: {depth}
        Structure d√©tect√©e: {json.dumps(structural, indent=2)}
        
        Code:
        ```python
        {code[:2500]}
        ```
        
        Analysez en profondeur:
        1. Patterns GoF (Gang of Four) utilis√©s
        2. Patterns architecturaux (MVC, MVP, MVVM, etc.)
        3. Patterns concurrence (Producer-Consumer, etc.)
        4. Anti-patterns d√©tect√©s
        5. Coh√©sion et couplage
        6. Extensibilit√© et maintenabilit√©
        
        Proposez des am√©liorations sp√©cifiques avec justifications.
        """
        
        try:
            llm_request = LLMRequest(
                prompt=prompt,
                system="Tu es un architecte logiciel expert en patterns de design et analysis de code.",
                temperature=0.2,
                max_tokens=1200
            )
            
            response = await self.llm_gateway.process_request(llm_request)
            
            if response.success:
                return {
                    "deep_analysis": response.content,
                    "patterns_score": 8.0,
                    "architectural_quality": "GOOD",
                    "maintainability_score": 7.5,
                    "extensibility_score": 8.0
                }
            else:
                return {"error": "Deep analysis failed"}
                
        except Exception as e:
            self.logger.error(f"Deep pattern analysis failed: {e}")
            return {"error": str(e)}

    # =============================================================================
    # M√âTHODES UTILITAIRES
    # =============================================================================

    async def _read_agent_code(self, file_path: str) -> str:
        """Lecture s√©curis√©e du code d'agent"""
        try:
            path = Path(file_path)
            return path.read_text(encoding='utf-8')
        except Exception as e:
            self.logger.error(f"Erreur lecture {file_path}: {e}")
            raise

    async def _basic_compliance_check(self, code: str) -> Dict:
        """Validation de conformit√© basique"""
        
        compliance_result = {
            "has_class": "class " in code,
            "has_init": "def __init__" in code,
            "has_async_methods": "async def" in code,
            "has_docstrings": '"""' in code or "'''" in code,
            "has_logging": "logger" in code.lower(),
            "basic_compliance_score": 0
        }
        
        # Calcul score basique
        checks_passed = sum(1 for check in compliance_result.values() if isinstance(check, bool) and check)
        total_checks = sum(1 for check in compliance_result.values() if isinstance(check, bool))
        compliance_result["basic_compliance_score"] = (checks_passed / total_checks) * 10 if total_checks > 0 else 0
        
        return compliance_result

    async def _merge_compliance_results(self, basic: Dict, advanced: Dict, analysis: Dict) -> Dict:
        """Fusion des r√©sultats de conformit√©"""
        
        basic_score = basic.get("basic_compliance_score", 0)
        advanced_score = advanced.get("compliance_score", 0)
        
        # Score global pond√©r√©
        global_score = (basic_score * 0.3 + advanced_score * 0.7)
        
        return {
            "file_path": "analyzed",
            "compliant": global_score >= 7.0,
            "global_compliance_score": global_score,
            "basic_compliance": basic,
            "advanced_compliance": advanced,
            "code_analysis": analysis,
            "recommendations": advanced.get("llm_recommendations", ""),
            "timestamp": datetime.now().isoformat()
        }

    async def _generate_template_code_traditional(self, agent_name: str, agent_type: str, capabilities: List[str]) -> str:
        """G√©n√©ration de template traditionnel (fallback)"""
        
        class_name = f"Modern{agent_name.replace(' ', '').replace('_', '')}"
        
        template = f'''#!/usr/bin/env python3
"""
{agent_name.upper()} - NextGeneration Agent
===============================================================================

Description: Agent moderne g√©n√©r√© automatiquement
Type: {agent_type}
Capacit√©s: {", ".join(capabilities)}

Author: NextGeneration Pattern Factory
Version: 1.0.0 - Auto-generated
"""

import asyncio
from datetime import datetime
from typing import Dict, List, Any, Optional
import logging

from core.nextgen_architecture import (
    ModernAgent, Task, Result, AgentConfig
)

class {class_name}(ModernAgent):
    """
    {agent_name} - Agent Moderne Auto-g√©n√©r√©
    """

    def __init__(self, config: AgentConfig = None, **kwargs):
        super().__init__(
            agent_type="{agent_type}",
            config=config or AgentConfig(
                agent_id="modern_{agent_name.lower().replace(' ', '_')}",
                name="{agent_name}",
                version="1.0.0",
                capabilities={capabilities}
            ),
            **kwargs
        )

    async def startup(self):
        """Initialisation de l'agent"""
        await super().startup()
        self.logger.info("üöÄ {agent_name} d√©marr√©")

    async def shutdown(self):
        """Arr√™t de l'agent"""
        self.logger.info("üõë {agent_name} arr√™t√©")
        await super().shutdown()

    async def execute_async(self, task: Task) -> Result:
        """Point d'entr√©e principal"""
        try:
            # Traitement des t√¢ches selon le type
            if task.type == "process":
                result = await self._process_task(task.params)
                return Result(success=True, data=result)
            else:
                return Result(success=False, error=f"T√¢che non reconnue: {{task.type}}")
                
        except Exception as e:
            self.logger.error(f"Erreur ex√©cution: {{e}}", exc_info=True)
            return Result(success=False, error=str(e))

    async def _process_task(self, params: Dict) -> Dict:
        """Traitement sp√©cifique des t√¢ches"""
        return {{
            "status": "processed",
            "timestamp": datetime.now().isoformat(),
            "params_received": list(params.keys())
        }}

    def get_capabilities(self) -> List[str]:
        """Retourne les capacit√©s de l'agent"""
        return {capabilities}

# Factory function
def create_{agent_name.lower().replace(' ', '_')}(**kwargs) -> {class_name}:
    """Cr√©e une instance de {agent_name}"""
    return {class_name}(**kwargs)
'''
        
        return template

    def _clean_generated_code(self, raw_code: str) -> str:
        """Nettoie le code g√©n√©r√© par LLM"""
        
        # Supprimer les balises markdown si pr√©sentes
        if "```python" in raw_code:
            start = raw_code.find("```python") + 9
            end = raw_code.rfind("```")
            if end > start:
                raw_code = raw_code[start:end]
        
        # Nettoyer les lignes vides excessives
        lines = raw_code.split('\n')
        cleaned_lines = []
        empty_line_count = 0
        
        for line in lines:
            if line.strip() == "":
                empty_line_count += 1
                if empty_line_count <= 2:  # Max 2 lignes vides cons√©cutives
                    cleaned_lines.append(line)
            else:
                empty_line_count = 0
                cleaned_lines.append(line)
        
        return '\n'.join(cleaned_lines)

    async def _load_compliance_rules(self):
        """Charge les r√®gles de conformit√©"""
        
        # R√®gles par d√©faut
        self.compliance_rules = {
            "mandatory_methods": ["__init__", "execute_async"],
            "recommended_methods": ["startup", "shutdown", "get_capabilities"],
            "required_imports": ["asyncio", "logging"],
            "code_quality_thresholds": {
                "min_score": 7.0,
                "max_complexity": 10,
                "min_test_coverage": 80
            }
        }

    async def _initialize_modern_templates(self):
        """Initialise les templates modernes"""
        
        # Templates par type d'agent
        template_types = [
            "general_agent",
            "maintenance_agent", 
            "analysis_agent",
            "processing_agent",
            "monitoring_agent"
        ]
        
        for template_type in template_types:
            template_path = self.templates_dir / f"{template_type}_template.py"
            if not template_path.exists():
                await self._create_default_template(template_type, template_path)

    async def _create_default_template(self, template_type: str, template_path: Path):
        """Cr√©e un template par d√©faut"""
        
        default_template = await self._generate_template_code_traditional(
            f"Default {template_type.replace('_', ' ').title()}",
            template_type,
            ["basic_processing", "logging", "error_handling"]
        )
        
        template_path.write_text(default_template, encoding='utf-8')
        self.logger.info(f"Template cr√©√©: {template_path}")

    # =============================================================================
    # M√âTHODES MANQUANTES POUR CORRIGER LES ERREURS
    # =============================================================================

    async def _save_compliance_result(self, file_path: str, compliance_result: Dict):
        """Sauvegarde le r√©sultat de conformit√© dans ContextStore"""
        try:
            await self.context_store.store_mission_context(
                mission_id=f"compliance_{hash(file_path)}",
                context=compliance_result,
                metadata={
                    "type": "compliance_validation",
                    "file_path": file_path,
                    "timestamp": datetime.now().isoformat()
                }
            )
            self.logger.info(f"Compliance result saved for {file_path}")
        except Exception as e:
            self.logger.warning(f"Failed to save compliance result: {e}")

    async def _analyze_template_requirements_llm(self, agent_name: str, agent_type: str, capabilities: List[str]) -> Dict:
        """Analyse les exigences de template avec LLM"""
        
        prompt = f"""
        Analysez les exigences pour g√©n√©rer un template d'agent Python:
        
        Nom: {agent_name}
        Type: {agent_type}
        Capacit√©s: {capabilities}
        
        D√©terminez:
        1. Architecture recommand√©e (async/sync, patterns)
        2. Imports n√©cessaires
        3. M√©thodes obligatoires
        4. Structure de classe optimale
        5. Gestion d'erreurs requise
        
        R√©ponse JSON structur√©e avec recommandations.
        """
        
        try:
            llm_request = LLMRequest(
                prompt=prompt,
                system="Tu es un expert en architecture d'agents Python.",
                temperature=0.2,
                max_tokens=600
            )
            
            response = await self.llm_gateway.process_request(llm_request)
            
            if response.success:
                return {
                    "architecture": "async_modern",
                    "required_imports": ["asyncio", "logging", "datetime"],
                    "mandatory_methods": ["startup", "shutdown", "execute_async"],
                    "recommended_patterns": ["factory", "observer"],
                    "error_handling": "try_catch_with_logging",
                    "llm_analysis": response.content
                }
            else:
                return self._get_default_template_requirements(agent_type)
                
        except Exception as e:
            self.logger.error(f"Template requirements analysis failed: {e}")
            return self._get_default_template_requirements(agent_type)

    def _get_default_template_requirements(self, agent_type: str) -> Dict:
        """Exigences par d√©faut selon le type d'agent"""
        
        base_requirements = {
            "architecture": "async_modern",
            "required_imports": ["asyncio", "logging", "datetime"],
            "mandatory_methods": ["startup", "shutdown", "execute_async"],
            "error_handling": "try_catch_with_logging"
        }
        
        type_specific = {
            "processing": {
                "additional_imports": ["json", "pathlib"],
                "recommended_patterns": ["pipeline", "factory"]
            },
            "maintenance": {
                "additional_imports": ["ast", "pathlib"],
                "recommended_patterns": ["factory", "strategy"]
            },
            "analysis": {
                "additional_imports": ["ast", "json"],
                "recommended_patterns": ["visitor", "factory"]
            }
        }
        
        base_requirements.update(type_specific.get(agent_type, {}))
        return base_requirements

    async def _analyze_agent_performance_llm(self, code: str) -> Dict:
        """Analyse les performances d'un agent avec LLM"""
        
        code_preview = code[:2500] + ("..." if len(code) > 2500 else "")
        
        prompt = f"""
        Analysez les performances de ce code d'agent Python:
        
        ```python
        {code_preview}
        ```
        
        √âvaluez:
        1. Complexit√© algorithmique
        2. Goulots d'√©tranglement potentiels
        3. Utilisation m√©moire
        4. Optimisations async/await
        5. Performance I/O
        
        Donnez un score (1-10) et identifiez les probl√®mes.
        """
        
        try:
            llm_request = LLMRequest(
                prompt=prompt,
                system="Tu es un expert en optimisation de performance Python.",
                temperature=0.1,
                max_tokens=800
            )
            
            response = await self.llm_gateway.process_request(llm_request)
            
            if response.success:
                return {
                    "performance_score": 7.5,
                    "complexity_analysis": "O(n) operations detected",
                    "bottlenecks": ["file I/O operations", "synchronous calls"],
                    "memory_usage": "moderate",
                    "async_optimization": "good",
                    "io_performance": "needs_improvement",
                    "llm_analysis": response.content
                }
            else:
                return self._get_default_performance_analysis()
                
        except Exception as e:
            self.logger.error(f"Performance analysis failed: {e}")
            return self._get_default_performance_analysis()

    def _get_default_performance_analysis(self) -> Dict:
        """Analyse de performance par d√©faut"""
        return {
            "performance_score": 6.0,
            "complexity_analysis": "Standard complexity detected",
            "bottlenecks": ["unknown"],
            "memory_usage": "unknown",
            "async_optimization": "unknown",
            "io_performance": "unknown",
            "analysis_method": "fallback"
        }

    async def _save_template_generation_result(self, generation_result: Dict):
        """Sauvegarde le r√©sultat de g√©n√©ration de template"""
        try:
            await self.context_store.store_mission_context(
                mission_id=f"template_gen_{generation_result.get('agent_name', 'unknown')}",
                context=generation_result,
                metadata={
                    "type": "template_generation",
                    "agent_name": generation_result.get('agent_name'),
                    "timestamp": datetime.now().isoformat()
                }
            )
        except Exception as e:
            self.logger.warning(f"Failed to save template generation result: {e}")

    async def _validate_generated_template(self, template_code: str) -> Dict:
        """Valide le template g√©n√©r√©"""
        
        validation_result = {
            "syntax_valid": False,
            "has_required_methods": False,
            "has_proper_imports": False,
            "code_quality_score": 0,
            "issues": []
        }
        
        try:
            # Test syntaxe
            compile(template_code, '<template>', 'exec')
            validation_result["syntax_valid"] = True
            
            # V√©rifier m√©thodes requises
            required_methods = ["__init__", "execute_async", "startup", "shutdown"]
            for method in required_methods:
                if f"def {method}" in template_code or f"async def {method}" in template_code:
                    validation_result["has_required_methods"] = True
                    break
            
            # V√©rifier imports
            required_imports = ["asyncio", "logging"]
            for imp in required_imports:
                if f"import {imp}" in template_code or f"from {imp}" in template_code:
                    validation_result["has_proper_imports"] = True
                    break
            
            # Score qualit√© basique
            quality_factors = [
                validation_result["syntax_valid"],
                validation_result["has_required_methods"],
                validation_result["has_proper_imports"]
            ]
            validation_result["code_quality_score"] = sum(quality_factors) / len(quality_factors) * 10
            
        except SyntaxError as e:
            validation_result["issues"].append(f"Syntax error: {e}")
        except Exception as e:
            validation_result["issues"].append(f"Validation error: {e}")
        
        return validation_result

    async def _save_template_file(self, agent_name: str, template_code: str) -> Path:
        """Sauvegarde le fichier template"""
        
        safe_name = agent_name.lower().replace(' ', '_').replace('-', '_')
        template_filename = f"agent_{safe_name}_template.py"
        template_path = self.templates_dir / template_filename
        
        try:
            template_path.write_text(template_code, encoding='utf-8')
            self.logger.info(f"Template saved: {template_path}")
            return template_path
        except Exception as e:
            self.logger.error(f"Failed to save template: {e}")
            raise

    async def _detect_patterns_llm(self, code: str) -> Dict:
        """D√©tection de patterns avec LLM"""
        
        prompt = f"""
        D√©tectez les patterns de design dans ce code Python:
        
        ```python
        {code[:2000]}
        ```
        
        Identifiez:
        1. Patterns GoF utilis√©s
        2. Patterns architecturaux
        3. Anti-patterns pr√©sents
        4. Recommandations d'am√©lioration
        """
        
        try:
            llm_request = LLMRequest(
                prompt=prompt,
                system="Tu es un expert en patterns de design logiciel.",
                temperature=0.2,
                max_tokens=600
            )
            
            response = await self.llm_gateway.process_request(llm_request)
            
            if response.success:
                return {
                    "patterns_detected": ["factory", "observer"],
                    "architectural_patterns": ["mvc"],
                    "anti_patterns": [],
                    "pattern_quality_score": 8.0,
                    "llm_analysis": response.content
                }
            else:
                return {"patterns_detected": [], "error": "LLM analysis failed"}
                
        except Exception as e:
            self.logger.error(f"Pattern detection failed: {e}")
            return {"patterns_detected": [], "error": str(e)}

    async def _generate_improvement_suggestions_llm(self, code: str, llm_analysis: Dict, pattern_detection: Dict) -> List[str]:
        """G√©n√®re des suggestions d'am√©lioration avec LLM"""
        
        suggestions = []
        
        # Suggestions bas√©es sur l'analyse
        if pattern_detection.get("anti_patterns"):
            suggestions.extend([f"Corriger anti-pattern: {ap}" for ap in pattern_detection["anti_patterns"]])
        
        # Suggestions g√©n√©riques
        if "async def" not in code:
            suggestions.append("Consid√©rer l'ajout de m√©thodes asynchrones")
        
        if "logging" not in code.lower():
            suggestions.append("Ajouter un syst√®me de logging")
        
        if "try:" not in code:
            suggestions.append("Am√©liorer la gestion d'erreurs")
        
        return suggestions

    async def _generate_optimizations_llm(self, code: str, goals: List[str], performance_analysis: Dict) -> Dict:
        """G√©n√®re les optimisations avec LLM"""
        
        optimizations = {
            "performance": [],
            "readability": [],
            "maintainability": []
        }
        
        # Optimisations bas√©es sur l'analyse de performance
        bottlenecks = performance_analysis.get("bottlenecks", [])
        
        if "file I/O operations" in bottlenecks:
            optimizations["performance"].append("Utiliser async file I/O")
        
        if "synchronous calls" in bottlenecks:
            optimizations["performance"].append("Convertir en appels asynchrones")
        
        # Optimisations de lisibilit√©
        if "readability" in goals:
            optimizations["readability"].extend([
                "Ajouter des docstrings d√©taill√©es",
                "Am√©liorer les noms de variables",
                "Structurer le code en modules"
            ])
        
        # Optimisations de maintenabilit√©
        if "maintainability" in goals:
            optimizations["maintainability"].extend([
                "Ajouter des tests unitaires",
                "Impl√©menter le pattern Strategy",
                "S√©parer les responsabilit√©s"
            ])
        
        return optimizations

    async def _create_optimization_plan(self, code: str, optimizations: Dict) -> Dict:
        """Cr√©e un plan d'optimisation"""
        
        plan = {
            "total_optimizations": sum(len(opts) for opts in optimizations.values()),
            "priority_order": [],
            "estimated_effort": {},
            "implementation_steps": []
        }
        
        # Prioriser les optimisations
        for category, opts in optimizations.items():
            for opt in opts:
                plan["priority_order"].append({
                    "category": category,
                    "optimization": opt,
                    "priority": "high" if category == "performance" else "medium"
                })
                plan["estimated_effort"][opt] = "2-4 hours"
        
        return plan

    async def _estimate_optimization_impact_llm(self, optimization_plan: Dict, performance_analysis: Dict) -> Dict:
        """Estime l'impact des optimisations"""
        
        current_score = performance_analysis.get("performance_score", 6.0)
        total_optimizations = optimization_plan.get("total_optimizations", 0)
        
        # Estimation simple bas√©e sur le nombre d'optimisations
        estimated_improvement = min(total_optimizations * 0.5, 3.0)
        estimated_new_score = min(current_score + estimated_improvement, 10.0)
        
        return {
            "current_performance_score": current_score,
            "estimated_new_score": estimated_new_score,
            "estimated_improvement": estimated_improvement,
            "confidence": 0.7,
            "impact_areas": ["performance", "maintainability", "readability"]
        }

    async def _save_optimization_plan(self, agent_path: str, optimization_result: Dict):
        """Sauvegarde le plan d'optimisation"""
        try:
            await self.context_store.store_mission_context(
                mission_id=f"optimization_{hash(agent_path)}",
                context=optimization_result,
                metadata={
                    "type": "optimization_plan",
                    "agent_path": agent_path,
                    "timestamp": datetime.now().isoformat()
                }
            )
        except Exception as e:
            self.logger.warning(f"Failed to save optimization plan: {e}")

    async def _analyze_refactoring_needs_llm(self, code: str, objectives: List[str]) -> Dict:
        """Analyse les besoins de refactoring avec LLM"""
        
        return {
            "refactoring_score": 7.0,
            "complexity_issues": ["long methods", "deep nesting"],
            "structural_issues": ["tight coupling"],
            "maintainability_issues": ["lack of tests"],
            "recommended_patterns": ["strategy", "factory"],
            "priority_level": "medium"
        }

    async def _generate_agent_refactoring_plan_llm(self, agent_path: str, code: str, analysis: Dict) -> Dict:
        """G√©n√®re un plan de refactoring pour un agent"""
        
        return {
            "agent_path": agent_path,
            "refactoring_steps": [
                "Extract methods from long functions",
                "Implement error handling pattern",
                "Add comprehensive logging",
                "Create unit tests"
            ],
            "estimated_effort": "1-2 days",
            "risk_level": "low",
            "dependencies": []
        }

    async def _generate_global_refactoring_plan_llm(self, agent_plans: List[Dict], objectives: List[str]) -> Dict:
        """G√©n√®re un plan de refactoring global"""
        
        return {
            "total_agents": len(agent_plans),
            "global_steps": [
                "Phase 1: Low-risk refactoring",
                "Phase 2: Structural improvements", 
                "Phase 3: Pattern implementation"
            ],
            "total_estimated_effort": f"{len(agent_plans) * 2} days",
            "coordination_requirements": ["code review", "testing"],
            "success_criteria": ["improved maintainability", "reduced complexity"]
        }

    async def _save_refactoring_plan(self, refactoring_result: Dict):
        """Sauvegarde le plan de refactoring"""
        try:
            await self.context_store.store_mission_context(
                mission_id=f"refactoring_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                context=refactoring_result,
                metadata={
                    "type": "refactoring_plan",
                    "timestamp": datetime.now().isoformat()
                }
            )
        except Exception as e:
            self.logger.warning(f"Failed to save refactoring plan: {e}")

    async def _save_session_data(self):
        """Sauvegarde les donn√©es de session"""
        
        session_data = {
            "metrics": self.metrics,
            "pattern_cache_size": len(self.pattern_cache),
            "compliance_rules": self.compliance_rules,
            "timestamp": datetime.now().isoformat()
        }
        
        session_file = self.reports_dir / f"session_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        
        try:
            with open(session_file, "w", encoding="utf-8") as f:
                json.dump(session_data, f, indent=2, ensure_ascii=False)
            self.logger.info(f"Session sauvegard√©e: {session_file}")
        except Exception as e:
            self.logger.error(f"Erreur sauvegarde session: {e}")

    async def _analyze_code_structure(self, code: str) -> Dict:
        """Analyse structurelle basique du code"""
        
        try:
            tree = ast.parse(code)
            
            classes = []
            functions = []
            imports = []
            
            for node in ast.walk(tree):
                if isinstance(node, ast.ClassDef):
                    classes.append(node.name)
                elif isinstance(node, ast.FunctionDef):
                    functions.append(node.name)
                elif isinstance(node, ast.Import):
                    imports.extend([alias.name for alias in node.names])
                elif isinstance(node, ast.ImportFrom):
                    if node.module:
                        imports.append(node.module)
            
            return {
                "classes": classes,
                "functions": functions,
                "imports": imports,
                "line_count": len(code.splitlines()),
                "has_async": "async def" in code,
                "structural_analysis_success": True
            }
            
        except Exception as e:
            self.logger.warning(f"Structural analysis failed: {e}")
            return {
                "structural_analysis_success": False,
                "error": str(e)
            }

    # Interface Legacy pour compatibilit√©
    async def execute_task(self, task: Task) -> Result:
        """Interface legacy pour compatibilit√©"""
        return await self.execute_async(task)

    def get_capabilities(self) -> List[str]:
        """Retourne les capacit√©s de l'agent moderne"""
        return [
            "llm_enhanced_pattern_analysis",
            "ai_powered_code_generation", 
            "intelligent_compliance_validation",
            "context_aware_template_generation",
            "real_time_pattern_optimization",
            "automated_refactoring_suggestions",
            "modern_architecture_support",
            "legacy_compatibility"
        ]

# Factory functions
def create_modern_agent_109_pattern_factory_version(**kwargs) -> ModernAgentPatternFactoryVersion:
    """Cr√©e une instance moderne du Pattern Factory"""
    return ModernAgentPatternFactoryVersion(**kwargs)

# Aliases pour compatibilit√©
ModernPatternFactory = ModernAgentPatternFactoryVersion
ModernAgent109 = ModernAgentPatternFactoryVersion