"""
üîí ANALYSEUR DE S√âCURIT√â - Agent 09
====================================

üéØ Mission : D√©tecter et analyser les vuln√©rabilit√©s de s√©curit√© dans le code et les syst√®mes.
‚ö° Capacit√©s : 
- Analyse statique de code Python
- Audit de s√©curit√© universel de fichiers/r√©pertoires
- D√©tection de secrets et donn√©es sensibles
- Analyse des d√©pendances et configurations
- G√©n√©ration de rapports d√©taill√©s
- Recommandations de correction automatis√©es

üè¢ √âquipe : NextGeneration Tools Migration
üìä Int√©gration : Compatible avec le syst√®me de logging centralis√©

Author: √âquipe de Maintenance NextGeneration
Version: 2.3.0 (S√©curit√© renforc√©e et optimis√©e)
"""

import ast
import re
import hashlib
import logging
import json
import uuid
import os
import sys
import time
from typing import List, Dict, Any, Optional, Union, Set, Tuple, Callable
from pathlib import Path
from datetime import datetime
from dataclasses import dataclass, asdict, field
from enum import Enum
import subprocess
from concurrent.futures import ThreadPoolExecutor, as_completed
import asyncio
import yaml
import traceback

from core.agent_factory_architecture import Agent, Task, Result
# Gestion du logging avec fallback
try:
    from core.manager import LoggingManager
except ImportError:
    LoggingManager = None

# Imports optionnels pour fonctionnalit√©s avanc√©es
try:
    import bandit
    BANDIT_AVAILABLE = True
except ImportError:
    BANDIT_AVAILABLE = False

try:
    from safety import safety
    SAFETY_CHECK_AVAILABLE = True
except ImportError:
    SAFETY_CHECK_AVAILABLE = False

# --- D√©but: √âl√©ments int√©gr√©s depuis Agent 18 ---
class SecurityLevel(Enum):
    """Niveaux de s√©curit√© √©tendus"""
    CRITICAL = "critique"
    HIGH = "haut"
    MEDIUM = "moyen"
    LOW = "bas"
    INFO = "information"
    SECURE = "s√©curis√©"

    @classmethod
    def from_cvss(cls, score: float) -> 'SecurityLevel':
        """Convertit un score CVSS en niveau de s√©curit√©"""
        if score >= 9.0: return cls.CRITICAL
        elif score >= 7.0: return cls.HIGH
        elif score >= 4.0: return cls.MEDIUM
        elif score >= 0.1: return cls.LOW
        return cls.INFO

    @classmethod
    def from_bandit_level(cls, level: str) -> 'SecurityLevel':
        """Convertit un niveau Bandit en niveau de s√©curit√©"""
        mapping = {
            'HIGH': cls.HIGH,
            'MEDIUM': cls.MEDIUM,
            'LOW': cls.LOW
        }
        return mapping.get(level.upper(), cls.INFO)

@dataclass
class SecurityContext:
    """Contexte de s√©curit√© pour l'analyse"""
    scan_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    scan_type: str = "security_scan"
    scan_start: datetime = field(default_factory=datetime.now)
    scan_end: Optional[datetime] = None
    target_path: Optional[str] = None
    excluded_paths: Set[str] = field(default_factory=set)
    config: Dict[str, Any] = field(default_factory=dict)
    scan_depth: int = 1
    max_files: int = 1000
    current_file_count: int = 0
    findings_count: Dict[str, int] = field(default_factory=lambda: {
        level.value: 0 for level in SecurityLevel
    })
    error_count: int = 0
    max_errors: int = 50
    scan_status: str = "initializing"
    scan_progress: float = 0.0
    scan_errors: List[Dict[str, Any]] = field(default_factory=list)
    scan_warnings: List[Dict[str, Any]] = field(default_factory=list)
    
    # Nouveaux champs
    scan_mode: str = "standard"  # standard, approfondi, rapide
    scan_priority: int = 1  # 1 (basse) √† 5 (haute)
    scan_tags: Set[str] = field(default_factory=set)
    scan_metadata: Dict[str, Any] = field(default_factory=dict)
    scan_history: List[Dict[str, Any]] = field(default_factory=list)
    scan_checkpoints: List[Dict[str, Any]] = field(default_factory=list)
    scan_metrics: Dict[str, float] = field(default_factory=dict)
    scan_dependencies: Set[str] = field(default_factory=set)
    scan_environment: Dict[str, str] = field(default_factory=dict)
    scan_requirements: Dict[str, Any] = field(default_factory=dict)
    scan_timeouts: Dict[str, int] = field(default_factory=lambda: {
        'file_scan': 30,  # secondes
        'dependency_check': 300,
        'config_audit': 60,
        'total_scan': 3600
    })
    
    # Nouveaux champs pour la gestion des erreurs et avertissements
    error_categories: Dict[str, int] = field(default_factory=lambda: {
        'syntax': 0,
        'configuration': 0,
        'permission': 0,
        'timeout': 0,
        'dependency': 0,
        'network': 0,
        'system': 0,
        'other': 0
    })
    warning_categories: Dict[str, int] = field(default_factory=lambda: {
        'deprecated': 0,
        'performance': 0,
        'best_practice': 0,
        'compatibility': 0,
        'documentation': 0,
        'other': 0
    })
    error_thresholds: Dict[str, int] = field(default_factory=lambda: {
        'syntax': 10,
        'configuration': 5,
        'permission': 3,
        'timeout': 5,
        'dependency': 5,
        'network': 3,
        'system': 3,
        'other': 10
    })
    warning_thresholds: Dict[str, int] = field(default_factory=lambda: {
        'deprecated': 20,
        'performance': 15,
        'best_practice': 25,
        'compatibility': 10,
        'documentation': 20,
        'other': 15
    })
    error_handlers: Dict[str, Callable] = field(default_factory=dict)
    warning_handlers: Dict[str, Callable] = field(default_factory=dict)
    retry_policies: Dict[str, Dict[str, Any]] = field(default_factory=lambda: {
        'file_scan': {'max_retries': 3, 'delay': 1},
        'dependency_check': {'max_retries': 2, 'delay': 5},
        'config_audit': {'max_retries': 2, 'delay': 2}
    })
    error_recovery_strategies: Dict[str, str] = field(default_factory=lambda: {
        'syntax': 'skip',
        'configuration': 'retry',
        'permission': 'escalate',
        'timeout': 'retry',
        'dependency': 'fallback',
        'network': 'retry',
        'system': 'abort',
        'other': 'log'
    })
    
    def update_findings_count(self, level: SecurityLevel) -> None:
        """Met √† jour le compteur de findings par niveau"""
        try:
            self.findings_count[level.value] += 1
            self._log_finding_update(level)
        except KeyError:
            logging.warning(f"Niveau de s√©curit√© inconnu: {level}")
            self.findings_count['autre'] = self.findings_count.get('autre', 0) + 1
            
    def _log_finding_update(self, level: SecurityLevel) -> None:
        """Enregistre la mise √† jour dans l'historique"""
        self.scan_history.append({
            'timestamp': datetime.now().isoformat(),
            'event_type': 'finding_update',
            'level': level.value,
            'count': self.findings_count[level.value]
        })
    
    def is_scan_limit_reached(self) -> bool:
        """V√©rifie si la limite de fichiers scann√©s est atteinte"""
        return self.current_file_count >= self.max_files
    
    def is_error_limit_reached(self) -> bool:
        """V√©rifie si la limite d'erreurs est atteinte"""
        return self.error_count >= self.max_errors
        
    def add_error(self, error: str, category: str = 'other', details: Optional[Dict[str, Any]] = None) -> None:
        """Ajoute une erreur au contexte avec cat√©gorisation"""
        if category not in self.error_categories:
            category = 'other'
            
        error_entry = {
            'timestamp': datetime.now().isoformat(),
            'error': error,
            'category': category,
            'details': details or {},
            'scan_mode': self.scan_mode,
            'current_progress': self.scan_progress
        }
        
        self.scan_errors.append(error_entry)
        self.error_categories[category] += 1
        self.error_count += 1
        
        # Mise √† jour des m√©triques
        self._update_metrics('error_rate', self.error_count / max(1, self.current_file_count))
        self._update_metrics(f'error_rate_{category}', 
                           self.error_categories[category] / max(1, self.current_file_count))
        
        # V√©rification des seuils et application de la strat√©gie de r√©cup√©ration
        if self.error_categories[category] >= self.error_thresholds[category]:
            self._apply_error_recovery_strategy(category)
            
        # Ex√©cution du handler sp√©cifique si d√©fini
        if category in self.error_handlers:
            try:
                self.error_handlers[category](error_entry)
            except Exception as e:
                logging.error(f"Erreur dans le handler d'erreur {category}: {str(e)}")
    
    def add_warning(self, warning: str, category: str = 'other', details: Optional[Dict[str, Any]] = None) -> None:
        """Ajoute un avertissement au contexte avec cat√©gorisation"""
        if category not in self.warning_categories:
            category = 'other'
            
        warning_entry = {
            'timestamp': datetime.now().isoformat(),
            'warning': warning,
            'category': category,
            'details': details or {},
            'scan_mode': self.scan_mode,
            'current_progress': self.scan_progress
        }
        
        self.scan_warnings.append(warning_entry)
        self.warning_categories[category] += 1
        self.warning_count = len(self.scan_warnings)
        
        # Mise √† jour des m√©triques
        self._update_metrics('warning_rate', self.warning_count / max(1, self.current_file_count))
        self._update_metrics(f'warning_rate_{category}', 
                           self.warning_categories[category] / max(1, self.current_file_count))
        
        # V√©rification des seuils
        if self.warning_categories[category] >= self.warning_thresholds[category]:
            self._handle_warning_threshold_exceeded(category)
            
        # Ex√©cution du handler sp√©cifique si d√©fini
        if category in self.warning_handlers:
            try:
                self.warning_handlers[category](warning_entry)
            except Exception as e:
                logging.error(f"Erreur dans le handler d'avertissement {category}: {str(e)}")
    
    def _apply_error_recovery_strategy(self, category: str) -> None:
        """Applique la strat√©gie de r√©cup√©ration pour une cat√©gorie d'erreur"""
        strategy = self.error_recovery_strategies.get(category, 'log')
        
        if strategy == 'skip':
            self._skip_current_operation()
        elif strategy == 'retry':
            self._retry_operation(category)
        elif strategy == 'escalate':
            self._escalate_error(category)
        elif strategy == 'fallback':
            self._use_fallback_solution(category)
        elif strategy == 'abort':
            self._abort_scan(category)
        else:  # 'log'
            self._log_error_threshold_exceeded(category)
    
    def _handle_warning_threshold_exceeded(self, category: str) -> None:
        """G√®re le d√©passement de seuil d'avertissements"""
        logging.warning(f"Seuil d'avertissements d√©pass√© pour la cat√©gorie {category}")
        
        self.scan_history.append({
            'timestamp': datetime.now().isoformat(),
            'event_type': 'warning_threshold_exceeded',
            'category': category,
            'count': self.warning_categories[category]
        })
        
        # Ajout d'une m√©trique de qualit√©
        quality_impact = min(1.0, self.warning_categories[category] / 
                           self.warning_thresholds[category])
        self._update_metrics(f'quality_impact_{category}', quality_impact)
    
    def _skip_current_operation(self) -> None:
        """Ignore l'op√©ration en cours"""
        self.scan_history.append({
            'timestamp': datetime.now().isoformat(),
            'event_type': 'operation_skipped',
            'current_file': self.current_file_count
        })
        
    def _retry_operation(self, category: str) -> None:
        """Tente de r√©essayer l'op√©ration"""
        policy = self.retry_policies.get(category, {'max_retries': 3, 'delay': 1})
        self.scan_metadata[f'retry_count_{category}'] = \
            self.scan_metadata.get(f'retry_count_{category}', 0) + 1
            
        if self.scan_metadata[f'retry_count_{category}'] <= policy['max_retries']:
            time.sleep(policy['delay'])
            # La logique de retry sera impl√©ment√©e par l'appelant
            
    def _escalate_error(self, category: str) -> None:
        """Escalade l'erreur au niveau sup√©rieur"""
        logging.error(f"Escalade des erreurs de cat√©gorie {category}")
        # Notification ou alerte √† impl√©menter selon le contexte
        
    def _use_fallback_solution(self, category: str) -> None:
        """Utilise une solution de repli"""
        logging.info(f"Utilisation de la solution de repli pour {category}")
        # Solution de repli √† impl√©menter selon le contexte
        
    def _abort_scan(self, category: str) -> None:
        """Arr√™te le scan en cours"""
        self.scan_status = "aborted"
        self.scan_end = datetime.now()
        logging.error(f"Scan arr√™t√© d√ª aux erreurs de cat√©gorie {category}")
        
    def _log_error_threshold_exceeded(self, category: str) -> None:
        """Enregistre le d√©passement de seuil d'erreurs"""
        logging.error(f"Seuil d'erreurs d√©pass√© pour la cat√©gorie {category}")
        
        self.scan_history.append({
            'timestamp': datetime.now().isoformat(),
            'event_type': 'error_threshold_exceeded',
            'category': category,
            'count': self.error_categories[category]
        })
    
    def update_progress(self, progress: float) -> None:
        """Met √† jour la progression du scan"""
        self.scan_progress = min(100.0, max(0.0, progress))
        self._add_checkpoint()
        
    def _add_checkpoint(self) -> None:
        """Ajoute un point de contr√¥le"""
        checkpoint = {
            'timestamp': datetime.now().isoformat(),
            'progress': self.scan_progress,
            'files_scanned': self.current_file_count,
            'findings_count': self.findings_count.copy(),
            'error_count': self.error_count,
            'status': self.scan_status
        }
        self.scan_checkpoints.append(checkpoint)
        
    def update_status(self, status: str) -> None:
        """Met √† jour le statut du scan"""
        old_status = self.scan_status
        self.scan_status = status
        
        self.scan_history.append({
            'timestamp': datetime.now().isoformat(),
            'event_type': 'status_change',
            'old_status': old_status,
            'new_status': status
        })
        
    def should_exclude_path(self, path: str) -> bool:
        """V√©rifie si un chemin doit √™tre exclu"""
        path = str(path)
        
        # V√©rification des motifs d'exclusion
        for excluded in self.excluded_paths:
            if '*' in excluded:
                if re.match(excluded.replace('*', '.*'), path):
                    return True
            elif excluded in path:
                return True
                
        return False
    
    def validate_config(self) -> Tuple[bool, List[str]]:
        """Valide la configuration du contexte"""
        errors = []
        
        # Validation des champs num√©riques
        if self.scan_depth < 1:
            errors.append("La profondeur de scan doit √™tre >= 1")
        if self.max_files < 1:
            errors.append("Le nombre maximum de fichiers doit √™tre >= 1")
        if self.max_errors < 1:
            errors.append("Le nombre maximum d'erreurs doit √™tre >= 1")
        if not (1 <= self.scan_priority <= 5):
            errors.append("La priorit√© doit √™tre entre 1 et 5")
            
        # Validation des timeouts
        for key, value in self.scan_timeouts.items():
            if value <= 0:
                errors.append(f"Le timeout {key} doit √™tre > 0")
                
        # Validation des types
        if not isinstance(self.excluded_paths, set):
            errors.append("excluded_paths doit √™tre un ensemble")
        if not isinstance(self.scan_tags, set):
            errors.append("scan_tags doit √™tre un ensemble")
            
        # Validation du mode de scan
        if self.scan_mode not in ['standard', 'approfondi', 'rapide']:
            errors.append("Mode de scan invalide")
            
        return len(errors) == 0, errors
    
    def _update_metrics(self, metric_name: str, value: float) -> None:
        """Met √† jour les m√©triques de scan"""
        self.scan_metrics[metric_name] = value
        
        # Calcul des m√©triques d√©riv√©es
        if 'error_rate' in self.scan_metrics and 'warning_rate' in self.scan_metrics:
            self.scan_metrics['health_score'] = 100 * (
                1 - (self.scan_metrics['error_rate'] + self.scan_metrics['warning_rate']) / 2
            )
    
    def add_dependency(self, dependency: str) -> None:
        """Ajoute une d√©pendance au scan"""
        self.scan_dependencies.add(dependency)
        
    def set_environment(self, key: str, value: str) -> None:
        """D√©finit une variable d'environnement pour le scan"""
        self.scan_environment[key] = value
        
    def add_requirement(self, key: str, value: Any) -> None:
        """Ajoute une exigence pour le scan"""
        self.scan_requirements[key] = value
        
    def get_timeout(self, operation: str) -> int:
        """R√©cup√®re le timeout pour une op√©ration"""
        return self.scan_timeouts.get(operation, self.scan_timeouts.get('total_scan', 3600))
    
    def to_dict(self) -> Dict[str, Any]:
        """Convertit le contexte en dictionnaire"""
        return {
            'scan_id': self.scan_id,
            'scan_type': self.scan_type,
            'scan_start': self.scan_start.isoformat(),
            'scan_end': self.scan_end.isoformat() if self.scan_end else None,
            'target_path': self.target_path,
            'excluded_paths': list(self.excluded_paths),
            'config': self.config,
            'scan_depth': self.scan_depth,
            'max_files': self.max_files,
            'current_file_count': self.current_file_count,
            'findings_count': self.findings_count,
            'error_count': self.error_count,
            'scan_status': self.scan_status,
            'scan_progress': self.scan_progress,
            'scan_errors': self.scan_errors,
            'scan_warnings': self.scan_warnings,
            'scan_mode': self.scan_mode,
            'scan_priority': self.scan_priority,
            'scan_tags': list(self.scan_tags),
            'scan_metadata': self.scan_metadata,
            'scan_history': self.scan_history,
            'scan_checkpoints': self.scan_checkpoints,
            'scan_metrics': self.scan_metrics,
            'scan_dependencies': list(self.scan_dependencies),
            'scan_environment': self.scan_environment,
            'scan_requirements': self.scan_requirements,
            'scan_timeouts': self.scan_timeouts
        }
        
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'SecurityContext':
        """Cr√©e un contexte √† partir d'un dictionnaire"""
        context = cls()
        
        # Conversion des dates
        if 'scan_start' in data:
            context.scan_start = datetime.fromisoformat(data['scan_start'])
        if 'scan_end' in data and data['scan_end']:
            context.scan_end = datetime.fromisoformat(data['scan_end'])
            
        # Conversion des ensembles
        if 'excluded_paths' in data:
            context.excluded_paths = set(data['excluded_paths'])
        if 'scan_tags' in data:
            context.scan_tags = set(data['scan_tags'])
        if 'scan_dependencies' in data:
            context.scan_dependencies = set(data['scan_dependencies'])
            
        # Copie des attributs simples
        for attr in ['scan_id', 'scan_type', 'target_path', 'scan_depth',
                    'max_files', 'current_file_count', 'error_count',
                    'scan_status', 'scan_progress', 'scan_mode', 'scan_priority']:
            if attr in data:
                setattr(context, attr, data[attr])
                
        # Copie des dictionnaires
        for attr in ['config', 'findings_count', 'scan_metadata', 'scan_metrics',
                    'scan_environment', 'scan_requirements', 'scan_timeouts']:
            if attr in data:
                setattr(context, attr, data[attr].copy())
                
        # Copie des listes
        for attr in ['scan_errors', 'scan_warnings', 'scan_history', 'scan_checkpoints']:
            if attr in data:
                setattr(context, attr, data[attr][:])
                
        return context

class VulnerabilityType(Enum):
    """Types de vuln√©rabilit√©s √©tendus avec descriptions et guides de rem√©diation"""
    # Vuln√©rabilit√©s OWASP Top 10
    INJECTION = "injection"
    XSS = "xss"
    BROKEN_AUTH = "authentification_cass√©e"
    SENSITIVE_DATA = "donn√©es_sensibles"
    XXE = "xxe"
    BROKEN_ACCESS = "contr√¥le_acc√®s_cass√©"
    MISCONFIGURATION = "mauvaise_configuration"
    INSECURE_DESERIALIZATION = "d√©s√©rialisation_non_s√©curis√©e"
    VULNERABLE_COMPONENTS = "composants_vuln√©rables"
    INSUFFICIENT_LOGGING = "journalisation_insuffisante"
    
    # Vuln√©rabilit√©s sp√©cifiques
    HARDCODED_SECRET = "secret_en_dur"
    WEAK_CRYPTO = "cryptographie_faible"
    FILE_TRAVERSAL = "travers√©e_de_fichier"
    DANGEROUS_FUNCTION = "fonction_dangereuse"
    PATH_INJECTION = "injection_de_chemin"
    XML_VULNERABILITIES = "vuln√©rabilit√©s_xml"
    INSECURE_PROTOCOLS = "protocoles_non_s√©curis√©s"
    INSECURE_FILE_OPERATION = "operation_fichier_non_securisee"
    INSECURE_FILE_PERMISSION = "permission_fichier_non_securisee"
    BROAD_EXCEPTION = "exception_large"
    ASSERTION_ISSUE = "probleme_assertion"
    
    # Nouvelles cat√©gories
    DEPENDENCY_VULNERABILITY = "vuln√©rabilit√©_d√©pendance"
    CONFIG_VULNERABILITY = "vuln√©rabilit√©_configuration"
    API_VULNERABILITY = "vuln√©rabilit√©_api"
    DOCKER_VULNERABILITY = "vuln√©rabilit√©_docker"
    CI_CD_VULNERABILITY = "vuln√©rabilit√©_ci_cd"
    CLOUD_VULNERABILITY = "vuln√©rabilit√©_cloud"
    CONTAINER_VULNERABILITY = "vuln√©rabilit√©_conteneur"
    KUBERNETES_VULNERABILITY = "vuln√©rabilit√©_kubernetes"
    DATABASE_VULNERABILITY = "vuln√©rabilit√©_base_donn√©es"
    NETWORK_VULNERABILITY = "vuln√©rabilit√©_r√©seau"
    AUTHENTICATION_VULNERABILITY = "vuln√©rabilit√©_authentification"
    AUTHORIZATION_VULNERABILITY = "vuln√©rabilit√©_autorisation"
    CRYPTOGRAPHIC_VULNERABILITY = "vuln√©rabilit√©_cryptographique"
    INPUT_VALIDATION_VULNERABILITY = "vuln√©rabilit√©_validation_entr√©e"
    OUTPUT_ENCODING_VULNERABILITY = "vuln√©rabilit√©_encodage_sortie"
    SESSION_MANAGEMENT_VULNERABILITY = "vuln√©rabilit√©_gestion_session"
    ERROR_HANDLING_VULNERABILITY = "vuln√©rabilit√©_gestion_erreurs"
    LOGGING_VULNERABILITY = "vuln√©rabilit√©_journalisation"
    
    # Nouvelles cat√©gories cloud et infrastructure
    AWS_VULNERABILITY = "vuln√©rabilit√©_aws"
    AZURE_VULNERABILITY = "vuln√©rabilit√©_azure"
    GCP_VULNERABILITY = "vuln√©rabilit√©_gcp"
    TERRAFORM_VULNERABILITY = "vuln√©rabilit√©_terraform"
    ANSIBLE_VULNERABILITY = "vuln√©rabilit√©_ansible"
    HELM_VULNERABILITY = "vuln√©rabilit√©_helm"
    
    # Nouvelles cat√©gories applicatives
    FRONTEND_VULNERABILITY = "vuln√©rabilit√©_frontend"
    BACKEND_VULNERABILITY = "vuln√©rabilit√©_backend"
    MOBILE_VULNERABILITY = "vuln√©rabilit√©_mobile"
    MICROSERVICE_VULNERABILITY = "vuln√©rabilit√©_microservice"
    API_GATEWAY_VULNERABILITY = "vuln√©rabilit√©_api_gateway"
    SERVICE_MESH_VULNERABILITY = "vuln√©rabilit√©_service_mesh"
    
    # Nouvelles cat√©gories donn√©es
    DATA_PRIVACY_VULNERABILITY = "vuln√©rabilit√©_confidentialit√©_donn√©es"
    DATA_INTEGRITY_VULNERABILITY = "vuln√©rabilit√©_int√©grit√©_donn√©es"
    DATA_AVAILABILITY_VULNERABILITY = "vuln√©rabilit√©_disponibilit√©_donn√©es"
    DATA_ENCRYPTION_VULNERABILITY = "vuln√©rabilit√©_chiffrement_donn√©es"
    DATA_BACKUP_VULNERABILITY = "vuln√©rabilit√©_sauvegarde_donn√©es"
    DATA_COMPLIANCE_VULNERABILITY = "vuln√©rabilit√©_conformit√©_donn√©es"
    
    # Nouvelles cat√©gories sp√©cifiques aux frameworks
    DJANGO_VULNERABILITY = "vuln√©rabilit√©_django"
    FLASK_VULNERABILITY = "vuln√©rabilit√©_flask"
    FASTAPI_VULNERABILITY = "vuln√©rabilit√©_fastapi"
    SPRING_VULNERABILITY = "vuln√©rabilit√©_spring"
    REACT_VULNERABILITY = "vuln√©rabilit√©_react"
    VUE_VULNERABILITY = "vuln√©rabilit√©_vue"
    ANGULAR_VULNERABILITY = "vuln√©rabilit√©_angular"
    
    # Nouvelles cat√©gories DevSecOps
    PIPELINE_VULNERABILITY = "vuln√©rabilit√©_pipeline"
    REGISTRY_VULNERABILITY = "vuln√©rabilit√©_registry"
    ARTIFACT_VULNERABILITY = "vuln√©rabilit√©_artifact"
    SECRET_MANAGEMENT_VULNERABILITY = "vuln√©rabilit√©_gestion_secrets"
    RBAC_VULNERABILITY = "vuln√©rabilit√©_rbac"
    MONITORING_VULNERABILITY = "vuln√©rabilit√©_monitoring"
    
    # Cat√©gorie par d√©faut
    OTHER = "autre"
    
    @classmethod
    def from_cwe(cls, cwe_id: str) -> Optional['VulnerabilityType']:
        """Convertit un CWE ID en type de vuln√©rabilit√©"""
        cwe_mapping = {
            'CWE-89': cls.INJECTION,  # SQL Injection
            'CWE-79': cls.XSS,  # Cross-site Scripting
            'CWE-287': cls.BROKEN_AUTH,  # Improper Authentication
            'CWE-256': cls.SENSITIVE_DATA,  # Plaintext Storage of Password
            'CWE-611': cls.XXE,  # XML External Entity Reference
            'CWE-285': cls.BROKEN_ACCESS,  # Improper Authorization
            'CWE-16': cls.MISCONFIGURATION,  # Configuration
            'CWE-502': cls.INSECURE_DESERIALIZATION,  # Deserialization of Untrusted Data
            'CWE-1104': cls.VULNERABLE_COMPONENTS,  # Use of Unmaintained Third Party Components
            'CWE-778': cls.INSUFFICIENT_LOGGING,  # Insufficient Logging
            'CWE-798': cls.HARDCODED_SECRET,  # Use of Hard-coded Credentials
            'CWE-326': cls.WEAK_CRYPTO,  # Inadequate Encryption Strength
            'CWE-22': cls.FILE_TRAVERSAL,  # Path Traversal
            'CWE-676': cls.DANGEROUS_FUNCTION,  # Use of Potentially Dangerous Function
            'CWE-73': cls.PATH_INJECTION,  # External Control of File Name or Path
            'CWE-611': cls.XML_VULNERABILITIES,  # Improper Restriction of XML External Entity Reference
            'CWE-319': cls.INSECURE_PROTOCOLS,  # Cleartext Transmission of Sensitive Information
            'CWE-732': cls.INSECURE_FILE_PERMISSION,  # Incorrect Permission Assignment for Critical Resource
            'CWE-396': cls.BROAD_EXCEPTION,  # Declaration of Catch for Generic Exception
            'CWE-703': cls.ASSERTION_ISSUE,  # Improper Check or Handling of Exceptional Conditions
            
            # Nouvelles correspondances
            'CWE-1008': cls.API_VULNERABILITY,  # Architectural Concepts
            'CWE-264': cls.AUTHORIZATION_VULNERABILITY,  # Permissions, Privileges, and Access Controls
            'CWE-311': cls.CRYPTOGRAPHIC_VULNERABILITY,  # Missing Encryption of Sensitive Data
            'CWE-20': cls.INPUT_VALIDATION_VULNERABILITY,  # Improper Input Validation
            'CWE-116': cls.OUTPUT_ENCODING_VULNERABILITY,  # Improper Encoding or Escaping of Output
            'CWE-384': cls.SESSION_MANAGEMENT_VULNERABILITY,  # Session Fixation
            'CWE-755': cls.ERROR_HANDLING_VULNERABILITY,  # Improper Handling of Exceptional Conditions
            'CWE-532': cls.LOGGING_VULNERABILITY,  # Information Exposure Through Log Files
            
            # Cloud et infrastructure
            'CWE-918': cls.AWS_VULNERABILITY,  # Server-Side Request Forgery (SSRF)
            'CWE-522': cls.AZURE_VULNERABILITY,  # Insufficiently Protected Credentials
            'CWE-668': cls.GCP_VULNERABILITY,  # Exposure of Resource to Wrong Sphere
            'CWE-434': cls.TERRAFORM_VULNERABILITY,  # Unrestricted Upload of File
            'CWE-269': cls.ANSIBLE_VULNERABILITY,  # Improper Privilege Management
            'CWE-494': cls.HELM_VULNERABILITY,  # Download of Code Without Integrity Check
            
            # Application
            'CWE-79': cls.FRONTEND_VULNERABILITY,  # XSS
            'CWE-89': cls.BACKEND_VULNERABILITY,  # SQL Injection
            'CWE-919': cls.MOBILE_VULNERABILITY,  # Weaknesses in Mobile Applications
            'CWE-319': cls.MICROSERVICE_VULNERABILITY,  # Cleartext Transmission
            'CWE-306': cls.API_GATEWAY_VULNERABILITY,  # Missing Authentication
            'CWE-400': cls.SERVICE_MESH_VULNERABILITY,  # Resource Exhaustion
            
            # Donn√©es
            'CWE-359': cls.DATA_PRIVACY_VULNERABILITY,  # Privacy Violation
            'CWE-345': cls.DATA_INTEGRITY_VULNERABILITY,  # Insufficient Verification of Data Authenticity
            'CWE-311': cls.DATA_ENCRYPTION_VULNERABILITY,  # Missing Encryption
            'CWE-530': cls.DATA_BACKUP_VULNERABILITY,  # Exposure of Backup File
            'CWE-200': cls.DATA_COMPLIANCE_VULNERABILITY,  # Information Exposure
        }
        
        # Nettoyage de l'ID CWE
        if not cwe_id.startswith('CWE-'):
            cwe_id = f'CWE-{cwe_id}'
            
        return cwe_mapping.get(cwe_id, cls.OTHER)

    @classmethod
    def from_bandit_id(cls, bandit_id: str) -> Optional['VulnerabilityType']:
        """Convertit un ID Bandit en type de vuln√©rabilit√©"""
        # Mapping Bandit vers VulnerabilityType
        bandit_mapping = {
            'B101': cls.ASSERTION_ISSUE,  # assert used
            'B102': cls.DANGEROUS_FUNCTION,  # exec used
            'B103': cls.DANGEROUS_FUNCTION,  # set bad file permissions
            'B104': cls.HARDCODED_SECRET,  # hardcoded bind all
            'B105': cls.HARDCODED_SECRET,  # hardcoded password string
            'B106': cls.HARDCODED_SECRET,  # hardcoded password funcarg
            'B107': cls.HARDCODED_SECRET,  # hardcoded password default
            'B108': cls.INSECURE_PROTOCOLS,  # hardcoded tmp directory
            'B110': cls.DANGEROUS_FUNCTION,  # try-except-pass
            'B112': cls.DANGEROUS_FUNCTION,  # try-except-continue
            'B201': cls.DANGEROUS_FUNCTION,  # flask debug true
            'B301': cls.DANGEROUS_FUNCTION,  # pickle
            'B302': cls.DANGEROUS_FUNCTION,  # marshal
            'B303': cls.DANGEROUS_FUNCTION,  # md5
            'B304': cls.WEAK_CRYPTO,  # ciphers
            'B305': cls.WEAK_CRYPTO,  # cipher suites
            'B306': cls.WEAK_CRYPTO,  # mktemp_q
            'B307': cls.DANGEROUS_FUNCTION,  # eval
            'B308': cls.DANGEROUS_FUNCTION,  # mark_safe
            'B309': cls.WEAK_CRYPTO,  # httpsconnection
            'B310': cls.WEAK_CRYPTO,  # urllib_urlopen
            'B311': cls.WEAK_CRYPTO,  # random
            'B312': cls.DANGEROUS_FUNCTION,  # telnetlib
            'B313': cls.WEAK_CRYPTO,  # xml_bad_cElementTree
            'B314': cls.WEAK_CRYPTO,  # xml_bad_ElementTree
            'B315': cls.WEAK_CRYPTO,  # xml_bad_expatreader
            'B316': cls.WEAK_CRYPTO,  # xml_bad_expatbuilder
            'B317': cls.WEAK_CRYPTO,  # xml_bad_sax
            'B318': cls.WEAK_CRYPTO,  # xml_bad_minidom
            'B319': cls.WEAK_CRYPTO,  # xml_bad_pulldom
            'B320': cls.WEAK_CRYPTO,  # xml_bad_etree
            'B321': cls.XXE,  # ftplib
            'B322': cls.DANGEROUS_FUNCTION,  # input
            'B323': cls.INSECURE_PROTOCOLS,  # unverified_context
            'B324': cls.WEAK_CRYPTO,  # hashlib_new_insecure_functions
            'B325': cls.WEAK_CRYPTO,  # tempnam
            
            # Nouveaux mappings
            'B401': cls.DEPENDENCY_VULNERABILITY,  # import-subprocess
            'B402': cls.API_VULNERABILITY,  # import-paramiko
            'B403': cls.NETWORK_VULNERABILITY,  # import-pickle
            'B404': cls.DANGEROUS_FUNCTION,  # import-subprocess
            'B405': cls.XML_VULNERABILITIES,  # import-xml
            'B406': cls.WEAK_CRYPTO,  # import-xml-etree
            'B407': cls.WEAK_CRYPTO,  # import-xml-sax
            'B408': cls.WEAK_CRYPTO,  # import-xml-expat
            'B409': cls.WEAK_CRYPTO,  # import-xml-minidom
            'B410': cls.WEAK_CRYPTO,  # import-lxml
            'B411': cls.DANGEROUS_FUNCTION,  # import-xmlrpclib
            'B412': cls.DANGEROUS_FUNCTION,  # import-httplib
            'B413': cls.INSECURE_PROTOCOLS,  # import-pycrypto
            
            # Cloud et infrastructure
            'B501': cls.AWS_VULNERABILITY,  # request-with-no-cert-validation
            'B502': cls.CLOUD_VULNERABILITY,  # ssl-with-bad-version
            'B503': cls.CONTAINER_VULNERABILITY,  # ssl-with-bad-defaults
            'B504': cls.KUBERNETES_VULNERABILITY,  # ssl-with-no-version
            'B505': cls.DOCKER_VULNERABILITY,  # weak-cryptographic-key
            'B506': cls.CI_CD_VULNERABILITY,  # yaml-load
            
            # Application
            'B601': cls.FRONTEND_VULNERABILITY,  # paramiko-calls
            'B602': cls.BACKEND_VULNERABILITY,  # subprocess-popen-with-shell-equals-true
            'B603': cls.API_VULNERABILITY,  # subprocess-without-shell-equals-true
            'B604': cls.MICROSERVICE_VULNERABILITY,  # any-other-function-with-shell-equals-true
            'B605': cls.API_GATEWAY_VULNERABILITY,  # start-process-with-a-shell
            'B606': cls.SERVICE_MESH_VULNERABILITY,  # start-process-with-no-shell
            'B607': cls.NETWORK_VULNERABILITY,  # start-process-with-partial-path
            'B608': cls.DANGEROUS_FUNCTION,  # hardcoded-sql-expressions
            'B609': cls.WEAK_CRYPTO,  # linux-commands-wildcard-injection
            'B610': cls.DANGEROUS_FUNCTION,  # django-extra-used
            'B611': cls.DANGEROUS_FUNCTION,  # django-rawsql-used
            'B701': cls.DANGEROUS_FUNCTION,  # jinja2-autoescape-false
            'B702': cls.DANGEROUS_FUNCTION,  # use-of-mako-templates
            'B703': cls.DANGEROUS_FUNCTION,  # django-mark-safe
            
            # Donn√©es
            'B801': cls.DATA_PRIVACY_VULNERABILITY,  # pycrypto-used
            'B802': cls.DATA_INTEGRITY_VULNERABILITY,  # ssl-insecure-version
            'B803': cls.DATA_ENCRYPTION_VULNERABILITY,  # ssl-no-cert-validation
            'B804': cls.DATA_BACKUP_VULNERABILITY,  # ssl-no-version
            'B805': cls.DATA_COMPLIANCE_VULNERABILITY,  # hardcoded-password-string
        }
        
        return bandit_mapping.get(bandit_id, cls.OTHER)

    @classmethod
    def get_category_description(cls, vuln_type: 'VulnerabilityType') -> str:
        """Retourne une description d√©taill√©e de la cat√©gorie de vuln√©rabilit√©"""
        descriptions = {
            cls.INJECTION: "Injection de code malveillant dans l'application",
            cls.XSS: "Cross-Site Scripting - Injection de scripts c√¥t√© client",
            cls.BROKEN_AUTH: "Probl√®mes dans le m√©canisme d'authentification",
            cls.SENSITIVE_DATA: "Exposition de donn√©es sensibles",
            cls.XXE: "XML External Entity - Vuln√©rabilit√©s li√©es au traitement XML",
            cls.BROKEN_ACCESS: "Contr√¥le d'acc√®s d√©faillant",
            cls.MISCONFIGURATION: "Erreurs de configuration de s√©curit√©",
            cls.INSECURE_DESERIALIZATION: "D√©s√©rialisation non s√©curis√©e d'objets",
            cls.VULNERABLE_COMPONENTS: "Utilisation de composants avec vuln√©rabilit√©s connues",
            cls.INSUFFICIENT_LOGGING: "Journalisation et monitoring insuffisants",
            
            # Descriptions pour les nouvelles cat√©gories
            cls.AWS_VULNERABILITY: "Vuln√©rabilit√©s sp√©cifiques √† AWS",
            cls.AZURE_VULNERABILITY: "Vuln√©rabilit√©s sp√©cifiques √† Azure",
            cls.GCP_VULNERABILITY: "Vuln√©rabilit√©s sp√©cifiques √† Google Cloud",
            cls.TERRAFORM_VULNERABILITY: "Probl√®mes de s√©curit√© dans les configurations Terraform",
            cls.ANSIBLE_VULNERABILITY: "Risques de s√©curit√© dans les playbooks Ansible",
            cls.HELM_VULNERABILITY: "Vuln√©rabilit√©s dans les charts Helm",
            
            cls.FRONTEND_VULNERABILITY: "Vuln√©rabilit√©s c√¥t√© client",
            cls.BACKEND_VULNERABILITY: "Vuln√©rabilit√©s c√¥t√© serveur",
            cls.MOBILE_VULNERABILITY: "Probl√®mes de s√©curit√© sur applications mobiles",
            cls.MICROSERVICE_VULNERABILITY: "Vuln√©rabilit√©s sp√©cifiques aux microservices",
            cls.API_GATEWAY_VULNERABILITY: "Failles de s√©curit√© au niveau de l'API Gateway",
            cls.SERVICE_MESH_VULNERABILITY: "Probl√®mes de s√©curit√© dans le maillage de services",
            
            cls.DATA_PRIVACY_VULNERABILITY: "Violations de la confidentialit√© des donn√©es",
            cls.DATA_INTEGRITY_VULNERABILITY: "Compromission de l'int√©grit√© des donn√©es",
            cls.DATA_AVAILABILITY_VULNERABILITY: "Probl√®mes de disponibilit√© des donn√©es",
            cls.DATA_ENCRYPTION_VULNERABILITY: "Faiblesses dans le chiffrement des donn√©es",
            cls.DATA_BACKUP_VULNERABILITY: "Vuln√©rabilit√©s li√©es aux sauvegardes",
            cls.DATA_COMPLIANCE_VULNERABILITY: "Non-conformit√© aux r√©glementations"
        }
        
        return descriptions.get(vuln_type, "Type de vuln√©rabilit√© non cat√©goris√©")

    @classmethod
    def get_remediation_guide(cls, vuln_type: 'VulnerabilityType') -> Dict[str, Any]:
        """Retourne un guide de rem√©diation pour le type de vuln√©rabilit√©"""
        guides = {
            cls.INJECTION: {
                'titre': "Pr√©vention des injections",
                'description': "Utiliser des requ√™tes param√©tr√©es et valider les entr√©es",
                '√©tapes': [
                    "Utiliser des requ√™tes pr√©par√©es",
                    "√âchapper les caract√®res sp√©ciaux",
                    "Valider toutes les entr√©es utilisateur"
                ],
                'r√©f√©rences': [
                    "OWASP SQL Injection Prevention Cheat Sheet",
                    "CWE-89: SQL Injection"
                ]
            },
            # ... Autres guides de rem√©diation ...
        }
        
        return guides.get(vuln_type, {
            'titre': "Guide g√©n√©rique",
            'description': "Appliquer les bonnes pratiques de s√©curit√©",
            '√©tapes': [
                "Analyser le contexte sp√©cifique",
                "Consulter la documentation",
                "Appliquer les correctifs recommand√©s"
            ],
            'r√©f√©rences': [
                "OWASP Top 10",
                "CWE/SANS Top 25"
            ]
        })

@dataclass
class SecurityFinding:
    """R√©sultat d'audit de s√©curit√© enrichi"""
    finding_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    vulnerability_type: VulnerabilityType = VulnerabilityType.OTHER
    security_level: SecurityLevel = SecurityLevel.INFO
    title: str = ""
    description: str = ""
    location: str = ""
    line_number: Optional[int] = None
    cwe_id: Optional[str] = None
    cvss_score: Optional[float] = None
    remediation: Optional[str] = ""
    evidence: Optional[str] = ""
    context: Dict[str, Any] = field(default_factory=dict)
    references: List[str] = field(default_factory=list)
    affected_components: List[str] = field(default_factory=list)
    detection_time: datetime = field(default_factory=datetime.now)
    false_positive_probability: float = 0.0
    exploit_complexity: str = "unknown"
    patch_availability: bool = False
    patch_complexity: str = "unknown"
    attack_vector: Optional[str] = None
    attack_complexity: Optional[str] = None
    privileges_required: Optional[str] = None
    user_interaction: Optional[str] = None
    scope: Optional[str] = None
    confidentiality_impact: Optional[str] = None
    integrity_impact: Optional[str] = None
    availability_impact: Optional[str] = None
    
    def __post_init__(self):
        """Validation apr√®s initialisation"""
        if not self.title:
            raise ValueError("Le titre est obligatoire")
        if not self.description:
            raise ValueError("La description est obligatoire")
        if not self.location:
            raise ValueError("La localisation est obligatoire")
            
    def add_reference(self, reference: str) -> None:
        """Ajoute une r√©f√©rence de mani√®re s√©curis√©e"""
        if reference and reference not in self.references:
            self.references.append(reference)
            
    def add_affected_component(self, component: str) -> None:
        """Ajoute un composant affect√© de mani√®re s√©curis√©e"""
        if component and component not in self.affected_components:
            self.affected_components.append(component)
            
    def update_cvss(self, score: float) -> None:
        """Met √† jour le score CVSS et le niveau de s√©curit√©"""
        if 0.0 <= score <= 10.0:
            self.cvss_score = score
            self.security_level = SecurityLevel.from_cvss(score)
        else:
            raise ValueError("Le score CVSS doit √™tre entre 0 et 10")
            
    def set_cwe(self, cwe_id: str) -> None:
        """D√©finit le CWE ID et met √† jour le type de vuln√©rabilit√©"""
        if not cwe_id.startswith('CWE-'):
            cwe_id = f'CWE-{cwe_id}'
        self.cwe_id = cwe_id
        
        vuln_type = VulnerabilityType.from_cwe(cwe_id)
        if vuln_type:
            self.vulnerability_type = vuln_type
            
    def calculate_risk_score(self) -> float:
        """Calcule un score de risque personnalis√©"""
        base_score = self.cvss_score or 5.0
        
        # Facteurs d'ajustement
        complexity_factor = {
            'low': 1.2,
            'medium': 1.0,
            'high': 0.8,
            'unknown': 1.0
        }.get(self.attack_complexity or 'unknown')
        
        interaction_factor = {
            'none': 1.2,
            'required': 0.9,
            'unknown': 1.0
        }.get(self.user_interaction or 'unknown')
        
        # Calcul du score ajust√©
        adjusted_score = base_score * complexity_factor * interaction_factor
        
        # R√©duction si patch disponible
        if self.patch_availability:
            adjusted_score *= 0.8
            
        # Ajustement pour faux positifs
        adjusted_score *= (1 - self.false_positive_probability)
        
        return round(min(10.0, max(0.0, adjusted_score)), 2)
    
    def to_dict(self) -> Dict[str, Any]:
        """Convertit le finding en dictionnaire"""
        return {
            'finding_id': self.finding_id,
            'vulnerability_type': self.vulnerability_type.value,
            'security_level': self.security_level.value,
            'title': self.title,
            'description': self.description,
            'location': self.location,
            'line_number': self.line_number,
            'cwe_id': self.cwe_id,
            'cvss_score': self.cvss_score,
            'remediation': self.remediation,
            'evidence': self.evidence,
            'context': self.context,
            'references': self.references,
            'affected_components': self.affected_components,
            'detection_time': self.detection_time.isoformat(),
            'false_positive_probability': self.false_positive_probability,
            'exploit_complexity': self.exploit_complexity,
            'patch_availability': self.patch_availability,
            'patch_complexity': self.patch_complexity,
            'attack_vector': self.attack_vector,
            'attack_complexity': self.attack_complexity,
            'privileges_required': self.privileges_required,
            'user_interaction': self.user_interaction,
            'scope': self.scope,
            'confidentiality_impact': self.confidentiality_impact,
            'integrity_impact': self.integrity_impact,
            'availability_impact': self.availability_impact,
            'risk_score': self.calculate_risk_score()
        }
        
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'SecurityFinding':
        """Cr√©e un finding √† partir d'un dictionnaire"""
        # Conversion des types √©num√©r√©s
        data['vulnerability_type'] = VulnerabilityType(data['vulnerability_type'])
        data['security_level'] = SecurityLevel(data['security_level'])
        
        # Conversion de la date
        if 'detection_time' in data:
            data['detection_time'] = datetime.fromisoformat(data['detection_time'])
            
        # Suppression du score de risque calcul√©
        data.pop('risk_score', None)
        
        return cls(**data)

@dataclass
class SecurityReport:
    """Rapport complet d'audit de s√©curit√© enrichi"""
    audit_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    target: str = ""
    timestamp: datetime = field(default_factory=datetime.now)
    findings: List[SecurityFinding] = field(default_factory=list)
    security_score: float = 10.0
    compliance_status: Dict[str, bool] = field(default_factory=dict)
    recommendations: List[str] = field(default_factory=list)
    summary: Dict[str, int] = field(default_factory=dict)
    context: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)
    scan_duration: float = 0.0
    total_files_scanned: int = 0
    total_lines_scanned: int = 0
    error_count: int = 0
    warning_count: int = 0
    scan_status: str = "completed"
    scan_coverage: float = 0.0
    excluded_files: List[str] = field(default_factory=list)
    failed_scans: List[Dict[str, Any]] = field(default_factory=list)
    
    def __post_init__(self):
        """Initialisation apr√®s cr√©ation"""
        self._update_summary()
        self.metadata.update({
            'generator': 'AgentMAINTENANCE09AnalyseurSecurite',
            'version': '2.1.0',
            'timestamp': self.timestamp.isoformat(),
            'scan_duration': self.scan_duration
        })
    
    def add_finding(self, finding: SecurityFinding) -> None:
        """Ajoute un finding et met √† jour le score"""
        try:
            if not isinstance(finding, SecurityFinding):
                raise TypeError("L'objet doit √™tre de type SecurityFinding")
            
            self.findings.append(finding)
            self._update_score()
            self._update_summary()
            
        except Exception as e:
            logging.error(f"Erreur lors de l'ajout du finding: {str(e)}")
            self.error_count += 1
            raise
    
    def add_failed_scan(self, file_path: str, error: str, details: Optional[Dict[str, Any]] = None) -> None:
        """Ajoute un scan √©chou√© au rapport"""
        self.failed_scans.append({
            'file_path': file_path,
            'error': error,
            'timestamp': datetime.now().isoformat(),
            'details': details or {}
        })
        self.error_count += 1
    
    def add_recommendation(self, recommendation: str) -> None:
        """Ajoute une recommandation de mani√®re s√©curis√©e"""
        if recommendation and recommendation not in self.recommendations:
            self.recommendations.append(recommendation)
    
    def update_compliance_status(self, rule: str, status: bool) -> None:
        """Met √† jour le statut de conformit√©"""
        self.compliance_status[rule] = status
    
    def _update_score(self) -> None:
        """Met √† jour le score de s√©curit√©"""
        if not self.findings:
            self.security_score = 10.0
            return
        
        # Nouveaux poids ajust√©s pour un calcul plus pr√©cis
        weights = {
            SecurityLevel.CRITICAL: 2.5,
            SecurityLevel.HIGH: 1.5,
            SecurityLevel.MEDIUM: 0.8,
            SecurityLevel.LOW: 0.3,
            SecurityLevel.INFO: 0.1,
            SecurityLevel.SECURE: 0.0
        }
        
        # Calcul du score avec plafonnement
        total_impact = sum(weights[f.security_level] for f in self.findings)
        base_score = max(0.0, 10.0 - total_impact)
        
        # Ajustement pour √©viter une p√©nalit√© excessive
        if len(self.findings) > 5:
            diminishing_factor = 0.8 ** (len(self.findings) - 5)
            base_score *= diminishing_factor
        
        # Ajustement bas√© sur la couverture du scan
        coverage_factor = max(0.5, min(1.0, self.scan_coverage / 100))
        base_score *= coverage_factor
        
        # Bonus pour conformit√© √©lev√©e
        if self.compliance_status:
            compliance_rate = sum(1 for v in self.compliance_status.values() if v) / len(self.compliance_status)
            if compliance_rate > 0.8:
                base_score *= 1.1
        
        self.security_score = round(max(0.0, min(10.0, base_score)), 2)
    
    def _update_summary(self) -> None:
        """Met √† jour le r√©sum√© des findings"""
        self.summary = {
            'total': len(self.findings),
            'par_niveau': {level.value: 0 for level in SecurityLevel},
            'par_type': {vtype.value: 0 for vtype in VulnerabilityType}
        }
        
        for finding in self.findings:
            self.summary['par_niveau'][finding.security_level.value] += 1
            self.summary['par_type'][finding.vulnerability_type.value] += 1
    
    def get_critical_findings(self) -> List[SecurityFinding]:
        """Retourne les findings critiques"""
        return [f for f in self.findings if f.security_level == SecurityLevel.CRITICAL]
    
    def get_findings_by_type(self, vuln_type: VulnerabilityType) -> List[SecurityFinding]:
        """Retourne les findings d'un type sp√©cifique"""
        return [f for f in self.findings if f.vulnerability_type == vuln_type]
    
    def get_findings_by_component(self, component: str) -> List[SecurityFinding]:
        """Retourne les findings affectant un composant sp√©cifique"""
        return [f for f in self.findings if component in f.affected_components]
    
    def calculate_risk_metrics(self) -> Dict[str, Any]:
        """Calcule des m√©triques de risque avanc√©es"""
        if not self.findings:
            return {
                'risk_score': 0.0,
                'risk_level': 'faible',
                'critical_count': 0,
                'high_priority_count': 0,
                'remediation_complexity': 'faible'
            }
        
        # Calcul des m√©triques
        critical_findings = self.get_critical_findings()
        high_findings = [f for f in self.findings if f.security_level == SecurityLevel.HIGH]
        
        # Score de risque moyen
        risk_scores = [f.calculate_risk_score() for f in self.findings]
        avg_risk_score = sum(risk_scores) / len(risk_scores)
        
        # Complexit√© de rem√©diation
        patch_complexities = [f.patch_complexity for f in self.findings]
        remediation_complexity = max(
            (patch_complexities.count('high') * 3 +
             patch_complexities.count('medium') * 2 +
             patch_complexities.count('low')) / len(self.findings),
            1
        )
        
        return {
            'risk_score': round(avg_risk_score, 2),
            'risk_level': 'critique' if len(critical_findings) > 0 else
                         '√©lev√©' if len(high_findings) > 0 else
                         'moyen' if avg_risk_score > 5 else 'faible',
            'critical_count': len(critical_findings),
            'high_priority_count': len(high_findings),
            'remediation_complexity': '√©lev√©e' if remediation_complexity > 2 else
                                    'moyenne' if remediation_complexity > 1 else 'faible'
        }
    
    def generate_summary_report(self) -> str:
        """G√©n√®re un r√©sum√© format√© du rapport conforme au standard agent 06"""
        # Utilise la nouvelle m√©thode standardis√©e
        return self._generate_standard_report("S√âCURIT√â", f"Audit {self.target}", self)
    
    def to_dict(self) -> Dict[str, Any]:
        """Convertit le rapport en dictionnaire"""
        return {
            'audit_id': self.audit_id,
            'target': self.target,
            'timestamp': self.timestamp.isoformat(),
            'findings': [f.to_dict() for f in self.findings],
            'security_score': self.security_score,
            'compliance_status': self.compliance_status,
            'recommendations': self.recommendations,
            'summary': self.summary,
            'context': self.context,
            'metadata': self.metadata,
            'scan_duration': self.scan_duration,
            'total_files_scanned': self.total_files_scanned,
            'total_lines_scanned': self.total_lines_scanned,
            'error_count': self.error_count,
            'warning_count': self.warning_count,
            'scan_status': self.scan_status,
            'scan_coverage': self.scan_coverage,
            'excluded_files': self.excluded_files,
            'failed_scans': self.failed_scans,
            'risk_metrics': self.calculate_risk_metrics()
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'SecurityReport':
        """Cr√©e un rapport √† partir d'un dictionnaire"""
        # Copie pour √©viter la modification des donn√©es d'entr√©e
        data = data.copy()
        
        # Conversion de la date
        if 'timestamp' in data:
            data['timestamp'] = datetime.fromisoformat(data['timestamp'])
        
        # Conversion des findings
        if 'findings' in data:
            data['findings'] = [
                SecurityFinding.from_dict(f) if isinstance(f, dict)
                else f for f in data['findings']
            ]
        
        # Suppression des champs calcul√©s
        data.pop('risk_metrics', None)
        
        return cls(**data)

# --- Fin: √âl√©ments int√©gr√©s depuis Agent 18 ---


class AgentMAINTENANCE09AnalyseurSecurite(Agent):
    """
    Agent avanc√© charg√© de la s√©curit√© du code Python et des audits universels:
    - D√©tection des vuln√©rabilit√©s de s√©curit√© communes
    - Identification des pratiques non s√©curis√©es
    - Analyse des injections potentielles
    - V√©rification de l'usage s√©curis√© des fonctions
    - Analyse des patterns de gestion des secrets
    - Audit de s√©curit√© des fichiers et r√©pertoires
    - Analyse des d√©pendances et configurations
    - Int√©gration avec des outils tiers (Bandit, Safety)
    """

    def __init__(self, **kwargs):
        
        # ‚úÖ MIGRATION SYST√àME LOGGING UNIFI√â
        try:
            from core.manager import LoggingManager
            logging_manager = LoggingManager()
            self.logger = logging_manager.get_logger(
                config_name="maintenance",
                custom_config={
                    "logger_name": f"nextgen.maintenance.MAINTENANCE_09_analyseur_securite.{self.agent_id if hasattr(self, 'agent_id') else self.id if hasattr(self, 'id') else 'unknown'}",
                    "log_dir": "logs/maintenance",
                    "metadata": {
                        "agent_type": "MAINTENANCE_09_analyseur_securite",
                        "agent_role": "maintenance",
                        "system": "nextgeneration"
                    }
                }
            )
        except ImportError:
            # Fallback en cas d'indisponibilit√© du LoggingManager
            self.logger = logging.getLogger(self.__class__.__name__)

        """Initialisation de l'agent"""
        super().__init__(**kwargs)
        self.name = "AgentMAINTENANCE09AnalyseurSecurite"
        self.version = "2.1.0"
        self.description = "Agent d'analyse de s√©curit√© avanc√©"
        
        # Configuration du logging
        self._setup_logging()
        
        # Patterns de s√©curit√©
        self.security_patterns = self._init_security_patterns()
        
        # Configuration par d√©faut
        self.default_config = {
            'max_files': 1000,
            'scan_depth': 3,
            'excluded_patterns': [
                '*.pyc', '__pycache__', '.git', '.env',
                'node_modules', 'venv', '.venv', '.pytest_cache'
            ],
            'max_file_size': 10 * 1024 * 1024,  # 10 MB
            'timeout': 300,  # 5 minutes
            'parallel_scans': 4
        }
        
        # √âtat de l'agent
        self.current_context = None
        self.executor = ThreadPoolExecutor(max_workers=4)
        
    def _setup_logging(self) -> None:
        """Configuration du syst√®me de logging"""
        try:
            if LoggingManager:
                self.logger = LoggingManager().get_logger(self.name)
            else:
                self.logger = logging.getLogger(self.name)
                self.logger.setLevel(logging.INFO)
                
                # Configuration du handler si n√©cessaire
                if not self.logger.handlers:
                    handler = logging.StreamHandler()
                    formatter = logging.Formatter(
                        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
                    )
                    handler.setFormatter(formatter)
                    self.logger.addHandler(handler)
                    
        except Exception as e:
            print(f"Erreur lors de la configuration du logging: {str(e)}")
            self.logger = logging.getLogger(self.name)
            
    async def startup(self) -> None:
        """Initialisation de l'agent"""
        try:
            self.logger.info(f"D√©marrage de l'agent {self.name} v{self.version}")
            
            # V√©rification des d√©pendances
            if not BANDIT_AVAILABLE:
                self.logger.warning("Bandit n'est pas disponible - fonctionnalit√©s limit√©es")
            if not SAFETY_CHECK_AVAILABLE:
                self.logger.warning("Safety n'est pas disponible - analyse des d√©pendances limit√©e")
                
            # Cr√©ation du r√©pertoire de rapports si n√©cessaire
            reports_dir = Path("reports/security")
            reports_dir.mkdir(parents=True, exist_ok=True)
            
        except Exception as e:
            self.logger.error(f"Erreur lors du d√©marrage: {str(e)}")
            raise
            
    async def execute_task(self, task: Task) -> Result:
        """Ex√©cution d'une t√¢che"""
        try:
            self.logger.info(f"Ex√©cution de la t√¢che: {task.task_id}")
            
            # Validation de la t√¢che
            if not task.parameters:
                raise ValueError("Param√®tres de t√¢che manquants")
                
            # Cr√©ation du contexte
            self.current_context = SecurityContext()
            self.current_context.target_path = task.parameters.get('target_path')
            
            # Configuration du contexte
            config = {**self.default_config, **task.parameters.get('config', {})}
            self.current_context.config = config
            self.current_context.max_files = config['max_files']
            self.current_context.scan_depth = config['scan_depth']
            self.current_context.excluded_paths = set(config['excluded_patterns'])
            
            # Validation du contexte
            is_valid, errors = self.current_context.validate_config()
            if not is_valid:
                raise ValueError(f"Configuration invalide: {', '.join(errors)}")
            
            # Ex√©cution selon le type de t√¢che
            scan_type = task.parameters.get('scan_type', 'security_scan')
            if scan_type == 'security_scan':
                result = await self._handle_security_scan(task, self.current_context)
            elif scan_type == 'dependency_check':
                result = await self._handle_dependency_check(task, self.current_context)
            elif scan_type == 'config_audit':
                result = await self._handle_config_audit(task, self.current_context)
            else:
                raise ValueError(f"Type de scan non support√©: {scan_type}")
                
            return result
            
        except Exception as e:
            self.logger.error(f"Erreur lors de l'ex√©cution: {str(e)}")
            tb = traceback.format_exc()
            self.logger.debug(f"Traceback: {tb}")
            
            return Result(
                success=False,
                error=str(e),
                details={'traceback': tb}
            )
            
    async def _handle_security_scan(self, task: Task, context: SecurityContext) -> Result:
        """Gestion d'un scan de s√©curit√©"""
        try:
            self.logger.info("D√©marrage du scan de s√©curit√©")
            context.update_status("scanning")
            
            # Cr√©ation du rapport
            report = SecurityReport(
                target=context.target_path,
                context={'task_id': task.task_id}
            )
            
            # Analyse du chemin cible
            target_path = Path(context.target_path)
            if not target_path.exists():
                raise FileNotFoundError(f"Chemin cible non trouv√©: {target_path}")
            
            # Scan r√©cursif
            start_time = datetime.now()
            await self._scan_path_recursive(target_path, report, context)
            
            # Finalisation du rapport
            end_time = datetime.now()
            report.scan_duration = (end_time - start_time).total_seconds()
            report.scan_coverage = self._calculate_coverage(context)
            
            # G√©n√©ration des recommandations
            self._generate_recommendations(report)
            
            # Sauvegarde du rapport
            report_path = self._save_report(report)
            
            return Result(
                success=True,
                data={
                    'report': report.to_dict(),
                    'report_path': str(report_path),
                    'summary': report.generate_summary_report()
                }
            )
            
        except Exception as e:
            context.add_error(str(e))
            raise
            
    async def _handle_dependency_check(self, task: Task, context: SecurityContext) -> Result:
        """Gestion d'une analyse des d√©pendances"""
        try:
            self.logger.info("D√©marrage de l'analyse des d√©pendances")
            context.update_status("checking_dependencies")
            
            # Cr√©ation du rapport
            report = SecurityReport(
                target=context.target_path,
                context={'task_id': task.task_id}
            )
            
            # Analyse des fichiers de d√©pendances
            dependency_files = self._find_dependency_files(Path(context.target_path))
            
            for dep_file in dependency_files:
                try:
                    if dep_file.name == 'requirements.txt':
                        await self._analyze_python_dependencies(dep_file, report)
                    elif dep_file.name == 'package.json':
                        await self._analyze_node_dependencies(dep_file, report)
                    elif dep_file.name == 'Gemfile':
                        await self._analyze_ruby_dependencies(dep_file, report)
                except Exception as e:
                    context.add_error(f"Erreur lors de l'analyse de {dep_file}: {str(e)}")
                    
            # Finalisation du rapport
            self._generate_recommendations(report)
            report_path = self._save_report(report)
            
            return Result(
                success=True,
                data={
                    'report': report.to_dict(),
                    'report_path': str(report_path)
                }
            )
            
        except Exception as e:
            context.add_error(str(e))
            raise
            
    async def _handle_config_audit(self, task: Task, context: SecurityContext) -> Result:
        """Gestion d'un audit de configuration"""
        try:
            self.logger.info("D√©marrage de l'audit de configuration")
            context.update_status("auditing_config")
            
            # Cr√©ation du rapport
            report = SecurityReport(
                target=context.target_path,
                context={'task_id': task.task_id}
            )
            
            # Analyse des fichiers de configuration
            config_files = self._find_config_files(Path(context.target_path))
            
            for config_file in config_files:
                try:
                    config_data = self._load_config_file(config_file)
                    findings = await self._analyze_config(config_data, config_file)
                    for finding in findings:
                        report.add_finding(finding)
                except Exception as e:
                    context.add_error(f"Erreur lors de l'analyse de {config_file}: {str(e)}")
                    
            # Finalisation du rapport
            self._generate_recommendations(report)
            report_path = self._save_report(report)
            
            return Result(
                success=True,
                data={
                    'report': report.to_dict(),
                    'report_path': str(report_path)
                }
            )
            
        except Exception as e:
            context.add_error(str(e))
            raise
            
    async def shutdown(self) -> None:
        """Arr√™t de l'agent"""
        try:
            self.logger.info("Arr√™t de l'agent")
            self.executor.shutdown(wait=True)
        except Exception as e:
            self.logger.error(f"Erreur lors de l'arr√™t: {str(e)}")
            
    def get_capabilities(self) -> List[str]:
        """Retourne les capacit√©s de l'agent"""
        capabilities = [
            "Analyse statique de code Python",
            "D√©tection de vuln√©rabilit√©s",
            "Analyse des d√©pendances",
            "Audit de configuration",
            "D√©tection de secrets",
            "G√©n√©ration de rapports"
        ]
        
        if BANDIT_AVAILABLE:
            capabilities.append("Analyse Bandit")
        if SAFETY_CHECK_AVAILABLE:
            capabilities.append("V√©rification Safety")
            
        return capabilities
        
    async def health_check(self) -> Dict[str, Any]:
        """V√©rifie l'√©tat de l'agent"""
        status = {
            'name': self.name,
            'version': self.version,
            'status': 'healthy',
            'timestamp': datetime.now().isoformat(),
            'capabilities': self.get_capabilities(),
            'dependencies': {
                'bandit': BANDIT_AVAILABLE,
                'safety': SAFETY_CHECK_AVAILABLE
            }
        }
        
        if self.current_context:
            status['current_scan'] = {
                'scan_id': self.current_context.scan_id,
                'status': self.current_context.scan_status,
                'progress': self.current_context.scan_progress
            }
            
        return status
        
    def _init_security_patterns(self) -> Dict[str, Any]:
        """Initialisation des patterns de s√©curit√©"""
        return {
            'secrets': {
                'api_key': r'(?i)(api[_-]?key|apikey|secret)["\s]*[:=]["\s]*[a-z0-9_-]+',
                'password': r'(?i)(password|passwd|pwd)["\s]*[:=]["\s]*[^\'"\s]+',
                'token': r'(?i)(access_token|auth_token|jwt)["\s]*[:=]["\s]*[a-z0-9_-]+',
                'private_key': r'-----BEGIN[A-Z\s]+PRIVATE KEY-----',
                'aws_key': r'(?i)(aws_access_key_id|aws_secret_access_key)["\s]*[:=]["\s]*[a-z0-9/+]+',
                'connection_string': r'(?i)(mongodb|postgresql|mysql)://[a-z0-9_-]+:[^@\s]+@[a-z0-9.-]+',
            },
            'dangerous_functions': {
                'python': {
                    'eval': r'eval\s*\(',
                    'exec': r'exec\s*\(',
                    'os_system': r'os\.system\s*\(',
                    'subprocess_shell': r'subprocess\..*shell\s*=\s*True',
                    'pickle_loads': r'pickle\.loads\s*\(',
                    'yaml_load': r'yaml\.load\s*\([^,)]+\)',
                    'sql_raw': r'execute\s*\(["\'].*SELECT|INSERT|UPDATE|DELETE',
                },
                'javascript': {
                    'eval': r'eval\s*\(',
                    'function': r'new Function\s*\(',
                    'dangerouslySetInnerHTML': r'dangerouslySetInnerHTML',
                }
            },
            'sql_injection': {
                r'(?i)SELECT.*WHERE.*=\s*[\'"].*%.*[\'"]',
                r'(?i)INSERT.*VALUES.*\$\{.*\}',
                r'(?i)UPDATE.*SET.*=.*\$\{.*\}',
            },
            'xss': {
                r'(?i)innerHTML\s*=',
                r'(?i)document\.write\s*\(',
                r'(?i)eval\s*\(',
            },
            'file_operations': {
                r'(?i)open\s*\([^,)]+,\s*[\'"]w[\'"]',
                r'(?i)file_get_contents\s*\(',
                r'(?i)readFile\s*\(',
                r'(?i)writeFile\s*\(',
            },
            'command_injection': {
                r'(?i)exec\s*\([^,)]+\)',
                r'(?i)spawn\s*\([^,)]+\)',
                r'(?i)system\s*\([^,)]+\)',
            }
        }
        
    async def _scan_path_recursive(self, path: Path, report: SecurityReport, context: SecurityContext) -> None:
        """Analyse r√©cursive d'un chemin"""
        try:
            if context.is_scan_limit_reached():
                return
                
            if context.should_exclude_path(path):
                context.excluded_files.append(str(path))
                return
                
            if path.is_file():
                await self._scan_file(path, report, context)
            elif path.is_dir():
                for item in path.iterdir():
                    await self._scan_path_recursive(item, report, context)
                    
        except Exception as e:
            context.add_error(f"Erreur lors du scan de {path}: {str(e)}")
            
    async def _scan_file(self, file_path: Path, report: SecurityReport, context: SecurityContext) -> None:
        """Analyse d'un fichier"""
        try:
            # V√©rification de la taille
            if file_path.stat().st_size > context.config['max_file_size']:
                context.add_warning(f"Fichier trop volumineux ignor√©: {file_path}")
                return
                
            context.current_file_count += 1
            
            # Analyse selon le type de fichier
            if file_path.suffix == '.py':
                await self._analyze_python_file(file_path, report, context)
            elif file_path.suffix in {'.js', '.ts', '.jsx', '.tsx'}:
                await self._analyze_javascript_file(file_path, report, context)
            elif file_path.suffix in {'.json', '.yaml', '.yml'}:
                await self._analyze_config_file(file_path, report, context)
                
            # Analyse g√©n√©rique
            await self._analyze_security_patterns(file_path, report, context)
            await self._analyze_secrets(file_path, report, context)
            
        except Exception as e:
            context.add_error(f"Erreur lors de l'analyse de {file_path}: {str(e)}")
            
    async def _analyze_python_file(self, file_path: Path, report: SecurityReport, context: SecurityContext) -> None:
        """Analyse d'un fichier Python"""
        try:
            # Analyse Bandit si disponible
            if BANDIT_AVAILABLE:
                await self._run_bandit_scan(file_path, report)
                
            # Analyse AST
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            await self._analyze_python_ast(content, file_path, report)
            
        except Exception as e:
            context.add_error(f"Erreur lors de l'analyse Python de {file_path}: {str(e)}")
            
    async def _analyze_javascript_file(self, file_path: Path, report: SecurityReport, context: SecurityContext) -> None:
        """Analyse d'un fichier JavaScript/TypeScript"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # Analyse des patterns de s√©curit√©
            for pattern_type, patterns in self.security_patterns['dangerous_functions']['javascript'].items():
                matches = re.finditer(patterns, content)
                for match in matches:
                    finding = SecurityFinding(
                        vulnerability_type=VulnerabilityType.DANGEROUS_FUNCTION,
                        security_level=SecurityLevel.HIGH,
                        title=f"Utilisation dangereuse de {pattern_type}",
                        description=f"Utilisation potentiellement dangereuse de {pattern_type} d√©tect√©e",
                        location=str(file_path),
                        line_number=content[:match.start()].count('\n') + 1,
                        evidence=match.group(0)
                    )
                    report.add_finding(finding)
                    
        except Exception as e:
            context.add_error(f"Erreur lors de l'analyse JavaScript de {file_path}: {str(e)}")
            
    async def _analyze_config_file(self, file_path: Path, report: SecurityReport, context: SecurityContext) -> None:
        """Analyse d'un fichier de configuration"""
        try:
            config_data = self._load_config_file(file_path)
            findings = await self._analyze_config(config_data, file_path)
            for finding in findings:
                report.add_finding(finding)
                
        except Exception as e:
            context.add_error(f"Erreur lors de l'analyse de configuration de {file_path}: {str(e)}")
            
    def _load_config_file(self, file_path: Path) -> Dict[str, Any]:
        """Charge un fichier de configuration"""
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
            
        if file_path.suffix == '.json':
            return json.loads(content)
        elif file_path.suffix in {'.yaml', '.yml'}:
            return yaml.safe_load(content)
        else:
            raise ValueError(f"Format de configuration non support√©: {file_path.suffix}")
            
    async def _analyze_config(self, config: Dict[str, Any], file_path: Path) -> List[SecurityFinding]:
        """Analyse une configuration"""
        findings = []
        
        def check_config_dict(d: Dict[str, Any], path: str = '') -> None:
            for key, value in d.items():
                current_path = f"{path}.{key}" if path else key
                
                # V√©rification des secrets
                if any(secret in key.lower() for secret in {'password', 'secret', 'key', 'token'}):
                    findings.append(SecurityFinding(
                        vulnerability_type=VulnerabilityType.SENSITIVE_DATA,
                        security_level=SecurityLevel.HIGH,
                        title=f"Information sensible dans la configuration",
                        description=f"D√©tection d'une information potentiellement sensible √† {current_path}",
                        location=str(file_path),
                        evidence=f"{key}: [MASQU√â]"
                    ))
                    
                # V√©rification r√©cursive
                if isinstance(value, dict):
                    check_config_dict(value, current_path)
                elif isinstance(value, list):
                    for i, item in enumerate(value):
                        if isinstance(item, dict):
                            check_config_dict(item, f"{current_path}[{i}]")
                            
        check_config_dict(config)
        return findings
        
    def _calculate_coverage(self, context: SecurityContext) -> float:
        """Calcule la couverture du scan"""
        total_files = sum(1 for _ in Path(context.target_path).rglob('*') if _.is_file())
        if total_files == 0:
            return 100.0
            
        scanned_ratio = min(1.0, context.current_file_count / total_files)
        return round(scanned_ratio * 100, 2)
        
    def _generate_recommendations(self, report: SecurityReport) -> None:
        """G√©n√®re des recommandations bas√©es sur les findings"""
        recommendations = set()
        
        for finding in report.findings:
            if finding.security_level in {SecurityLevel.CRITICAL, SecurityLevel.HIGH}:
                if finding.remediation:
                    recommendations.add(finding.remediation)
                    
        report.recommendations = list(recommendations)
        
    def _save_report(self, report: SecurityReport) -> Path:
        """Sauvegarde le rapport"""
        reports_dir = Path("reports/security")
        report_file = reports_dir / f"security_report_{report.audit_id}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report.to_dict(), f, indent=2, ensure_ascii=False)
            
        return report_file
        
    def _find_dependency_files(self, path: Path) -> List[Path]:
        """Trouve les fichiers de d√©pendances"""
        dependency_files = []
        for pattern in ['requirements.txt', 'package.json', 'Gemfile']:
            dependency_files.extend(path.rglob(pattern))
        return dependency_files
        
    def _find_config_files(self, path: Path) -> List[Path]:
        """Trouve les fichiers de configuration"""
        config_files = []
        for pattern in ['*.json', '*.yaml', '*.yml', '*.conf', '*.config']:
            config_files.extend(path.rglob(pattern))
        return config_files
    
    def _generate_standard_report(self, category: str, title: str, data: Dict[str, Any]) -> str:
        """G√©n√®re un rapport conforme au standard agent 06."""
        
        from datetime import datetime
        timestamp = datetime.now()
        
        # Calcul automatique du score et niveau qualit√©
        score = self._calculate_report_score(data)
        quality_level = self._determine_quality_level(score)
        conformity = self._assess_conformity(data)
        critical_issues = self._count_critical_issues(data)
        
        # G√©n√©ration contenu par section
        architecture_context = self._generate_architecture_context(data)
        metrics_kpis = self._generate_metrics_kpis(data)
        detailed_analysis = self._generate_detailed_analysis(data)
        strategic_recommendations = self._generate_strategic_recommendations(data)
        business_impact = self._generate_business_impact(data)
        
        # Application du template standard
        report = f"""# üìä **RAPPORT {category.upper()} : {title}**

**Date :** {timestamp.strftime('%Y-%m-%d %H:%M:%S')}
**Module :** {self.__class__.__name__}
**Score Global** : {score}/10
**Niveau Qualit√©** : {quality_level}
**Conformit√©** : {conformity}
**Issues Critiques** : {critical_issues}

## üèóÔ∏è Architecture et Contexte
{architecture_context}

## üìä M√©triques et KPIs
{metrics_kpis}

## üîç Analyse D√©taill√©e
{detailed_analysis}

## üéØ Recommandations Strat√©giques
{strategic_recommendations}

## üìà Impact Business
{business_impact}

---

*Rapport {category} g√©n√©r√© par {self.__class__.__name__} - {timestamp.strftime('%Y-%m-%d %H:%M:%S')}*
*üìÇ Sauvegard√© dans : /mnt/c/Dev/nextgeneration/reports/security/*
"""
        
        return report
    
    def _calculate_report_score(self, data: Dict[str, Any]) -> float:
        """Calcule le score global du rapport bas√© sur les donn√©es."""
        # Pour l'agent s√©curit√©, base sur security_score et autres m√©triques
        base_score = 7.0
        
        # Si on a un rapport de s√©curit√© dans les donn√©es
        if isinstance(data, dict) and hasattr(data.get('report'), 'security_score'):
            # Score bas√© sur le security_score du rapport
            security_score = data['report'].security_score
            base_score = float(security_score)
        elif isinstance(data, SecurityReport):
            base_score = float(data.security_score)
        
        return min(10.0, base_score)
    
    def _determine_quality_level(self, score: float) -> str:
        """D√©termine le niveau de qualit√© bas√© sur le score."""
        if score >= 9.0:
            return "OPTIMAL"
        elif score >= 8.0:
            return "EXCELLENT"
        elif score >= 7.0:
            return "BON"
        elif score >= 6.0:
            return "MOYEN"
        else:
            return "INSUFFISANT"
    
    def _assess_conformity(self, data: Dict[str, Any]) -> str:
        """√âvalue la conformit√© aux standards de s√©curit√©."""
        conformity_score = 0
        total_checks = 4
        
        # Checks de conformit√© sp√©cifiques √† la s√©curit√©
        if isinstance(data, SecurityReport):
            if data.scan_coverage >= 80:
                conformity_score += 1
            if data.security_score >= 7.0:
                conformity_score += 1
            if len(data.findings) > 0:  # Audit r√©ellement effectu√©
                conformity_score += 1
            if data.recommendations:
                conformity_score += 1
        elif isinstance(data, dict):
            report = data.get('report')
            if report and hasattr(report, 'scan_coverage') and report.scan_coverage >= 80:
                conformity_score += 1
            if report and hasattr(report, 'security_score') and report.security_score >= 7.0:
                conformity_score += 1
            conformity_score += 2  # Base pour autres donn√©es
                
        conformity_rate = conformity_score / total_checks
        
        if conformity_rate >= 0.9:
            return "‚úÖ CONFORME"
        elif conformity_rate >= 0.7:
            return "‚ö†Ô∏è PARTIELLEMENT CONFORME"
        else:
            return "‚ùå NON CONFORME"
    
    def _count_critical_issues(self, data: Dict[str, Any]) -> int:
        """Compte les issues critiques dans les donn√©es de s√©curit√©."""
        critical_count = 0
        
        if isinstance(data, SecurityReport):
            critical_count = len([f for f in data.findings if f.security_level == SecurityLevel.CRITICAL])
        elif isinstance(data, dict):
            report = data.get('report')
            if report and hasattr(report, 'findings'):
                critical_count = len([f for f in report.findings if f.security_level == SecurityLevel.CRITICAL])
                
        return critical_count
    
    def _generate_architecture_context(self, data: Dict[str, Any]) -> str:
        """G√©n√®re la section Architecture et Contexte pour s√©curit√©."""
        if isinstance(data, SecurityReport):
            target = data.target
            total_files = data.total_files_scanned
        elif isinstance(data, dict):
            report = data.get('report', data)
            target = report.get('target', 'Non sp√©cifi√©')
            total_files = report.get('total_files_scanned', 0)
        else:
            target = "Non sp√©cifi√©"
            total_files = 0
            
        context = f"""Audit de s√©curit√© automatis√© effectu√© sur l'architecture logicielle cible.

**P√©rim√®tre d'analyse :**
- Cible analys√©e : {target}
- Nombre de fichiers scann√©s : {total_files}
- Technologies d√©tect√©es : Python, Configuration, D√©pendances

**M√©thodologie d'audit :**
- Analyse statique de code source
- V√©rification des configurations de s√©curit√©
- Scan des d√©pendances vuln√©rables
- D√©tection de patterns de s√©curit√© d√©faillants

**Architecture de s√©curit√© √©valu√©e :**
- Authentification et autorisation
- Gestion des secrets et configuration
- Validation des entr√©es utilisateur
- S√©curisation des communications"""
        
        return context
    
    def _generate_metrics_kpis(self, data: Dict[str, Any]) -> str:
        """G√©n√®re la section M√©triques et KPIs pour s√©curit√©."""
        if isinstance(data, SecurityReport):
            report = data
        elif isinstance(data, dict):
            report = data.get('report', data)
        else:
            return "Aucune m√©trique disponible"
            
        # Calculs des m√©triques
        findings_by_level = {}
        if hasattr(report, 'findings'):
            for finding in report.findings:
                level = finding.security_level.value if hasattr(finding.security_level, 'value') else str(finding.security_level)
                findings_by_level[level] = findings_by_level.get(level, 0) + 1
        
        security_score = getattr(report, 'security_score', 0)
        coverage = getattr(report, 'scan_coverage', 0)
        total_findings = len(getattr(report, 'findings', []))
        
        metrics = f"""### üìà Indicateurs de S√©curit√©
- **Score de s√©curit√© global :** {security_score}/10
- **Couverture du scan :** {coverage}%
- **Total vuln√©rabilit√©s d√©tect√©es :** {total_findings}
- **Criticit√© critique :** {findings_by_level.get('CRITICAL', 0)}
- **Criticit√© haute :** {findings_by_level.get('HIGH', 0)}
- **Criticit√© moyenne :** {findings_by_level.get('MEDIUM', 0)}
- **Criticit√© faible :** {findings_by_level.get('LOW', 0)}

### üéØ KPIs de Conformit√©
- **Conformit√© s√©curit√© :** {((10 - len(findings_by_level.get('CRITICAL', []))) / 10 * 100):.1f}%
- **Niveau de risque :** {"√âLEV√â" if findings_by_level.get('CRITICAL', 0) > 0 else "MOD√âR√â" if total_findings > 5 else "FAIBLE"}
- **Recommandations actionnables :** {len(getattr(report, 'recommendations', []))}"""
        
        return metrics
    
    def _generate_detailed_analysis(self, data: Dict[str, Any]) -> str:
        """G√©n√®re la section Analyse D√©taill√©e pour s√©curit√©."""
        if isinstance(data, SecurityReport):
            report = data
        elif isinstance(data, dict):
            report = data.get('report', data)
        else:
            return "Aucune analyse disponible"
            
        findings = getattr(report, 'findings', [])
        
        analysis = f"""### üîç Analyse par Criticit√©

**Vuln√©rabilit√©s Critiques ({len([f for f in findings if str(f.security_level) == 'CRITICAL'])}):**"""
        
        critical_findings = [f for f in findings if str(f.security_level) == 'CRITICAL']
        for finding in critical_findings[:5]:  # Limite √† 5 pour le rapport
            analysis += f"\n- `{finding.type}`: {finding.description} (Ligne {finding.line_number})"
        
        high_findings = [f for f in findings if str(f.security_level) == 'HIGH']
        if high_findings:
            analysis += f"\n\n**Vuln√©rabilit√©s Hautes ({len(high_findings)}):**"
            for finding in high_findings[:3]:
                analysis += f"\n- `{finding.type}`: {finding.description}"
        
        analysis += f"\n\n### üìä Distribution des Risques"
        analysis += f"\nLa majorit√© des vuln√©rabilit√©s sont de niveau {'critique' if len(critical_findings) > len(high_findings) else '√©lev√©' if len(high_findings) > 0 else 'mod√©r√©'}."
        analysis += f"\nFocus recommand√© sur la rem√©diation des {len(critical_findings)} vuln√©rabilit√©s critiques."
        
        return analysis
    
    def _generate_strategic_recommendations(self, data: Dict[str, Any]) -> str:
        """G√©n√®re la section Recommandations Strat√©giques pour s√©curit√©."""
        if isinstance(data, SecurityReport):
            report = data
        elif isinstance(data, dict):
            report = data.get('report', data)
        else:
            return "Aucune recommandation disponible"
            
        findings = getattr(report, 'findings', [])
        recommendations = getattr(report, 'recommendations', [])
        critical_count = len([f for f in findings if str(f.security_level) == 'CRITICAL'])
        
        strategic_recs = f"""### üéØ Actions Prioritaires

**Priorit√© HAUTE :**"""
        
        if critical_count > 0:
            strategic_recs += f"""
1. **Rem√©diation imm√©diate** des {critical_count} vuln√©rabilit√©s critiques
2. **Review s√©curit√©** approfondie du code concern√©
3. **Tests de s√©curit√©** additionnels post-correction"""
        else:
            strategic_recs += f"""
1. **Maintien du niveau** de s√©curit√© actuel
2. **Surveillance continue** des nouvelles vuln√©rabilit√©s
3. **Formation √©quipe** sur les bonnes pratiques"""
        
        strategic_recs += f"""

**Priorit√© MOYENNE :**
1. **Automatisation** des contr√¥les de s√©curit√© dans CI/CD
2. **Documentation** des proc√©dures de s√©curit√©
3. **Audit p√©riodique** des configurations

**Priorit√© BASSE :**
1. **Optimisation** des outils de scanning
2. **Extension couverture** √† d'autres composants
3. **Benchmark** contre standards industrie"""
        
        if recommendations:
            strategic_recs += f"\n\n**Recommandations sp√©cifiques d√©tect√©es :**"
            for i, rec in enumerate(recommendations[:3], 1):
                strategic_recs += f"\n{i}. {rec}"
        
        return strategic_recs
    
    def _generate_business_impact(self, data: Dict[str, Any]) -> str:
        """G√©n√®re la section Impact Business pour s√©curit√©."""
        if isinstance(data, SecurityReport):
            report = data
        elif isinstance(data, dict):
            report = data.get('report', data)
        else:
            return "Aucune √©valuation d'impact disponible"
            
        findings = getattr(report, 'findings', [])
        critical_count = len([f for f in findings if str(f.security_level) == 'CRITICAL'])
        security_score = getattr(report, 'security_score', 0)
        
        # Estimations d'impact
        risk_level = "√âLEV√â" if critical_count > 0 else "MOD√âR√â" if len(findings) > 5 else "FAIBLE"
        cost_impact = critical_count * 50000 + len(findings) * 5000  # Estimation co√ªt potentiel
        
        impact = f"""### üí∞ Impact S√©curit√© Quantifi√©

**Niveau de Risque Business :** {risk_level}
- **Vuln√©rabilit√©s critiques :** {critical_count} (impact potentiel: {critical_count * 50000}‚Ç¨)
- **Score de s√©curit√© :** {security_score}/10 ({"Acceptable" if security_score >= 7 else "N√©cessite am√©lioration"})
- **Co√ªt potentiel total estim√© :** {cost_impact}‚Ç¨

**B√©n√©fices S√©curisation :**
- **R√©duction risque cyber :** {min(95, security_score * 10)}%
- **Conformit√© r√©glementaire :** Am√©lioration RGPD/ISO27001
- **Confiance clients :** Protection donn√©es personnelles

### üìä ROI S√©curit√©

**Investissement pr√©vention :**
- Co√ªt rem√©diation imm√©diate : ~{len(findings) * 500}‚Ç¨
- Formation √©quipe s√©curit√© : ~2000‚Ç¨
- Outils automatisation : ~5000‚Ç¨

**Retour sur investissement :**
- √âvitement incidents : +{(cost_impact / 10000 * 100):.0f}%
- R√©duction temps r√©solution : 80%
- Am√©lioration r√©putation : Inestimable

### üõ°Ô∏è Impact Op√©rationnel

**Continuit√© d'activit√© :**
- Disponibilit√© syst√®me pr√©serv√©e
- R√©duction risque interruption service
- Am√©lioration temps de r√©ponse incidents

**Compliance :**
- Respect standards s√©curit√© industrie
- Audit trail complet pour r√©gulateurs
- Certification s√©curit√© facilit√©e"""
        
        return impact

def create_agent_MAINTENANCE_09_analyseur_securite(**kwargs) -> AgentMAINTENANCE09AnalyseurSecurite:
    """Cr√©e une instance de l'agent"""
    return AgentMAINTENANCE09AnalyseurSecurite(**kwargs)

async def main():
    """Point d'entr√©e pour les tests"""
    agent = create_agent_MAINTENANCE_09_analyseur_securite()
    await agent.startup()
    # Ajoutez vos tests ici
    await agent.shutdown()

if __name__ == "__main__":
    asyncio.run(main())