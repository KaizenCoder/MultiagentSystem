#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
üìä AGENT 06 - MONITORING AVANC√â
Mission: Observabilit√© distribu√©e avec OpenTelemetry et Prometheus.
"""
import sys
from pathlib import Path

# Ajout du r√©pertoire parent au path pour r√©soudre les imports locaux
sys.path.append(str(Path(__file__).resolve().parent.parent))

import asyncio
import logging
from typing import Dict, List, Optional, Any
from core.manager import LoggingManager

from core.agent_factory_architecture import Agent, Task, Result

__version__ = "0.1.0-sprint4"

try:
    from opentelemetry import trace, metrics
    from opentelemetry.sdk.trace import TracerProvider
    from opentelemetry.sdk.metrics import MeterProvider
    OPENTELEMETRY_AVAILABLE = True
except ImportError:
    OPENTELEMETRY_AVAILABLE = False


class Agent06AdvancedMonitoring(Agent):
    """
    üìä AGENT 06 - MONITORING AVANC√â - Version restructur√©e et fonctionnelle.
    """
    
    def __init__(self, agent_id="agent_06_specialiste_monitoring", agent_type="monitoring", version="0.1.0-sprint4", **kwargs):
        logging_manager = LoggingManager()
        custom_log_config = {
            "logger_name": f"agent.{agent_id}",
            "metadata": {
                "agent_name": agent_id,
                "role": "monitoring",
                "domain": "observability"
            }
        }
        logger = logging_manager.get_logger(config_name="default", custom_config=custom_log_config)
        super().__init__(agent_id=agent_id, agent_type=agent_type, logger=logger, **kwargs)
        self.logger = logger
        self.agent_id = agent_id
        self.version = version
        
        self.tracer_provider = None
        self.meter_provider = None
        self.tracer = None
        self.meter = None
        
        if OPENTELEMETRY_AVAILABLE:
            self._setup_opentelemetry()
        else:
            self.logger.warning("‚ö†Ô∏è OpenTelemetry non disponible - mode d√©grad√©.")

    def _setup_opentelemetry(self):
        """Initialisation propre d'OpenTelemetry."""
        try:
            self.tracer_provider = TracerProvider()
            trace.set_tracer_provider(self.tracer_provider)
            self.tracer = trace.get_tracer(__name__)
            
            self.meter_provider = MeterProvider()
            metrics.set_meter_provider(self.meter_provider)
            self.meter = metrics.get_meter(__name__)
            
            self.logger.info("‚úÖ OpenTelemetry initialis√© avec succ√®s.")
        except Exception as e:
            self.logger.error(f"‚ùå Erreur initialisation OpenTelemetry: {e}")
            global OPENTELEMETRY_AVAILABLE
            OPENTELEMETRY_AVAILABLE = False

    async def execute_task(self, task: Task) -> Result:
        if task.type == "generate_strategic_report":
            try:
                context = task.params
                type_rapport = task.params.get('type_rapport', 'monitoring')
                format_sortie = task.params.get('format_sortie', 'json')
                
                rapport = await self.generer_rapport_strategique(context, type_rapport)
                
                if format_sortie == 'markdown':
                    rapport_md = await self.generer_rapport_markdown(rapport, type_rapport, context)
                    
                    import os
                    from datetime import datetime 
                    reports_dir = "reports"
                    os.makedirs(reports_dir, exist_ok=True)
                    
                    timestamp_val = datetime.now() 
                    filename = f"strategic_report_agent_06_monitoring_{type_rapport}_{timestamp_val.strftime('%Y-%m-%d_%H%M%S')}.md"
                    filepath = os.path.join(reports_dir, filename)
                    
                    with open(filepath, 'w', encoding='utf-8') as f:
                        f.write(rapport_md)
                    
                    return Result(success=True, data={
                        'rapport_json': rapport, 
                        'rapport_markdown': rapport_md,
                        'fichier_sauvegarde': filepath
                    })
                
                return Result(success=True, data=rapport)
            except Exception as e:
                self.logger.error(f"Erreur g√©n√©ration rapport monitoring: {e}")
                return Result(success=False, error=f"Exception rapport monitoring: {str(e)}")
        else:
            self.logger.info(f"‚öôÔ∏è Ex√©cution de la t√¢che de monitoring: {task.id}")
            if self.tracer and OPENTELEMETRY_AVAILABLE:
                with self.tracer.start_as_current_span("monitoring_task") as span:
                    span.set_attribute("task.id", task.id)
                    status = self.get_system_status()
                    span.set_attribute("system.status", "ok" if status.get("success") else "error")
                    return Result(success=True, data=status)
            else:
                status = self.get_system_status()
                return Result(success=True, data=status)

    def get_system_status(self) -> Dict[str, Any]:
        return {
            "success": True,
            "timestamp": asyncio.get_event_loop().time(),
            "opentelemetry_enabled": OPENTELEMETRY_AVAILABLE,
        }

    async def startup(self):
        self.logger.info(f"üìä {self.agent_id} v{self.version} - D√âMARRAGE")

    async def shutdown(self):
        self.logger.info(f"üìä {self.agent_id} v{self.version} - ARR√äT")

    async def generer_rapport_strategique(self, context: Dict[str, Any], type_rapport: str = 'monitoring') -> Dict[str, Any]:
        self.logger.info(f"G√©n√©ration rapport monitoring/observabilit√©: {type_rapport}")
        metriques_base = await self._collecter_metriques_monitoring()
        from datetime import datetime 
        timestamp_val = datetime.now() 
        
        if type_rapport == 'monitoring':
            return await self._generer_rapport_monitoring(context, metriques_base, timestamp_val)
        elif type_rapport == 'observabilite':
            return await self._generer_rapport_observabilite(context, metriques_base, timestamp_val)
        elif type_rapport == 'performance': 
            return await self._generer_rapport_performance_monitoring(context, metriques_base, timestamp_val)
        elif type_rapport == 'alertes':
            return await self._generer_rapport_alertes(context, metriques_base, timestamp_val)
        else: 
            return await self._generer_rapport_monitoring(context, metriques_base, timestamp_val)

    async def _collecter_metriques_monitoring(self) -> Dict[str, Any]:
        try:
            system_status = self.get_system_status()
            from datetime import datetime 
            current_iso_timestamp = datetime.now().isoformat()
            
            # Simulation de donn√©es plus riches pour les rapports
            services_monitores_actifs = 10
            total_services_infrastructure = 12
            alert_rules_actives = 15
            
            monitoring_metrics = {
                'opentelemetry_enabled': OPENTELEMETRY_AVAILABLE,
                'tracer_provider_active': self.tracer_provider is not None,
                'meter_provider_active': self.meter_provider is not None,
                'monitoring_active': system_status.get('success', False)
            }
            observability_metrics = { # Ces m√©triques sont plus g√©n√©riques et peuvent √™tre utilis√©es par d'autres types de rapports
                'traces_collected_total': 2450,  
                'metrics_collected_total': 12800,  
                'logs_processed_total': 102400,    
                'alert_rules_count_total': alert_rules_actives, # Nombre total de r√®gles, peut √™tre diff√©rent des actives pour un type de rapport
                'dashboards_active_count': 8,
                'services_monitores_actifs': services_monitores_actifs,
                'total_services_infrastructure': total_services_infrastructure
            }
            monitoring_health = {
                'telemetry_operational': OPENTELEMETRY_AVAILABLE,
                'tracing_enabled': self.tracer is not None,
                'metrics_enabled': self.meter is not None,
                'system_responsive': system_status.get('success', False)
            }
            return {
                'monitoring_metrics': monitoring_metrics,
                'observability_metrics': observability_metrics, # Renomm√© pour plus de clart√©
                'monitoring_health': monitoring_health,
                'system_status': system_status,
                'derniere_maj': current_iso_timestamp
            }
        except Exception as e:
            self.logger.error(f"Erreur collecte m√©triques monitoring: {e}")
            return {'erreur': str(e), 'metriques_partielles': True}

    async def _generer_rapport_monitoring(self, context: Dict, metriques: Dict, timestamp) -> Dict[str, Any]:
        """G√©n√®re le contenu du rapport de monitoring strat√©gique."""
        monitoring_metrics = metriques.get('monitoring_metrics', {})
        observability_data = metriques.get('observability_metrics', {}) # Utilisation des donn√©es d'observabilit√© g√©n√©rales
        monitoring_health = metriques.get('monitoring_health', {})
        
        agent_filename = Path(__file__).name

        score_monitoring = 0
        issues_critiques_details_list = [] 
        if monitoring_health.get('telemetry_operational'): score_monitoring += 30
        else: issues_critiques_details_list.append("OpenTelemetry indisponible ou non op√©rationnel.")
        if monitoring_health.get('tracing_enabled'): score_monitoring += 25
        else: issues_critiques_details_list.append("Syst√®me de Tracing distribu√© inactif ou mal configur√©.")
        if monitoring_health.get('metrics_enabled'): score_monitoring += 25
        else: issues_critiques_details_list.append("Collecte des m√©triques syst√®me et applicatives inactive.")
        if monitoring_health.get('system_responsive'): score_monitoring += 20
        else: issues_critiques_details_list.append("Le syst√®me de monitoring global ne r√©pond pas ou est d√©grad√©.")
        
        niveau_qualite_val = "OPTIMAL" if score_monitoring >= 90 else "ACCEPTABLE" if score_monitoring >= 70 else "CRITIQUE"
        conformite_val = "‚úÖ CONFORME" if score_monitoring >= 70 else "‚ùå NON CONFORME"
        issues_critiques_count_val = len(issues_critiques_details_list)

        reco_telemetry = ('‚úÖ OpenTelemetry est pleinement op√©rationnel, assurant une collecte de donn√©es de t√©l√©m√©trie compl√®te.' 
                          if monitoring_health.get('telemetry_operational') 
                          else '‚ö†Ô∏è OpenTelemetry est indisponible ou rencontre des probl√®mes. Investigation imm√©diate requise pour restaurer la visibilit√©.')
        reco_tracing = ('‚úÖ Le tracing distribu√© est actif et correctement configur√©, permettant une analyse fine des flux transactionnels.' 
                        if monitoring_health.get('tracing_enabled') 
                        else '‚ö†Ô∏è Le tracing distribu√© est inactif. V√©rifier la configuration du provider de traces et les agents d\'instrumentation.')
        reco_metrics = ('‚úÖ La collecte des m√©triques est active et les donn√©es sont agr√©g√©es de mani√®re fiable.' 
                        if monitoring_health.get('metrics_enabled') 
                        else '‚ö†Ô∏è La collecte des m√©triques est inactive. V√©rifier le meter provider et les points de collecte.')
        reco_systeme = ('‚úÖ Le syst√®me de monitoring est r√©actif et performant, garantissant des donn√©es en temps r√©el.' 
                        if monitoring_health.get('system_responsive') 
                        else '‚ö†Ô∏è Le syst√®me de monitoring pr√©sente des latences ou des indisponibilit√©s. Identifier et corriger la cause racine.')

        return {
            'agent_id': self.agent_id,
            'agent_file_name': agent_filename, # NOUVEAU
            'type_rapport': 'monitoring',
            'timestamp': timestamp.isoformat(),
            'specialisation': 'Sp√©cialiste Monitoring & Observabilit√© Strat√©gique', # Plus descriptif
            'score_global': score_monitoring, 
            'niveau_qualite': niveau_qualite_val, 
            'conformite': conformite_val, 
            'signature_cryptographique': 'N/A (Fonctionnalit√© non impl√©ment√©e pour cet agent)', # NOUVEAU
            'issues_critiques_identifies': issues_critiques_count_val, 
            'architecture_monitoring': { 
                'description': "Syst√®me de monitoring strat√©gique avanc√©, s'appuyant sur OpenTelemetry pour une observabilit√© distribu√©e compl√®te et une visibilit√© approfondie de la performance applicative et de l'infrastructure.",
                'statut_operationnel': 'Syst√®me de monitoring OpenTelemetry globalement op√©rationnel.', # NOUVEAU
                'confirmation_specialisation': f"{self.agent_id} confirm√© comme Sp√©cialiste Monitoring & Observabilit√©.", # NOUVEAU
                'objectifs_principaux': [
                    "Assurer une collecte exhaustive et en temps r√©el des traces distribu√©es √† travers tous les services.",
                    "Surveiller en continu les m√©triques de performance cl√©s (KPIs) de l'application et de l'infrastructure.",
                    "Permettre une agr√©gation et une analyse centralis√©e des logs pour un diagnostic rapide des incidents.",
                    "Faciliter la configuration et la gestion proactive des alertes critiques bas√©es sur des seuils et des anomalies."
                ],
                'technologies_cles': ["OpenTelemetry (OTLP)", "Prometheus (simulation pour agr√©gation m√©triques)", "Grafana (simulation pour dashboards et visualisation)", "Python Asyncio"]
            },
            'recommandations_monitoring': [ # Recommandations plus descriptives
                f"üìä T√âL√âM√âTRIE: {reco_telemetry}",
                f"üîç TRACING: {reco_tracing}",
                f"üìà M√âTRIQUES: {reco_metrics}",
                f"‚ö° SYST√àME MONITORING: {reco_systeme}"
            ],
            'issues_critiques_monitoring_details': issues_critiques_details_list if issues_critiques_count_val > 0 else ["Aucun issue critique de monitoring majeur d√©tect√©. Le syst√®me fonctionne dans les param√®tres attendus."], 
             'details_techniques_monitoring': { 
                'strategie_monitoring': "Observabilit√© distribu√©e full-stack avec OpenTelemetry, ax√©e sur la collecte proactive de traces, m√©triques et logs.", # NOUVEAU
                'collecteurs_donnees': ["Traces (OTLP via agents OpenTelemetry)", "M√©triques (OTLP/Prometheus via SDKs et exporters)", "Logs (Potentiel pour FluentBit vers OTLP, non actif)"], # NOUVEAU
                'opentelemetry_disponible': monitoring_metrics.get('opentelemetry_enabled', False),
                'tracer_provider_actif': monitoring_metrics.get('tracer_provider_active', False),
                'meter_provider_actif': monitoring_metrics.get('meter_provider_active', False),
                'traces_collectees_session': observability_data.get('traces_collected_total', 0), # Chang√© pour refl√©ter le total (simul√©)
                'metriques_collectees_session': observability_data.get('metrics_collected_total', 0), # Chang√©
                'logs_traites_session': observability_data.get('logs_processed_total', 0), # Chang√©
                'alert_rules_actives_monitoring': observability_data.get('alert_rules_count_total',0), # Sp√©cifique au monitoring
                'dashboards_actifs_monitoring': observability_data.get('dashboards_active_count',0) # Sp√©cifique au monitoring
            },
            'metriques_monitoring_detaillees': {  # Scores structur√©s
                'score_monitoring_global': {'actuel': score_monitoring, 'cible': 100},
                'sante_telemetrie': {'actuel': 100 if monitoring_health.get('telemetry_operational') else 30, 'cible': 100, 'unite': '%'},
                'efficacite_tracing': {'actuel': 100 if monitoring_health.get('tracing_enabled') else 30, 'cible': 100, 'unite': '%'},
                'couverture_metriques': {'actuel': 100 if monitoring_health.get('metrics_enabled') else 30, 'cible': 100, 'unite': '%'},
                'reactivite_systeme_monitoring': {'actuel': 100 if monitoring_health.get('system_responsive') else 30, 'cible': 100, 'unite': '%'},
                'services_monitores_ok': {'actuel': observability_data.get('services_monitores_actifs',0) , 'total': observability_data.get('total_services_infrastructure',0), 'unite': 'services'},
                'regles_alertes_configurees_monitoring': {'actuel': observability_data.get('alert_rules_count_total',0), 'unite': 'r√®gles'}
            },
            'metadonnees': { 
                'version_agent': self.version, # Utiliser la version de l'agent
                'version_rapport': '1.1.0', # Version de la structure du rapport
                'notes_qualite': "Rapport g√©n√©r√© conform√©ment aux standards de qualit√© v1.2 de l'√©quipe NextGeneration.", # NOUVEAU
                'dependances_simulation': ["OpenTelemetry SDK", "Prometheus (simulation)", "Grafana (simulation)"],
                'context_analyse': context.get('cible', 'Analyse g√©n√©rale du syst√®me de monitoring strat√©gique')
            }
        }

    async def _generer_rapport_observabilite(self, context: Dict, metriques: Dict, timestamp) -> Dict[str, Any]:
        """G√©n√®re le contenu du rapport d'observabilit√© strat√©gique."""
        observability_data = metriques.get('observability_metrics', {})
        agent_filename = Path(__file__).name

        score = 0
        issues_details = []

        traces_collectees = observability_data.get('traces_collected_total', 0)
        metriques_collectees = observability_data.get('metrics_collected_total', 0)
        logs_traites = observability_data.get('logs_processed_total', 0)
        dashboards_actifs = observability_data.get('dashboards_active_count', 0)

        if traces_collectees > 1000: score += 25
        else: issues_details.append(f"Couverture des traces ({traces_collectees}) inf√©rieure √† l'objectif de 1000.")
        if metriques_collectees > 5000: score += 25
        else: issues_details.append(f"Volume des m√©triques ({metriques_collectees}) inf√©rieur √† l'objectif de 5000.")
        if logs_traites > 50000: score += 25
        else: issues_details.append(f"Volume des logs trait√©s ({logs_traites}) inf√©rieur √† l'objectif de 50000.")
        if dashboards_actifs >= 5: score += 25
        else: issues_details.append(f"Nombre de dashboards actifs ({dashboards_actifs}) insuffisant (cible: 5+).")
        
        score_observabilite_global = score
        niveau_qualite = "OPTIMAL" if score_observabilite_global >= 90 else "ACCEPTABLE" if score_observabilite_global >= 70 else "CRITIQUE"
        conformite = "‚úÖ CONFORME" if score_observabilite_global >= 70 else "‚ùå NON CONFORME"
        issues_critiques_count = len(issues_details)

        # Simplification des f-strings pour les recommandations
        if traces_collectees > 1000:
            reco_traces_text = f"Traces: {traces_collectees} collect√©es. Maintenir une haute couverture et envisager l'√©chantillonnage adaptatif pour les syst√®mes √† haut volume."
        else:
            reco_traces_text = f"Traces: {traces_collectees} collect√©es. Augmenter la couverture des traces sur les services critiques et les flux utilisateurs cl√©s."

        if metriques_collectees > 5000:
            reco_metriques_text = f"M√©triques: {metriques_collectees} collect√©es. Assurer la pertinence des m√©triques (RED, USE) et explorer les m√©triques personnalis√©es."
        else:
            reco_metriques_text = f"M√©triques: {metriques_collectees} collect√©es. √âtoffer la collecte avec des m√©triques orient√©es business et exp√©rience utilisateur."

        if logs_traites > 50000:
            reco_logs_text = f"Logs: {logs_traites} trait√©s. Optimiser la corr√©lation des logs avec les traces et m√©triques via des identifiants partag√©s."
        else:
            reco_logs_text = f"Logs: {logs_traites} trait√©s. Standardiser les formats de logs (ex: JSON structur√©) et enrichir avec des contextes applicatifs."

        if dashboards_actifs >= 5:
            reco_dashboards_text = f"Dashboards: {dashboards_actifs} actifs. Personnaliser les dashboards par √©quipe/service et int√©grer des visualisations d'alertes."
        else:
            reco_dashboards_text = f"Dashboards: {dashboards_actifs} actifs. D√©velopper davantage de dashboards pour les KPIs cl√©s et les flux critiques."

        return {
            'agent_id': self.agent_id,
            'agent_file_name': agent_filename,
            'type_rapport': 'observabilite',
            'timestamp': timestamp.isoformat(),
            'specialisation': 'Observabilit√© Syst√®me & Applicative Distribu√©e',
            'score_global': score_observabilite_global,
            'niveau_qualite': niveau_qualite,
            'conformite': conformite,
            'signature_cryptographique': 'N/A (Fonctionnalit√© non impl√©ment√©e pour cet agent)',
            'issues_critiques_identifies': issues_critiques_count,
            'architecture_observabilite': {
                'description': "Plateforme d'observabilit√© centralis√©e con√ßue pour offrir une visibilit√© de bout en bout sur la sant√©, la performance et le comportement des syst√®mes distribu√©s.",
                'statut_operationnel': 'Plateforme d\'observabilit√© pleinement op√©rationnelle et int√©gr√©e aux flux CI/CD.',
                'confirmation_specialisation': f"{self.agent_id} confirm√© comme expert en conception et impl√©mentation de strat√©gies d\'observabilit√©.",
                'piliers': ['Traces distribu√©es (Tracing)', 'M√©triques temporelles (Metrics)', 'Logs structur√©s (Logging)', 'Visualisation & Alerting Int√©gr√©'],
                'outils_simules': ['OpenTelemetry (Collector & SDKs)', 'Prometheus/VictoriaMetrics (Time-Series DB)', 'Grafana/Kibana (Visualisation)', 'ELK Stack/Loki (Log Management)']
            },
            'recommandations_observabilite': [
                f"üîç {reco_traces_text}",
                f"üìä {reco_metriques_text}",
                f"üìù {reco_logs_text}",
                f"üìã {reco_dashboards_text}",
                "‚öôÔ∏è AUTOMATION: Envisager l'automatisation de la d√©tection d'anomalies bas√©e sur le machine learning pour les m√©triques et logs."
            ],
            'issues_critiques_observabilite_details': issues_details if issues_critiques_count > 0 else ["Aucun issue critique d'observabilit√© majeur d√©tect√©. La plateforme r√©pond aux exigences actuelles."],
            'details_techniques_observabilite': {
                'strategie_observabilite': "Approche 'Three Pillars of Observability' (Traces, Metrics, Logs) augment√©e par une forte capacit√© de visualisation et d'analyse.",
                'indicateurs_cles_suivis': [
                    'Latence de bout en bout par transaction', 
                    'Taux d\'erreurs par service/endpoint (RED)',
                    'Saturation et utilisation des ressources (USE)',
                    'Sant√© des d√©pendances critiques',
                    'Volume et types d\'erreurs dans les logs'
                ],
                'collecte_traces_volume': f"{traces_collectees} traces/p√©riode (simul√©)",
                'granularite_metriques_freq': '15 secondes - 1 minute (simul√©)',
                'retention_logs_duree': '90 jours pour logs critiques, 30 jours pour logs applicatifs (simul√©)',
                'utilisateurs_plateforme_actifs': f"{dashboards_actifs * 5} utilisateurs r√©guliers (simul√©)"
            },
            'metriques_observabilite_detaillees': {
                'score_observabilite_global': {'actuel': score_observabilite_global, 'cible': 100, 'unite': 'points'},
                'couverture_tracing_services': {'actuel': traces_collectees, 'cible': 1000, 'seuil_critique': 500, 'unite': 'traces_indicatives'},
                'volume_metriques_pertinentes': {'actuel': metriques_collectees, 'cible': 5000, 'seuil_critique': 2000, 'unite': 'metriques_indicatives'},
                'centralisation_logs_efficace': {'actuel': logs_traites, 'cible': 50000, 'seuil_critique': 10000, 'unite': 'logs_indicatifs'},
                'disponibilite_dashboards_cles': {'actuel': dashboards_actifs, 'cible': 5, 'seuil_critique': 2, 'unite': 'dashboards'}
            },
            'metadonnees': {
                'version_agent': self.version,
                'version_rapport': '1.1.0',
                'notes_qualite': "Ce rapport d'observabilit√© est conforme aux standards v1.2 de l'√©quipe NextGeneration.",
                'dependances_simulation': ['OpenTelemetry', 'Prometheus', 'Grafana', 'ELK Stack'],
                'context_analyse': context.get('cible', 'Analyse strat√©gique de la plateforme d\'observabilit√© globale')
            }
        }

    async def _generer_rapport_performance_monitoring(self, context: Dict, metriques: Dict, timestamp) -> Dict[str, Any]:
        """G√©n√®re le contenu du rapport de performance strat√©gique li√© au monitoring."""
        observability_data = metriques.get('observability_metrics', {}) # utiliser les donn√©es d'observabilit√© g√©n√©rales
        monitoring_health = metriques.get('monitoring_health', {})
        agent_filename = Path(__file__).name

        score = 0
        issues_details = []
        
        # Simulation de donn√©es plus sp√©cifiques √† la performance du monitoring
        latence_collecte_ms_simule = observability_data.get('latence_collecte_ms_p95', 8) # P95
        overhead_agent_simule_pourcentage = observability_data.get('overhead_agent_cpu_avg', 1.5) # % CPU moyen
        debit_traitement_events_sec_simule = observability_data.get('debit_traitement_metrics_sec', 15000)
        utilisation_cpu_monitoring_simule = observability_data.get('cpu_usage_monitoring_total_avg', 12) # % CPU total moyen

        # Crit√®res de scoring pour la performance du monitoring
        if latence_collecte_ms_simule < 10: score += 25
        else: issues_details.append(f"Latence de collecte P95 √©lev√©e: {latence_collecte_ms_simule}ms (cible < 10ms)")
        if overhead_agent_simule_pourcentage < 2: score += 25
        else: issues_details.append(f"Overhead moyen des agents de monitoring: {overhead_agent_simule_pourcentage}% (cible < 2%)")
        if debit_traitement_events_sec_simule >= 10000 : score += 25
        else: issues_details.append(f"D√©bit de traitement des donn√©es de t√©l√©m√©trie: {debit_traitement_events_sec_simule} events/sec (cible >= 10000)")
        if monitoring_health.get('system_responsive'): score += 25 # La r√©activit√© g√©n√©rale du syst√®me reste un pilier
        else: issues_details.append("Syst√®me de monitoring global non r√©actif, impactant la performance per√ßue de l'analyse.")
        
        score_performance_global = score
        niveau_qualite = "OPTIMAL" if score_performance_global >= 90 else "ACCEPTABLE" if score_performance_global >= 70 else "CRITIQUE"
        conformite = "‚úÖ CONFORME" if score_performance_global >= 70 else "‚ùå NON CONFORME"
        issues_critiques_count = len(issues_details)
        
        # Recommandations am√©lior√©es
        reco_latence = (f"Latence de collecte (P95): {latence_collecte_ms_simule}ms. Maintenir sous 10ms pour une r√©activit√© optimale."
                        if latence_collecte_ms_simule < 10
                        else f"Latence de collecte (P95): {latence_collecte_ms_simule}ms. Investiguer les causes de cette latence (r√©seau, charge agents). Cible < 10ms.")
        reco_overhead = (f"Overhead agents: {overhead_agent_simule_pourcentage}% CPU. Excellent, impact minimal sur les applications monitor√©es."
                         if overhead_agent_simule_pourcentage < 2
                         else f"Overhead agents: {overhead_agent_simule_pourcentage}% CPU. Analyser les agents consommateurs et optimiser leur configuration/ressources. Cible < 2%.")
        reco_debit = (f"D√©bit traitement: {debit_traitement_events_sec_simule} events/sec. Capacit√© de traitement ad√©quate."
                      if debit_traitement_events_sec_simule >= 10000
                      else f"D√©bit traitement: {debit_traitement_events_sec_simule} events/sec. √âvaluer la scalabilit√© de la pipeline de collecte et de traitement. Cible >= 10000 events/sec.")
        reco_reactivite_sys = ("R√©activit√© syst√®me monitoring: Optimale."
                               if monitoring_health.get('system_responsive')
                               else "R√©activit√© syst√®me monitoring: D√©grad√©e. Identifier les goulots d'√©tranglement internes au syst√®me de monitoring.")

        return {
            'agent_id': self.agent_id,
            'agent_file_name': agent_filename,
            'type_rapport': 'performance',
            'timestamp': timestamp.isoformat(),
            'specialisation': 'Analyse & Optimisation de Performance des Syst√®mes de Monitoring',
            'score_global': score_performance_global,
            'niveau_qualite': niveau_qualite,
            'conformite': conformite,
            'signature_cryptographique': 'N/A (Fonctionnalit√© non impl√©ment√©e pour cet agent)',
            'issues_critiques_identifies': issues_critiques_count,
            'architecture_performance_monitoring': {
                'description': "Analyse approfondie de la performance intrins√®que du syst√®me de monitoring, incluant la latence de collecte, l'overhead des agents, le d√©bit de traitement des donn√©es de t√©l√©m√©trie, et la consommation globale des ressources.",
                'statut_operationnel_performance': "Syst√®me d'analyse de performance du monitoring pleinement op√©rationnel.",
                'confirmation_specialisation_performance': f"{self.agent_id} est confirm√© pour l'analyse et l'optimisation de la performance des syst√®mes de monitoring distribu√©s.",
                'indicateurs_cles_performance_architecture': [
                    'Latence de collecte des donn√©es (P95, P99)', 
                    'Overhead CPU/M√©moire des agents de monitoring sur les h√¥tes applicatifs',
                    'D√©bit de traitement des donn√©es de t√©l√©m√©trie (√©v√©nements/seconde)', 
                    'Utilisation CPU/M√©moire par les composants centraux du syst√®me de monitoring (collecteurs, bases de donn√©es, etc.)',
                    'Temps de r√©ponse des APIs de configuration et de requ√™tage du monitoring'
                ]
            },
            'recommandations_performance': [
                f"‚ö° {reco_latence}",
                f"üî¨ {reco_overhead}",
                f"üöÄ {reco_debit}",
                f"üíª {reco_reactivite_sys}",
                "üìà PROJECTION: Mod√©liser la croissance des donn√©es de t√©l√©m√©trie pour anticiper les besoins futurs en capacit√© de la plateforme de monitoring."
            ],
            'issues_critiques_performance_monitoring_details': issues_details if issues_critiques_count > 0 else ["Aucun issue critique de performance majeur d√©tect√© pour le syst√®me de monitoring lui-m√™me."],
            'details_techniques_performance_monitoring': {
                'strategie_analyse_performance': "Analyse proactive et continue des goulots d'√©tranglement, optimisation des configurations d'agents et des ressources allou√©es √† la plateforme de monitoring.",
                'kpis_cles_performance_suivis': [
                    f"Latence de collecte (P95): {latence_collecte_ms_simule}ms",
                    f"Overhead moyen des agents CPU: {overhead_agent_simule_pourcentage}%",
                    f"D√©bit de traitement des donn√©es: {debit_traitement_events_sec_simule} events/sec",
                    f"Utilisation CPU moyenne du syst√®me de monitoring: {utilisation_cpu_monitoring_simule}%"
                ],
                'outils_analyse_performance_simules': ['Profilers (e.g., cProfile, Pyflame)', 'Benchmarking tools', 'Simulateurs de charge'],
                'ressources_allouees_monitoring_simule': 'CPU: 8 vCores, RAM: 32GB, Disque: 1TB SSD (cluster de monitoring)'
            },
            'metriques_performance_monitoring_detaillees': {
                'score_performance_monitoring_global': {'actuel': score_performance_global, 'cible': 100, 'unite': 'points'},
                'latence_collecte_p95_ms': {'actuel': latence_collecte_ms_simule, 'cible': 10, 'unite': 'ms'},
                'overhead_agents_cpu_pourcentage': {'actuel': overhead_agent_simule_pourcentage, 'cible': 2, 'unite': '%'},
                'debit_traitement_events_par_sec': {'actuel': debit_traitement_events_sec_simule, 'cible': 10000, 'unite': 'events/sec'},
                'reactivite_systeme_monitoring_sante': {'actuel': 100 if monitoring_health.get('system_responsive') else 30, 'cible': 100, 'unite': '%'}
            },
            'metadonnees': {
                'version_agent': self.version,
                'version_rapport': '1.1.0',
                'notes_qualite': "Rapport de performance du syst√®me de monitoring conforme aux standards v1.2.",
                'specialisation_agent': 'performance_analysis_monitoring_systems',
                'context_analyse': context.get('cible', 'Analyse de performance du syst√®me de monitoring distribu√©')
            }
        }

    async def _generer_rapport_alertes(self, context: Dict, metriques: Dict, timestamp) -> Dict[str, Any]:
        """G√©n√®re le contenu du rapport d'alertes strat√©gique."""
        observability_metrics = metriques.get('observability_metrics', {})
        score = 0
        issues_details = []
        regles_alertes_simule = observability_metrics.get('alert_rules', 0)
        alertes_actives_simule = 3 
        couverture_alertes_simule = 95 
        if regles_alertes_simule >= 10: score += 30
        else: issues_details.append(f"Nombre de r√®gles d'alertes faible: {regles_alertes_simule}")
        if alertes_actives_simule <= 5: score += 30 
        else: issues_details.append(f"Nombre √©lev√© d'alertes actives: {alertes_actives_simule}")
        if couverture_alertes_simule >= 90: score += 40
        else: issues_details.append(f"Couverture des alertes insuffisante: {couverture_alertes_simule}%")
        score_alertes_global = score
        niveau_qualite = "OPTIMAL" if score_alertes_global >= 90 else "ACCEPTABLE" if score_alertes_global >= 70 else "CRITIQUE"
        conformite = "‚úÖ CONFORME" if score_alertes_global >= 70 else "‚ùå NON CONFORME"
        issues_critiques_count = len(issues_details)
        return {
            'agent_id': 'agent_06_specialiste_monitoring_sprint4',
            'type_rapport': 'alertes',
            'timestamp': timestamp.isoformat(),
            'specialisation': 'Gestion Strat√©gique des Alertes',
            'score_global': score_alertes_global,
            'niveau_qualite': niveau_qualite,
            'conformite': conformite,
            'issues_critiques_identifies': issues_critiques_count,
            'architecture_alertes': {
                'description': "Syst√®me de gestion des alertes con√ßu pour une d√©tection proactive et une notification rapide des incidents.",
                'composants_cles': ['Moteur de r√®gles d\'alertes', 'Syst√®me de notification multi-canal', 'Tableau de bord de suivi des alertes', 'Processus d\'escalade']
            },
            'recommandations_alertes': [
                f"üö® R√àGLES D'ALERTES: {regles_alertes_simule} configur√©es. R√©viser et affiner r√©guli√®rement.",
                f"‚ö†Ô∏è ALERTES ACTIVES: {alertes_actives_simule} en cours. Prioriser et traiter.",
                f"üéØ COUVERTURE DES ALERTES: {couverture_alertes_simule}%. Viser une couverture de 99%+ des services critiques.",
                f"üìö DOCUMENTATION: S'assurer que chaque alerte a une proc√©dure de r√©ponse document√©e (runbook)."
            ],
            'issues_critiques_alertes_details': issues_details if issues_critiques_count > 0 else ["Aucun issue critique majeur dans la gestion des alertes d√©tect√©."],
            'details_techniques_alertes': {
                'nombre_regles_actives': regles_alertes_simule,
                'temps_moyen_detection': '< 1 min (simul√©)',
                'canaux_notification': ['Email', 'Slack', 'PagerDuty (simul√©)'],
                'severite_niveaux': ['Critique', 'Avertissement', 'Information']
            },
            'metriques_alertes_detaillees': {
                'score_alertes_global': score_alertes_global,
                'nombre_regles_configurees': regles_alertes_simule,
                'alertes_actives_en_cours': alertes_actives_simule,
                'pourcentage_couverture_alertes': couverture_alertes_simule,
                'score_nombre_regles': 30 if regles_alertes_simule >= 10 else 5,
                'score_alertes_actives': 30 if alertes_actives_simule <= 5 else 5,
                'score_couverture': 40 if couverture_alertes_simule >= 90 else 10
            },
            'metadonnees': {
                'specialisation_agent': 'gestion_alertes_intelligentes',
                'context_analyse': context.get('cible', 'analyse_systeme_alertes')
            }
        }

    async def generer_rapport_markdown(self, rapport_json: Dict[str, Any], type_rapport: str, context: Dict[str, Any]) -> str:
        from datetime import datetime 
        timestamp_val = datetime.now() 
        if type_rapport == 'monitoring':
            return await self._generer_markdown_monitoring(rapport_json, context, timestamp_val)
        elif type_rapport == 'observabilite':
            return await self._generer_markdown_observabilite(rapport_json, context, timestamp_val)
        elif type_rapport == 'performance': 
            return await self._generer_markdown_performance_monitoring(rapport_json, context, timestamp_val)
        elif type_rapport == 'alertes':
            return await self._generer_markdown_alertes(rapport_json, context, timestamp_val)
        else:
            self.logger.warning(f"Type de rapport Markdown inconnu: {type_rapport}. Utilisation du rapport monitoring par d√©faut.")
            return await self._generer_markdown_monitoring(rapport_json, context, timestamp_val)

    async def _generer_markdown_monitoring(self, rapport: Dict, context: Dict, timestamp) -> str:
        score = rapport.get('score_global', 0)
        niveau_qualite = rapport.get('niveau_qualite', 'N/A')
        conformite = rapport.get('conformite', 'N/A')
        signature_crypto = rapport.get('signature_cryptographique', 'N/A')
        agent_file_name = rapport.get('agent_file_name', rapport.get('agent_id', 'N/A'))
        issues_count = rapport.get('issues_critiques_identifies', 0)
        architecture = rapport.get('architecture_monitoring', {})
        recommandations = rapport.get('recommandations_monitoring', [])
        issues_details = rapport.get('issues_critiques_monitoring_details', [])
        details_tech = rapport.get('details_techniques_monitoring', {})
        metriques_detaillees = rapport.get('metriques_monitoring_detaillees', {})

        objectifs_str_list = [f"- {o}" for o in architecture.get('objectifs_principaux', [])]
        objectifs_block = "\\n".join(objectifs_str_list)
        
        tech_cles_list = architecture.get('technologies_cles', [])
        tech_cles_str = ", ".join(tech_cles_list) if tech_cles_list else "Non sp√©cifi√©es"
        
        recommandations_str_list = [f"- {r}" for r in recommandations]
        recommandations_block = "\\n".join(recommandations_str_list)
        
        issues_critiques_str_list = [f"- üî¥ {i}" for i in issues_details] if issues_count > 0 else ["- Aucun issue critique majeur de monitoring d√©tect√©."]
        issues_block = "\\n".join(issues_critiques_str_list)

        otel_disponible_icon = '‚úÖ' if details_tech.get('opentelemetry_disponible') else '‚ùå'
        tracer_provider_status = '‚úÖ actif' if details_tech.get('tracer_provider_actif') else '‚ùå inactif'
        meter_provider_status = '‚úÖ actif' if details_tech.get('meter_provider_actif') else '‚ùå inactif'
        
        reactivite_val = metriques_detaillees.get('reactivite_systeme_monitoring', {}).get('actuel', 0)
        if reactivite_val >= 70:
            reactivite_systeme_icon = '‚úÖ R√©actif'
        elif reactivite_val >= 40:
            reactivite_systeme_icon = 'üî∂ Moyen'
        else:
            reactivite_systeme_icon = '‚ùå Non R√©actif'

        collecteurs_donnees_list = details_tech.get('collecteurs_donnees', [])
        collecteurs_donnees_str_list = [f"  - {cd}" for cd in collecteurs_donnees_list]
        collecteurs_donnees_block = "\\n".join(collecteurs_donnees_str_list) if collecteurs_donnees_list else "  - Non sp√©cifi√©s"

        md_content = f"""# üìà **RAPPORT MONITORING STRAT√âGIQUE : {rapport.get('agent_id', 'N/A')}**

**Date :** {timestamp.strftime('%Y-%m-%d %H:%M:%S')}
**Module :** {agent_file_name}
**Score Global** : {score/10:.1f}/10
**Niveau Qualit√©** : {niveau_qualite}
**Conformit√©** : {conformite}
**Signature Cryptographique** : {signature_crypto}
**Issues Critiques** : {issues_count}

## üèóÔ∏è Architecture Monitoring
{architecture.get('description', 'Description non disponible.')}
- **Statut Op√©rationnel :** {architecture.get('statut_operationnel', 'Non sp√©cifi√©.')}
- **Confirmation Sp√©cialisation :** {architecture.get('confirmation_specialisation', 'Non confirm√©e.')}

**Objectifs principaux :**
{objectifs_block}

**Technologies cl√©s (simul√©es) :** {tech_cles_str}

## üîß Recommandations Monitoring
{recommandations_block}

## üö® Issues Critiques Monitoring
{issues_block}

## üìã D√©tails Techniques Monitoring
- **Strat√©gie Monitoring :** {details_tech.get('strategie_monitoring', 'Non d√©finie.')}
- **Collecteurs de Donn√©es Principaux :**
{collecteurs_donnees_block}
- **OpenTelemetry disponible :** {otel_disponible_icon}
- **Tracer Provider :** {tracer_provider_status}
- **Meter Provider :** {meter_provider_status}
- **Traces collect√©es (session) :** {details_tech.get('traces_collectees_session', 0)}
- **M√©triques collect√©es (session) :** {details_tech.get('metriques_collectees_session', 0)}
- **Logs trait√©s (session) :** {details_tech.get('logs_traites_session', 0)}
- **R√®gles d'alertes (monitoring) :** {details_tech.get('alert_rules_actives_monitoring', 0)}
- **Dashboards actifs (monitoring) :** {details_tech.get('dashboards_actifs_monitoring', 0)}

## üìä M√©triques Monitoring D√©taill√©es
- **Score Monitoring Global :** {metriques_detaillees.get('score_monitoring_global', {}).get('actuel',0)}/{metriques_detaillees.get('score_monitoring_global', {}).get('cible',100)}
- **Sant√© T√©l√©m√©trie :** {metriques_detaillees.get('sante_telemetrie', {}).get('actuel',0)}/{metriques_detaillees.get('sante_telemetrie', {}).get('cible',100)} {metriques_detaillees.get('sante_telemetrie', {}).get('unite','%')}
- **Efficacit√© Tracing :** {metriques_detaillees.get('efficacite_tracing', {}).get('actuel',0)}/{metriques_detaillees.get('efficacite_tracing', {}).get('cible',100)} {metriques_detaillees.get('efficacite_tracing', {}).get('unite','%')}
- **Couverture M√©triques :** {metriques_detaillees.get('couverture_metriques', {}).get('actuel',0)}/{metriques_detaillees.get('couverture_metriques', {}).get('cible',100)} {metriques_detaillees.get('couverture_metriques', {}).get('unite','%')}
- **R√©activit√© Syst√®me Monitoring :** {reactivite_systeme_icon} ({metriques_detaillees.get('reactivite_systeme_monitoring', {}).get('actuel',0)}/{metriques_detaillees.get('reactivite_systeme_monitoring', {}).get('cible',100)} {metriques_detaillees.get('reactivite_systeme_monitoring', {}).get('unite','%')})
- **Services Monitor√©s OK :** {metriques_detaillees.get('services_monitores_ok', {}).get('actuel',0)}/{metriques_detaillees.get('services_monitores_ok', {}).get('total',0)} {metriques_detaillees.get('services_monitores_ok', {}).get('unite','services')}
- **R√®gles d'Alertes Configur√©es (pour Monitoring) :** {metriques_detaillees.get('regles_alertes_configurees_monitoring', {}).get('actuel',0)} {metriques_detaillees.get('regles_alertes_configurees_monitoring', {}).get('unite','r√®gles')}

--- 

*Rapport Monitoring g√©n√©r√© par {rapport.get('agent_id', 'Agent Inconnu')} - {timestamp.strftime('%Y-%m-%d %H:%M:%S')}*
*üìä {rapport.get('specialisation', 'Sp√©cialiste Monitoring & Observabilit√©')}*
*üìÇ Sauvegard√© dans : reports/*
"""
        return md_content

    async def _generer_markdown_observabilite(self, rapport: Dict, context: Dict, timestamp) -> str:
        score = rapport.get('score_global', 0)
        niveau_qualite = rapport.get('niveau_qualite', 'N/A')
        conformite = rapport.get('conformite', 'N/A')
        signature_crypto = rapport.get('signature_cryptographique', 'N/A')
        agent_file_name = rapport.get('agent_file_name', rapport.get('agent_id', 'N/A'))
        issues_count = rapport.get('issues_critiques_identifies', 0)
        architecture = rapport.get('architecture_observabilite', {})
        recommandations = rapport.get('recommandations_observabilite', [])
        issues_details = rapport.get('issues_critiques_observabilite_details', [])
        details_tech = rapport.get('details_techniques_observabilite', {})
        metriques_detaillees = rapport.get('metriques_observabilite_detaillees', {})

        piliers_str_list = [f"- {p}" for p in architecture.get('piliers', [])]
        piliers_block = "\\n".join(piliers_str_list)
        
        outils_simules_list = architecture.get('outils_simules', [])
        outils_simules_str = ", ".join(outils_simules_list) if outils_simules_list else "Non sp√©cifi√©s"
        
        recommandations_str_list = [f"- {r}" for r in recommandations]
        recommandations_block = "\\n".join(recommandations_str_list)
        
        issues_critiques_str_list = [f"- üî¥ {i}" for i in issues_details] if issues_count > 0 else ["- Aucun issue critique majeur d'observabilit√© d√©tect√©."]
        issues_block = "\\n".join(issues_critiques_str_list)

        indicateurs_cles_list = details_tech.get('indicateurs_cles_suivis', [])
        indicateurs_cles_str_list = [f"  - {ic}" for ic in indicateurs_cles_list]
        indicateurs_cles_block = "\\n".join(indicateurs_cles_str_list) if indicateurs_cles_list else "  - Non sp√©cifi√©s"

        md_content = f"""# üí° **RAPPORT D'OBSERVABILIT√â STRAT√âGIQUE : {rapport.get('agent_id', 'N/A')}**

**Date :** {timestamp.strftime('%Y-%m-%d %H:%M:%S')}
**Module :** {agent_file_name}
**Score Global** : {score/10:.1f}/10
**Niveau Qualit√©** : {niveau_qualite}
**Conformit√©** : {conformite}
**Signature Cryptographique** : {signature_crypto}
**Issues Critiques** : {issues_count}

## üèóÔ∏è Architecture d'Observabilit√©
{architecture.get('description', 'Description non disponible.')}
- **Statut Op√©rationnel :** {architecture.get('statut_operationnel', 'Non sp√©cifi√©.')}
- **Confirmation Sp√©cialisation :** {architecture.get('confirmation_specialisation', 'Non confirm√©e.')}

**Piliers cl√©s :**
{piliers_block}

**Outils principaux (simul√©s) :** {outils_simules_str}

## üîß Recommandations Strat√©giques d'Observabilit√©
{recommandations_block}

## üö® Issues Critiques d'Observabilit√©
{issues_block}

## üìã D√©tails Techniques de la Plateforme d'Observabilit√©
- **Strat√©gie d'Observabilit√© :** {details_tech.get('strategie_observabilite', 'Non d√©finie.')}
- **Indicateurs Cl√©s Suivis :**
{indicateurs_cles_block}
- **Volume de Collecte des Traces :** {details_tech.get('collecte_traces_volume', 'N/A')}
- **Fr√©quence de Granularit√© des M√©triques :** {details_tech.get('granularite_metriques_freq', 'N/A')}
- **Dur√©e de R√©tention des Logs :** {details_tech.get('retention_logs_duree', 'N/A')}
- **Nombre d'Utilisateurs Actifs de la Plateforme :** {details_tech.get('utilisateurs_plateforme_actifs', 'N/A')}

## üìä M√©triques d'Observabilit√© D√©taill√©es
- **Score Global d'Observabilit√© :** {metriques_detaillees.get('score_observabilite_global', {}).get('actuel',0)}/{metriques_detaillees.get('score_observabilite_global', {}).get('cible',100)} {metriques_detaillees.get('score_observabilite_global', {}).get('unite','points')}
- **Couverture Tracing des Services (indic.) :** {metriques_detaillees.get('couverture_tracing_services', {}).get('actuel',0)}/{metriques_detaillees.get('couverture_tracing_services', {}).get('cible',1000)} {metriques_detaillees.get('couverture_tracing_services', {}).get('unite','traces')} (Seuil critique: {metriques_detaillees.get('couverture_tracing_services', {}).get('seuil_critique',0)})
- **Volume M√©triques Pertinentes (indic.) :** {metriques_detaillees.get('volume_metriques_pertinentes', {}).get('actuel',0)}/{metriques_detaillees.get('volume_metriques_pertinentes', {}).get('cible',5000)} {metriques_detaillees.get('volume_metriques_pertinentes', {}).get('unite','m√©triques')} (Seuil critique: {metriques_detaillees.get('volume_metriques_pertinentes', {}).get('seuil_critique',0)})
- **Efficacit√© Centralisation Logs (indic.) :** {metriques_detaillees.get('centralisation_logs_efficace', {}).get('actuel',0)}/{metriques_detaillees.get('centralisation_logs_efficace', {}).get('cible',50000)} {metriques_detaillees.get('centralisation_logs_efficace', {}).get('unite','logs')} (Seuil critique: {metriques_detaillees.get('centralisation_logs_efficace', {}).get('seuil_critique',0)})
- **Disponibilit√© Dashboards Cl√©s :** {metriques_detaillees.get('disponibilite_dashboards_cles', {}).get('actuel',0)}/{metriques_detaillees.get('disponibilite_dashboards_cles', {}).get('cible',5)} {metriques_detaillees.get('disponibilite_dashboards_cles', {}).get('unite','dashboards')} (Seuil critique: {metriques_detaillees.get('disponibilite_dashboards_cles', {}).get('seuil_critique',0)})

--- 

*Rapport d'Observabilit√© g√©n√©r√© par {rapport.get('agent_id', 'Agent Inconnu')} - {timestamp.strftime('%Y-%m-%d %H:%M:%S')}*
*üí° {rapport.get('specialisation', 'Expert en Observabilit√© Syst√®me & Applicative Distribu√©e')}*
*üìÇ Sauvegard√© dans : reports/*
"""
        return md_content

    async def _generer_markdown_performance_monitoring(self, rapport: Dict, context: Dict, timestamp) -> str:
        score = rapport.get('score_global', 0)
        niveau_qualite = rapport.get('niveau_qualite', 'N/A')
        conformite = rapport.get('conformite', 'N/A')
        signature_crypto = rapport.get('signature_cryptographique', 'N/A')
        agent_file_name = rapport.get('agent_file_name', rapport.get('agent_id', 'N/A'))
        issues_count = rapport.get('issues_critiques_identifies', 0)
        architecture = rapport.get('architecture_performance_monitoring', {})
        recommandations = rapport.get('recommandations_performance', [])
        issues_details = rapport.get('issues_critiques_performance_monitoring_details', [])
        details_tech = rapport.get('details_techniques_performance_monitoring', {})
        metriques_detaillees = rapport.get('metriques_performance_monitoring_detaillees', {})

        indicateurs_arch_list = architecture.get('indicateurs_cles_performance_architecture', [])
        indicateurs_arch_block = "\\\\n".join([f"- {i}" for i in indicateurs_arch_list]) if indicateurs_arch_list else "- Non sp√©cifi√©s"
        
        recommandations_str_list = [f"- {r}" for r in recommandations]
        recommandations_block = "\\\\n".join(recommandations_str_list)
        
        issues_critiques_str_list = [f"- üî¥ {i}" for i in issues_details] if issues_count > 0 else ["- Aucun issue critique majeur de performance pour le syst√®me de monitoring d√©tect√©."]
        issues_block = "\\\\n".join(issues_critiques_str_list)

        kpis_suivis_list = details_tech.get('kpis_cles_performance_suivis', [])
        kpis_suivis_block = "\\\\n".join([f"  - {kpi}" for kpi in kpis_suivis_list]) if kpis_suivis_list else "  - Non sp√©cifi√©s"
        
        outils_analyse_list = details_tech.get('outils_analyse_performance_simules', [])
        outils_analyse_str = ", ".join(outils_analyse_list) if outils_analyse_list else "Non sp√©cifi√©s"

        md_content = f"""# üöÄ **RAPPORT PERFORMANCE DU SYST√àME DE MONITORING : {rapport.get('agent_id', 'N/A')}**

**Date :** {timestamp.strftime('%Y-%m-%d %H:%M:%S')}
**Module :** {agent_file_name}
**Score Global** : {score/10:.1f}/10
**Niveau Qualit√©** : {niveau_qualite}
**Conformit√©** : {conformite}
**Signature Cryptographique** : {signature_crypto}
**Issues Critiques** : {issues_count}

## üèóÔ∏è Architecture d'Analyse de Performance du Monitoring
{architecture.get('description', 'Description non disponible.')}
- **Statut Op√©rationnel (Analyse Perf.) :** {architecture.get('statut_operationnel_performance', 'Non sp√©cifi√©.')}
- **Confirmation Sp√©cialisation (Analyse Perf.) :** {architecture.get('confirmation_specialisation_performance', 'Non confirm√©e.')}

**Indicateurs Cl√©s de Performance de l'Architecture de Monitoring Suivis :**
{indicateurs_arch_block}

## üîß Recommandations d'Optimisation de Performance
{recommandations_block}

## üö® Issues Critiques de Performance du Monitoring
{issues_block}

## üìã D√©tails Techniques d'Analyse de Performance
- **Strat√©gie d'Analyse de Performance :** {details_tech.get('strategie_analyse_performance', 'Non d√©finie.')}
- **KPIs Cl√©s de Performance Suivis (D√©tail) :**
{kpis_suivis_block}
- **Outils d'Analyse de Performance (simul√©s) :** {outils_analyse_str}
- **Ressources Allou√©es au Monitoring (simul√©) :** {details_tech.get('ressources_allouees_monitoring_simule', 'N/A')}

## üìä M√©triques de Performance du Monitoring D√©taill√©es
- **Score Global de Performance Monitoring :** {metriques_detaillees.get('score_performance_monitoring_global', {}).get('actuel',0)}/{metriques_detaillees.get('score_performance_monitoring_global', {}).get('cible',100)} {metriques_detaillees.get('score_performance_monitoring_global', {}).get('unite','points')}
- **Latence de Collecte (P95) :** {metriques_detaillees.get('latence_collecte_p95_ms', {}).get('actuel','N/A')}/{metriques_detaillees.get('latence_collecte_p95_ms', {}).get('cible','N/A')} {metriques_detaillees.get('latence_collecte_p95_ms', {}).get('unite','ms')}
- **Overhead Moyen des Agents (CPU) :** {metriques_detaillees.get('overhead_agents_cpu_pourcentage', {}).get('actuel','N/A')}/{metriques_detaillees.get('overhead_agents_cpu_pourcentage', {}).get('cible','N/A')} {metriques_detaillees.get('overhead_agents_cpu_pourcentage', {}).get('unite','%')}
- **D√©bit de Traitement des Donn√©es :** {metriques_detaillees.get('debit_traitement_events_par_sec', {}).get('actuel','N/A')}/{metriques_detaillees.get('debit_traitement_events_par_sec', {}).get('cible','N/A')} {metriques_detaillees.get('debit_traitement_events_par_sec', {}).get('unite','events/sec')}
- **R√©activit√© Globale du Syst√®me de Monitoring (Sant√©) :** {metriques_detaillees.get('reactivite_systeme_monitoring_sante', {}).get('actuel','N/A')}/{metriques_detaillees.get('reactivite_systeme_monitoring_sante', {}).get('cible','N/A')} {metriques_detaillees.get('reactivite_systeme_monitoring_sante', {}).get('unite','%')}

--- 

*Rapport Performance Monitoring g√©n√©r√© par {rapport.get('agent_id', 'Agent Inconnu')} - {timestamp.strftime('%Y-%m-%d %H:%M:%S')}*
*üöÄ {rapport.get('specialisation', 'Analyse & Optimisation de Performance des Syst√®mes de Monitoring')}*
*üìÇ Sauvegard√© dans : reports/*
"""
        return md_content

    async def _generer_markdown_alertes(self, rapport: Dict, context: Dict, timestamp) -> str:
        score = rapport.get('score_global', 0)
        niveau_qualite = rapport.get('niveau_qualite', 'N/A')
        conformite = rapport.get('conformite', 'N/A')
        issues_count = rapport.get('issues_critiques_identifies', 0)
        architecture = rapport.get('architecture_alertes', {})
        recommandations = rapport.get('recommandations_alertes', [])
        issues_details = rapport.get('issues_critiques_alertes_details', [])
        details_tech = rapport.get('details_techniques_alertes', {})
        metriques_detaillees = rapport.get('metriques_alertes_detaillees', {})

        composants_cles_str_list = [f"- {c}" for c in architecture.get('composants_cles', [])]
        composants_cles_block = "\\n".join(composants_cles_str_list)
        recommandations_str_list = [f"- {r}" for r in recommandations]
        recommandations_block = "\\n".join(recommandations_str_list)
        issues_critiques_str_list = [f"- üî¥ {i}" for i in issues_details] if issues_count > 0 else ["- Aucun issue critique majeur dans la gestion des alertes d√©tect√©."]
        issues_block = "\\n".join(issues_critiques_str_list)
        canaux_notification_str = ", ".join(details_tech.get('canaux_notification', []))
        severite_niveaux_str = ", ".join(details_tech.get('severite_niveaux', []))

        md_content = f"""# üö® **RAPPORT ALERTES : {rapport.get('agent_id', 'N/A')}**

**Date :** {timestamp.strftime('%Y-%m-%d %H:%M:%S')}
**Module :** {rapport.get('agent_id', 'N/A')}
**Score Global** : {score/10:.1f}/10
**Niveau Qualit√©** : {niveau_qualite}
**Conformit√©** : {conformite}
**Issues Critiques** : {issues_count}

## üèóÔ∏è Architecture Alertes
{architecture.get('description', 'Description non disponible.')}
**Composants cl√©s :**
{composants_cles_block}

## üîß Recommandations Alertes
{recommandations_block}

## üö® Issues Critiques Alertes
{issues_block}

## üìã D√©tails Techniques Alertes
- Nombre de r√®gles actives : {details_tech.get('nombre_regles_actives', 'N/A')}
- Temps moyen de d√©tection : {details_tech.get('temps_moyen_detection', 'N/A')}
- Canaux de notification : {canaux_notification_str}
- Niveaux de s√©v√©rit√© : {severite_niveaux_str}

## üìä M√©triques Alertes D√©taill√©es
- Score Alertes Global : {metriques_detaillees.get('score_alertes_global', 0)}/100
- Nombre de R√®gles Configur√©es : {metriques_detaillees.get('nombre_regles_configurees', 0)}
- Alertes Actives en Cours : {metriques_detaillees.get('alertes_actives_en_cours', 0)}
- Pourcentage Couverture Alertes : {metriques_detaillees.get('pourcentage_couverture_alertes', 0)}%
- Score Nombre de R√®gles : {metriques_detaillees.get('score_nombre_regles', 0)}/30
- Score Alertes Actives : {metriques_detaillees.get('score_alertes_actives', 0)}/30
- Score Couverture : {metriques_detaillees.get('score_couverture', 0)}/40

--- 

*Rapport Alertes g√©n√©r√© par {rapport.get('agent_id', 'Agent Inconnu')} - {timestamp.strftime('%Y-%m-%d %H:%M:%S')}*
*üìÇ Sauvegard√© dans : /mnt/c/Dev/nextgeneration/reports/*
"""
        return md_content

    def get_capabilities(self) -> list[str]: 
        return ["monitoring", "observability", "opentelemetry", "generate_strategic_report"]

    async def health_check(self) -> dict: 
        return {"status": "ok", "opentelemetry_available": OPENTELEMETRY_AVAILABLE}

def create_agent_06_specialiste_monitoring_sprint4(**config):
    return Agent06AdvancedMonitoring(**config)