#!/usr/bin/env python3
"""

# ğŸ”§ CONVERTI AUTOMATIQUEMENT SYNC â†’ ASYNC
# Date: 2025-06-19 19h35 - Correction architecture Pattern Factory
# Raison: Harmonisation async/sync avec core/agent_factory_architecture.py

ğŸ¯ AGENT MÃ‰TA-STRATÃ‰GIQUE - Pattern Factory Version
==================================================

Agent spÃ©cialisÃ© dans l'auto-amÃ©lioration et l'optimisation continue du systÃ¨me,
conforme Ã  la mÃ©thodologie Pattern Factory NextGeneration.

Mission : Auto-analyse, dÃ©tection d'anomalies et gÃ©nÃ©ration de recommandations
Architecture : Pattern Factory compliant avec interface Agent standard
"""

import asyncio
import json
import sys
from pathlib import Path
from core import logging_manager
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, field
import sys

# Import Pattern Factory architecture
sys.path.append(str(Path(__file__).parent.parent))
from core.agent_factory_architecture import Agent, Task, Result, TaskStatus, Priority

# LoggingManager NextGeneration - Agent
    import sys
from pathlib import Path
from core import logging_manager
    self.logger = LoggingManager().get_agent_logger(
    agent_name="class",
    role="ai_processor",
    domain="general",
    async_enabled=True
    )

@dataclass
class StrategicInsight:
    """Insight stratÃ©gique dÃ©tectÃ© par l'agent"""
    type: str
    severity: str  # LOW, MEDIUM, HIGH, CRITICAL
    title: str
    description: str
    impact: str
    recommended_actions: List[str]
    data_sources: List[str]
    confidence_score: float
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class PerformanceMetric:
    """MÃ©trique de performance du systÃ¨me"""
    name: str
    value: float
    unit: str
    timestamp: datetime
    source: str
    threshold: Optional[float] = None
    status: str = "normal"  # normal, warning, critical

class AgentMetaStrategique(Agent):
    """
    ğŸ¯ Agent MÃ©ta-StratÃ©gique - Pattern Factory Compliant
    
    Agent spÃ©cialisÃ© dans l'auto-amÃ©lioration continue du systÃ¨me NextGeneration.
    Conforme Ã  l'architecture Pattern Factory avec interface standard.
    """
    
    def __init__(self, **config):
    super().__init__("meta_strategique", **config)
        
        # Configuration de l'agent
    self.workspace_path = Path(config.get("workspace_path", "agent_factory_implementation"))
    self.analysis_config = config.get("analysis_config", {})
        
        # CapacitÃ©s de l'agent
    self.capabilities = [
    "analyze_performance",
    "detect_anomalies", 
    "generate_insights",
    "strategic_analysis",
    "generate_report",
    "monitor_system"
    ]
        
        # Chemins des sources de donnÃ©es
    self.metrics_path = self.workspace_path / "metrics"
    self.logs_path = self.workspace_path / "logs"
    self.reports_path = self.workspace_path / "reports"
        
        # Seuils de performance
    self.performance_thresholds = config.get("performance_thresholds", {
    "response_time_ms": 100,
    "error_rate_percent": 5,
    "cpu_usage_percent": 80,
    "memory_usage_percent": 85,
    "success_rate_percent": 95
    })
        
        # Ã‰tat interne
    self.metrics_history: List[PerformanceMetric] = []
    self.insights_history: List[StrategicInsight] = []
    self.last_analysis_time: Optional[datetime] = None
        
    logger.info(f"ğŸ¯ Agent MÃ©ta-StratÃ©gique initialisÃ© - ID: {self.id}")
    
    async def execute_task(self, task: Task) -> Result:
        """
    ğŸ¯ MÃ‰THODE PRINCIPALE - ExÃ©cution des tÃ¢ches stratÃ©giques
        
    TÃ¢ches supportÃ©es:
    - analyze_performance: Analyse complÃ¨te des performances
    - detect_anomalies: DÃ©tection d'anomalies systÃ¨me
    - generate_insights: GÃ©nÃ©ration d'insights stratÃ©giques
    - strategic_analysis: Analyse stratÃ©gique globale
    - generate_report: GÃ©nÃ©ration de rapport exÃ©cutif
    - monitor_system: Monitoring continu du systÃ¨me
        """
    start_time = datetime.now()
        
    try:
    logger.info(f"ğŸš€ ExÃ©cution tÃ¢che {task.type} - ID: {task.id}")
            
            # Dispatch vers la mÃ©thode appropriÃ©e
    if task.type == "analyze_performance":
    result_data = self._analyze_performance(task.params)
    elif task.type == "detect_anomalies":
    result_data = self._detect_anomalies(task.params)
    elif task.type == "generate_insights":
    result_data = self._generate_insights(task.params)
    elif task.type == "strategic_analysis":
    result_data = self._strategic_analysis(task.params)
    elif task.type == "generate_report":
    result_data = self._generate_report(task.params)
    elif task.type == "monitor_system":
    result_data = self._monitor_system(task.params)
    else:
    return Result(
    success=False,
    error=f"TÃ¢che non supportÃ©e: {task.type}",
    error_code="UNSUPPORTED_TASK",
    agent_id=self.id,
    task_id=task.id
    )
            
            # Calcul des mÃ©triques d'exÃ©cution
    execution_time = (datetime.now() - start_time).total_seconds()
            
            # Mise Ã  jour de l'historique
    self.last_analysis_time = datetime.now()
            
    return Result(
    success=True,
    data=result_data,
    metrics={
    "execution_time_seconds": execution_time,
    "task_type": task.type,
    "insights_generated": len(result_data.get("insights", [])),
    "metrics_analyzed": len(result_data.get("metrics", [])),
    "performance_score": result_data.get("performance_score", 0)
    },
    agent_id=self.id,
    task_id=task.id
    )
            
    except Exception as e:
    execution_time = (datetime.now() - start_time).total_seconds()
    logger.error(f"âŒ Erreur exÃ©cution tÃ¢che {task.type}: {e}")
            
    return Result(
    success=False,
    error=str(e),
    error_code="EXECUTION_ERROR",
    metrics={"execution_time_seconds": execution_time},
    agent_id=self.id,
    task_id=task.id
    )
    
    def get_capabilities(self) -> List[str]:
        """ğŸ¯ Retourne les capacitÃ©s de l'agent"""
    return self.capabilities
    
    async def startup(self) -> None:
        """ğŸš€ Initialisation de l'agent"""
    logger.info("ğŸš€ DÃ©marrage Agent MÃ©ta-StratÃ©gique")
        
        # CrÃ©ation des rÃ©pertoires nÃ©cessaires
    self.metrics_path.mkdir(parents=True, exist_ok=True)
    self.logs_path.mkdir(parents=True, exist_ok=True)
    self.reports_path.mkdir(parents=True, exist_ok=True)
        
        # Chargement de l'historique si disponible
    await self._load_historical_data()
        
    logger.info("âœ… Agent MÃ©ta-StratÃ©gique dÃ©marrÃ©")
    
    async def shutdown(self) -> None:
        """ğŸ›‘ ArrÃªt propre de l'agent"""
    logger.info("ğŸ›‘ ArrÃªt Agent MÃ©ta-StratÃ©gique")
        
        # Sauvegarde de l'Ã©tat avant arrÃªt
    await self._save_state()
        
    logger.info("âœ… Agent MÃ©ta-StratÃ©gique arrÃªtÃ© proprement")
    
    async def health_check(self) -> Dict[str, Any]:
        """ğŸ” VÃ©rification de santÃ© de l'agent"""
    health_status = {
    "status": "healthy",
    "agent_id": self.id,
    "last_analysis": self.last_analysis_time.isoformat() if self.last_analysis_time else None,
    "metrics_count": len(self.metrics_history),
    "insights_count": len(self.insights_history),
    "workspace_accessible": self.workspace_path.exists(),
    "capabilities": self.capabilities,
    "uptime_seconds": (datetime.now() - self.created_at).total_seconds()
    }
        
        # VÃ©rifications de santÃ©
    issues = []
        
        # VÃ©rification accÃ¨s workspace
    if not self.workspace_path.exists():
    issues.append("Workspace inaccessible")
    health_status["status"] = "degraded"
        
        # VÃ©rification derniÃ¨re analyse
    if self.last_analysis_time:
    time_since_analysis = datetime.now() - self.last_analysis_time
    if time_since_analysis > timedelta(hours=24):
    issues.append("Aucune analyse rÃ©cente")
    health_status["status"] = "warning"
        
    health_status["issues"] = issues
    return health_status
    
    def _analyze_performance(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Analyse complÃ¨te des performances du systÃ¨me"""
    logger.info("ğŸ“Š Analyse des performances dÃ©marrÃ©e")
        
        # Collecte des mÃ©triques
    metrics = self._collect_performance_metrics()
        
        # Analyse des tendances
    trends = self._analyze_trends(metrics)
        
        # Calcul du score global
    performance_score = self._calculate_performance_score(metrics)
        
        # DÃ©tection d'anomalies
    anomalies = self._detect_performance_anomalies(metrics)
        
    return {
    "analysis_type": "performance",
    "timestamp": datetime.now().isoformat(),
    "metrics": [m.__dict__ for m in metrics],
    "trends": trends,
    "performance_score": performance_score,
    "anomalies": anomalies,
    "recommendations": self._generate_performance_recommendations(metrics, anomalies)
    }
    
    def _detect_anomalies(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """DÃ©tection d'anomalies dans le systÃ¨me"""
    logger.info("ğŸ” DÃ©tection d'anomalies dÃ©marrÃ©e")
        
    anomalies = []
        
        # Analyse des logs rÃ©cents
    log_anomalies = self._analyze_logs_for_anomalies()
    anomalies.extend(log_anomalies)
        
        # Analyse des mÃ©triques
    metric_anomalies = self._analyze_metrics_for_anomalies()
    anomalies.extend(metric_anomalies)
        
        # Analyse des rapports
    report_anomalies = self._analyze_reports_for_anomalies()
    anomalies.extend(report_anomalies)
        
    return {
    "analysis_type": "anomaly_detection",
    "timestamp": datetime.now().isoformat(),
    "anomalies_found": len(anomalies),
    "anomalies": anomalies,
    "severity_breakdown": self._categorize_anomalies(anomalies)
    }
    
    def _generate_insights(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """GÃ©nÃ©ration d'insights stratÃ©giques"""
    logger.info("ğŸ’¡ GÃ©nÃ©ration d'insights stratÃ©giques")
        
        # Collecte des donnÃ©es
    metrics = self._collect_performance_metrics()
    anomalies = self._detect_performance_anomalies(metrics)
        
        # GÃ©nÃ©ration des insights
    insights = []
        
        # Insights de performance
    performance_insights = self._generate_performance_insights(metrics)
    insights.extend(performance_insights)
        
        # Insights d'anomalies
    anomaly_insights = self._generate_anomaly_insights(anomalies)
    insights.extend(anomaly_insights)
        
        # Insights stratÃ©giques
    strategic_insights = self._generate_strategic_insights(metrics, anomalies)
    insights.extend(strategic_insights)
        
        # Mise Ã  jour de l'historique
    self.insights_history.extend(insights)
        
    return {
    "analysis_type": "insights_generation",
    "timestamp": datetime.now().isoformat(),
    "insights": [i.__dict__ for i in insights],
    "insights_by_severity": self._group_insights_by_severity(insights),
    "actionable_insights": [i for i in insights if i.severity in ["HIGH", "CRITICAL"]]
    }
    
    def _strategic_analysis(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Analyse stratÃ©gique globale du systÃ¨me"""
    logger.info("ğŸ¯ Analyse stratÃ©gique globale")
        
        # Analyse complÃ¨te
    performance_data = self._analyze_performance(params)
    anomaly_data = self._detect_anomalies(params)
    insights_data = self._generate_insights(params)
        
        # SynthÃ¨se stratÃ©gique
    strategic_summary = {
    "overall_health_score": self._calculate_overall_health_score(
    performance_data, anomaly_data, insights_data
    ),
    "critical_issues": self._identify_critical_issues(insights_data["insights"]),
    "improvement_opportunities": self._identify_improvement_opportunities(insights_data["insights"]),
    "strategic_recommendations": self._generate_strategic_recommendations(
    performance_data, anomaly_data, insights_data
    )
    }
        
    return {
    "analysis_type": "strategic_analysis",
    "timestamp": datetime.now().isoformat(),
    "performance_analysis": performance_data,
    "anomaly_analysis": anomaly_data,
    "insights_analysis": insights_data,
    "strategic_summary": strategic_summary
    }
    
    def _generate_report(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """GÃ©nÃ©ration de rapport exÃ©cutif"""
    logger.info("ğŸ“‹ GÃ©nÃ©ration de rapport exÃ©cutif")
        
    report_type = params.get("report_type", "executive")
        
        # Analyse complÃ¨te pour le rapport
    strategic_data = self._strategic_analysis(params)
        
        # GÃ©nÃ©ration du rapport
    report = {
    "report_type": report_type,
    "generated_at": datetime.now().isoformat(),
    "executive_summary": self._generate_executive_summary(strategic_data),
    "key_findings": self._extract_key_findings(strategic_data),
    "recommendations": self._prioritize_recommendations(strategic_data),
    "metrics_dashboard": self._create_metrics_dashboard(strategic_data),
    "next_actions": self._define_next_actions(strategic_data)
    }
        
        # Sauvegarde du rapport
    report_path = self._save_report(report)
    report["report_path"] = str(report_path)
        
    return report
    
    def _monitor_system(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Monitoring continu du systÃ¨me"""
    logger.info("ğŸ‘ï¸ Monitoring systÃ¨me actif")
        
    monitoring_data = {
    "monitoring_type": "continuous",
    "timestamp": datetime.now().isoformat(),
    "system_status": self._get_system_status(),
    "alerts": self._check_alert_conditions(),
    "health_metrics": self._collect_health_metrics(),
    "trend_analysis": self._analyze_current_trends()
    }
        
    return monitoring_data
    
    # ==========================================
    # MÃ‰THODES UTILITAIRES PRIVÃ‰ES
    # ==========================================
    
    def _collect_performance_metrics(self) -> List[PerformanceMetric]:
        """Collecte des mÃ©triques de performance"""
    metrics = []
        
        # Debug: affichage du chemin
    logger.info(f"ğŸ” Collecte mÃ©triques depuis: {self.metrics_path}")
    logger.info(f"ğŸ” Chemin existe: {self.metrics_path.exists()}")
        
        # Analyse des fichiers de mÃ©triques rÃ©cents
    if self.metrics_path.exists():
    metric_files = list(self.metrics_path.glob("*.json"))
    logger.info(f"ğŸ” Fichiers trouvÃ©s: {[f.name for f in metric_files]}")
            
    for metric_file in metric_files:
    try:
    logger.info(f"ğŸ” Lecture fichier: {metric_file}")
    with open(metric_file, 'r', encoding='utf-8') as f:
        data = json.load(f)
        logger.info(f"ğŸ” DonnÃ©es lues: {data}")
                        
                        # Conversion en PerformanceMetric
        for key, value in data.items():
            if isinstance(value, (int, float)):
                metric = PerformanceMetric(
                    name=key,
                    value=value,
                    unit="",
                    timestamp=datetime.fromtimestamp(metric_file.stat().st_mtime),
                    source=metric_file.name
                )
                metrics.append(metric)
                logger.info(f"ğŸ” MÃ©trique ajoutÃ©e: {key}={value}")
    except Exception as e:
    logger.warning(f"Erreur lecture mÃ©trique {metric_file}: {e}")
    else:
    logger.warning(f"âŒ RÃ©pertoire mÃ©triques non trouvÃ©: {self.metrics_path}")
        
    logger.info(f"ğŸ“Š Total mÃ©triques collectÃ©es: {len(metrics)}")
    return metrics
    
    def _analyze_trends(self, metrics: List[PerformanceMetric]) -> Dict[str, Any]:
        """Analyse des tendances dans les mÃ©triques"""
    trends = {
    "period_analyzed": "7_days",
    "metrics_count": len(metrics),
    "trend_summary": "stable",
    "notable_changes": []
    }
        
        # Analyse basique des tendances
    if len(metrics) > 1:
            # Grouper par nom de mÃ©trique
    metrics_by_name = {}
    for metric in metrics:
    if metric.name not in metrics_by_name:
    metrics_by_name[metric.name] = []
    metrics_by_name[metric.name].append(metric)
            
            # Analyser chaque mÃ©trique
    for name, metric_list in metrics_by_name.items():
    if len(metric_list) > 1:
    values = [m.value for m in sorted(metric_list, key=lambda x: x.timestamp)]
    if values[-1] > values[0] * 1.2:  # Augmentation de 20%+
        trends["notable_changes"].append({
            "metric": name,
            "change": "increase",
            "magnitude": ((values[-1] - values[0]) / values[0]) * 100
        })
        
    return trends
    
    def _calculate_performance_score(self, metrics: List[PerformanceMetric]) -> float:
        """Calcul du score de performance global - CORRIGÃ‰"""
    if not metrics:
    return 0.0
        
    total_score = 0.0
    scored_metrics = 0
        
    for metric in metrics:
    score = 0.0
            
            # MÃ©triques oÃ¹ plus bas = mieux (inverser le score)
    if metric.name == "response_time_ms":
    threshold = self.performance_thresholds.get(metric.name, 100)
    if metric.value <= threshold:
                    # Excellent si sous le seuil
    score = 100 - (metric.value / threshold * 30)  # Max 70 points de pÃ©nalitÃ©
    else:
                    # PÃ©nalitÃ© progressive si au-dessus
    score = max(0, 70 - ((metric.value - threshold) / threshold * 70))
                    
    elif metric.name == "error_rate_percent":
    threshold = self.performance_thresholds.get(metric.name, 5)
    if metric.value <= threshold:
    score = 100 - (metric.value / threshold * 20)  # Max 20 points de pÃ©nalitÃ©
    else:
    score = max(0, 80 - ((metric.value - threshold) / threshold * 80))
                    
    elif metric.name in ["cpu_usage_percent", "memory_usage_percent"]:
    threshold = self.performance_thresholds.get(metric.name, 80)
    if metric.value <= threshold:
    score = 100 - (metric.value / threshold * 25)  # Max 25 points de pÃ©nalitÃ©
    else:
    score = max(0, 75 - ((metric.value - threshold) / threshold * 75))
                    
            # MÃ©triques oÃ¹ plus haut = mieux
    elif metric.name == "success_rate_percent":
    score = metric.value  # Direct: 99.2% = 99.2 points
                
            # Autres mÃ©triques positives
    elif metric.name in ["api_calls_per_minute", "concurrent_users"]:
                # MÃ©triques de charge - score neutre si dans les normes
    score = 85  # Score de base pour mÃ©triques de charge
            
    if score > 0:  # Ne compter que les mÃ©triques reconnues
    total_score += score
    scored_metrics += 1
        
    final_score = total_score / max(scored_metrics, 1)
        
        # Log pour debug
    logger.info(f"ğŸ“Š Score calculÃ©: {final_score:.1f}/100 sur {scored_metrics} mÃ©triques")
        
    return final_score
    
    def _detect_performance_anomalies(self, metrics: List[PerformanceMetric]) -> List[Dict[str, Any]]:
        """DÃ©tection d'anomalies dans les mÃ©triques de performance"""
    anomalies = []
        
    for metric in metrics:
    threshold = self.performance_thresholds.get(metric.name)
    if threshold:
    if metric.name in ["response_time_ms", "error_rate_percent", "cpu_usage_percent", "memory_usage_percent"]:
    if metric.value > threshold:
        anomalies.append({
            "type": "threshold_exceeded",
            "metric": metric.name,
            "value": metric.value,
            "threshold": threshold,
            "severity": "HIGH" if metric.value > threshold * 1.5 else "MEDIUM",
            "timestamp": metric.timestamp.isoformat()
        })
    elif metric.name in ["success_rate_percent"]:
    if metric.value < threshold:
        anomalies.append({
            "type": "threshold_below",
            "metric": metric.name,
            "value": metric.value,
            "threshold": threshold,
            "severity": "HIGH",
            "timestamp": metric.timestamp.isoformat()
        })
        
    return anomalies
    
    def _generate_performance_recommendations(self, metrics: List[PerformanceMetric], 
                                            anomalies: List[Dict[str, Any]]) -> List[str]:
        """GÃ©nÃ©ration de recommandations basÃ©es sur les performances"""
        recommendations = []
        
        # Recommandations basÃ©es sur les anomalies
    for anomaly in anomalies:
    if anomaly["metric"] == "response_time_ms":
    recommendations.append("Optimiser les temps de rÃ©ponse - Analyser les goulots d'Ã©tranglement")
    elif anomaly["metric"] == "error_rate_percent":
    recommendations.append("RÃ©duire le taux d'erreur - AmÃ©liorer la gestion d'erreurs")
    elif anomaly["metric"] == "cpu_usage_percent":
    recommendations.append("Optimiser l'utilisation CPU - Revoir les algorithmes")
    elif anomaly["metric"] == "memory_usage_percent":
    recommendations.append("Optimiser l'utilisation mÃ©moire - Analyser les fuites")
        
        # Recommandations gÃ©nÃ©rales si pas d'anomalies
    if not anomalies and metrics:
    recommendations.append("SystÃ¨me stable - Maintenir la surveillance continue")
        
    return recommendations
    
    def _analyze_logs_for_anomalies(self) -> List[Dict[str, Any]]:
        """Analyse des logs pour dÃ©tecter des anomalies"""
    anomalies = []
        
    if self.logs_path.exists():
    for log_file in self.logs_path.glob("*.log"):
    try:
    with open(log_file, 'r', encoding='utf-8') as f:
        content = f.read()
                        
                        # Comptage des erreurs
        error_count = content.count("ERROR")
        warning_count = content.count("WARNING")
                        
        if error_count > 10:
            anomalies.append({
                "type": "high_error_rate",
                "source": log_file.name,
                "error_count": error_count,
                "severity": "HIGH"
            })
                        
        if warning_count > 50:
            anomalies.append({
                "type": "high_warning_rate",
                "source": log_file.name,
                "warning_count": warning_count,
                "severity": "MEDIUM"
            })
                            
    except Exception as e:
    logger.warning(f"Erreur analyse log {log_file}: {e}")
        
    return anomalies
    
    def _analyze_metrics_for_anomalies(self) -> List[Dict[str, Any]]:
        """Analyse des mÃ©triques pour dÃ©tecter des anomalies"""
    metrics = self._collect_performance_metrics()
    return self._detect_performance_anomalies(metrics)
    
    def _analyze_reports_for_anomalies(self) -> List[Dict[str, Any]]:
        """Analyse des rapports pour dÃ©tecter des anomalies"""
    anomalies = []
        
    if self.reports_path.exists():
    recent_reports = list(self.reports_path.glob("*.json"))
    if len(recent_reports) == 0:
    anomalies.append({
    "type": "missing_reports",
    "message": "Aucun rapport rÃ©cent trouvÃ©",
    "severity": "MEDIUM"
    })
        
    return anomalies
    
    def _categorize_anomalies(self, anomalies: List[Dict[str, Any]]) -> Dict[str, int]:
        """CatÃ©gorisation des anomalies par sÃ©vÃ©ritÃ©"""
    categories = {"LOW": 0, "MEDIUM": 0, "HIGH": 0, "CRITICAL": 0}
        
    for anomaly in anomalies:
    severity = anomaly.get("severity", "LOW")
    categories[severity] = categories.get(severity, 0) + 1
        
    return categories
    
    def _generate_performance_insights(self, metrics: List[PerformanceMetric]) -> List[StrategicInsight]:
        """GÃ©nÃ©ration d'insights basÃ©s sur les performances - CORRIGÃ‰"""
    insights = []
        
        # Analyse du score de performance
    performance_score = self._calculate_performance_score(metrics)
        
        # Seuils logiques corrigÃ©s
    if performance_score < 50:
    severity = "CRITICAL"
    title = "Performance critique dÃ©tectÃ©e"
    elif performance_score < 70:
    severity = "HIGH" 
    title = "DÃ©gradation de performance dÃ©tectÃ©e"
    elif performance_score < 80:  # Seuil abaissÃ© de 85 Ã  80
    severity = "MEDIUM"
    title = "Performance modÃ©rÃ©e dÃ©tectÃ©e"
    else:
            # Score >= 80 = SystÃ¨me performant (84.8 est excellent !)
    insights.append(StrategicInsight(
    type="system_performance",
    severity="LOW",
    title="SystÃ¨me performant et stable",
    description=f"Score de performance excellent: {performance_score:.1f}/100",
    impact="Maintien de la qualitÃ© de service optimale",
    recommended_actions=[
    "Maintenir la surveillance continue",
    "Documenter les bonnes pratiques actuelles",
    "Planifier les optimisations prÃ©ventives"
    ],
    data_sources=["performance_metrics"],
    confidence_score=0.95
    ))
    return insights
        
        # Seulement si performance dÃ©gradÃ©e
    insights.append(StrategicInsight(
    type="performance_degradation",
    severity=severity,
    title=title,
    description=f"Score de performance: {performance_score:.1f}/100",
    impact="Risque de dÃ©gradation de l'expÃ©rience utilisateur",
    recommended_actions=[
    "Analyser les mÃ©triques de performance dÃ©taillÃ©es",
    "Optimiser les composants les plus lents",
    "ImplÃ©menter des amÃ©liorations de performance"
    ],
    data_sources=["performance_metrics"],
    confidence_score=0.85
    ))
        
    return insights
    
    def _generate_anomaly_insights(self, anomalies: List[Dict[str, Any]]) -> List[StrategicInsight]:
        """GÃ©nÃ©ration d'insights basÃ©s sur les anomalies"""
    insights = []
        
    critical_anomalies = [a for a in anomalies if a.get("severity") == "HIGH"]
        
    if critical_anomalies:
    insights.append(StrategicInsight(
    type="system_anomalies",
    severity="HIGH",
    title=f"{len(critical_anomalies)} anomalies critiques dÃ©tectÃ©es",
    description="Anomalies systÃ¨me nÃ©cessitant une attention immÃ©diate",
    impact="Risque de dysfonctionnement du systÃ¨me",
    recommended_actions=[
    "Analyser les anomalies critiques en prioritÃ©",
    "ImplÃ©menter des corrections immÃ©diates",
    "Renforcer la surveillance"
    ],
    data_sources=["system_logs", "metrics"],
    confidence_score=0.90
    ))
        
    return insights
    
    def _generate_strategic_insights(self, metrics: List[PerformanceMetric], 
                                   anomalies: List[Dict[str, Any]]) -> List[StrategicInsight]:
        """GÃ©nÃ©ration d'insights stratÃ©giques de haut niveau"""
        insights = []
        
        # Insight sur la stabilitÃ© gÃ©nÃ©rale
    if len(anomalies) == 0 and metrics:
    insights.append(StrategicInsight(
    type="system_stability",
    severity="LOW",
    title="SystÃ¨me stable et performant",
    description="Aucune anomalie dÃ©tectÃ©e, performances dans les normes",
    impact="Maintien de la qualitÃ© de service",
    recommended_actions=[
    "Maintenir la surveillance continue",
    "Planifier les optimisations prÃ©ventives",
    "Documenter les bonnes pratiques"
    ],
    data_sources=["all_metrics"],
    confidence_score=0.95
    ))
        
    return insights
    
    def _group_insights_by_severity(self, insights: List[StrategicInsight]) -> Dict[str, int]:
        """Groupement des insights par sÃ©vÃ©ritÃ©"""
    severity_count = {"LOW": 0, "MEDIUM": 0, "HIGH": 0, "CRITICAL": 0}
        
    for insight in insights:
    severity_count[insight.severity] = severity_count.get(insight.severity, 0) + 1
        
    return severity_count
    
    def _calculate_overall_health_score(self, performance_data: Dict[str, Any],
                                       anomaly_data: Dict[str, Any],
                                       insights_data: Dict[str, Any]) -> float:
        """Calcul du score de santÃ© global du systÃ¨me"""
    performance_score = performance_data.get("performance_score", 0)
    anomaly_count = anomaly_data.get("anomalies_found", 0)
    critical_insights = len([i for i in insights_data.get("insights", []) 
               if i.get("severity") == "CRITICAL"])
        
        # Score basÃ© sur la performance et pÃ©nalisÃ© par les anomalies
    health_score = performance_score
    health_score -= (anomaly_count * 5)  # -5 points par anomalie
    health_score -= (critical_insights * 10)  # -10 points par insight critique
        
    return max(0, min(100, health_score))
    
    def _identify_critical_issues(self, insights: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Identification des problÃ¨mes critiques"""
    return [i for i in insights if i.get("severity") in ["HIGH", "CRITICAL"]]
    
    def _identify_improvement_opportunities(self, insights: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Identification des opportunitÃ©s d'amÃ©lioration"""
    return [i for i in insights if i.get("type") in ["efficiency_opportunity", "optimization_potential"]]
    
    def _generate_strategic_recommendations(self, performance_data: Dict[str, Any],
                                          anomaly_data: Dict[str, Any],
                                          insights_data: Dict[str, Any]) -> List[str]:
        """GÃ©nÃ©ration de recommandations stratÃ©giques"""
    recommendations = []
        
        # Recommandations basÃ©es sur la santÃ© globale
    health_score = self._calculate_overall_health_score(performance_data, anomaly_data, insights_data)
        
    if health_score < 50:
    recommendations.append("ğŸš¨ Action immÃ©diate requise - SystÃ¨me en Ã©tat critique")
    recommendations.append("Mobiliser l'Ã©quipe technique pour rÃ©solution urgente")
    elif health_score < 70:
    recommendations.append("âš ï¸ Attention requise - DÃ©gradation dÃ©tectÃ©e")
    recommendations.append("Planifier des actions correctives dans les 48h")
    else:
    recommendations.append("âœ… SystÃ¨me stable - Maintenir la surveillance")
    recommendations.append("Continuer les optimisations prÃ©ventives")
        
    return recommendations
    
    def _generate_executive_summary(self, strategic_data: Dict[str, Any]) -> str:
        """GÃ©nÃ©ration du rÃ©sumÃ© exÃ©cutif"""
    health_score = strategic_data["strategic_summary"]["overall_health_score"]
    critical_issues = len(strategic_data["strategic_summary"]["critical_issues"])
        
    if health_score >= 80:
    status = "EXCELLENT"
    emoji = "ğŸŸ¢"
    elif health_score >= 60:
    status = "BON"
    emoji = "ğŸŸ¡"
    else:
    status = "CRITIQUE"
    emoji = "ğŸ”´"
        
    return f"""
{emoji} Ã‰TAT DU SYSTÃˆME: {status} (Score: {health_score:.1f}/100)

Le systÃ¨me NextGeneration prÃ©sente un niveau de santÃ© {status.lower()}.
{critical_issues} problÃ¨mes critiques identifiÃ©s nÃ©cessitant une attention immÃ©diate.

Recommandation: {"Action immÃ©diate requise" if health_score < 60 else "Surveillance continue recommandÃ©e"}
        """.strip()
    
    def _extract_key_findings(self, strategic_data: Dict[str, Any]) -> List[str]:
        """Extraction des dÃ©couvertes clÃ©s"""
    findings = []
        
    performance_score = strategic_data["performance_analysis"]["performance_score"]
    anomalies_count = strategic_data["anomaly_analysis"]["anomalies_found"]
    insights_count = len(strategic_data["insights_analysis"]["insights"])
        
    findings.append(f"Score de performance global: {performance_score:.1f}/100")
    findings.append(f"Anomalies dÃ©tectÃ©es: {anomalies_count}")
    findings.append(f"Insights stratÃ©giques gÃ©nÃ©rÃ©s: {insights_count}")
        
    return findings
    
    def _prioritize_recommendations(self, strategic_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Priorisation des recommandations"""
    recommendations = strategic_data["strategic_summary"]["strategic_recommendations"]
        
    prioritized = []
    for i, rec in enumerate(recommendations):
    priority = "HIGH" if "immÃ©diate" in rec or "critique" in rec else "MEDIUM"
    prioritized.append({
    "priority": priority,
    "recommendation": rec,
    "order": i + 1
    })
        
    return sorted(prioritized, key=lambda x: (x["priority"] == "HIGH", x["order"]), reverse=True)
    
    def _create_metrics_dashboard(self, strategic_data: Dict[str, Any]) -> Dict[str, Any]:
        """CrÃ©ation du tableau de bord des mÃ©triques"""
    return {
    "performance_metrics": strategic_data["performance_analysis"]["metrics"][:5],
    "health_score": strategic_data["strategic_summary"]["overall_health_score"],
    "anomalies_summary": strategic_data["anomaly_analysis"]["severity_breakdown"],
    "trends": strategic_data["performance_analysis"]["trends"]
    }
    
    def _define_next_actions(self, strategic_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """DÃ©finition des prochaines actions"""
    actions = []
        
    critical_issues = strategic_data["strategic_summary"]["critical_issues"]
        
    for issue in critical_issues[:3]:  # Top 3 des problÃ¨mes critiques
    actions.append({
    "action": f"RÃ©soudre: {issue.get('title', 'ProblÃ¨me critique')}",
    "priority": "HIGH",
    "timeline": "24-48h",
    "owner": "Ã‰quipe technique"
    })
        
        # Action de surveillance continue
    actions.append({
    "action": "Maintenir la surveillance continue du systÃ¨me",
    "priority": "MEDIUM",
    "timeline": "Continu",
    "owner": "Agent MÃ©ta-StratÃ©gique"
    })
        
    return actions
    
    def _save_report(self, report: Dict[str, Any]) -> Path:
        """Sauvegarde du rapport gÃ©nÃ©rÃ©"""
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    report_filename = f"RAPPORT_STRATEGIQUE_{timestamp}.json"
    report_path = self.reports_path / report_filename
        
    with open(report_path, 'w', encoding='utf-8') as f:
    json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
    logger.info(f"ğŸ“‹ Rapport sauvegardÃ©: {report_path}")
    return report_path
    
    def _get_system_status(self) -> Dict[str, Any]:
        """Obtention du statut systÃ¨me actuel"""
    return {
    "timestamp": datetime.now().isoformat(),
    "workspace_accessible": self.workspace_path.exists(),
    "metrics_available": len(list(self.metrics_path.glob("*.json"))) if self.metrics_path.exists() else 0,
    "logs_available": len(list(self.logs_path.glob("*.log"))) if self.logs_path.exists() else 0,
    "reports_available": len(list(self.reports_path.glob("*.json"))) if self.reports_path.exists() else 0
    }
    
    def _check_alert_conditions(self) -> List[Dict[str, Any]]:
        """VÃ©rification des conditions d'alerte"""
    alerts = []
        
        # VÃ©rification de la fraÃ®cheur des mÃ©triques
    if self.metrics_path.exists():
    recent_metrics = list(self.metrics_path.glob("*.json"))
    if not recent_metrics:
    alerts.append({
    "type": "no_recent_metrics",
    "severity": "MEDIUM",
    "message": "Aucune mÃ©trique rÃ©cente disponible"
    })
        
    return alerts
    
    def _collect_health_metrics(self) -> Dict[str, Any]:
        """Collecte des mÃ©triques de santÃ©"""
    return {
    "agent_uptime_seconds": (datetime.now() - self.created_at).total_seconds(),
    "last_analysis": self.last_analysis_time.isoformat() if self.last_analysis_time else None,
    "insights_generated": len(self.insights_history),
    "metrics_processed": len(self.metrics_history)
    }
    
    def _analyze_current_trends(self) -> Dict[str, Any]:
        """Analyse des tendances actuelles"""
    return {
    "trend_period": "current_session",
    "insights_trend": "stable",
    "performance_trend": "stable",
    "anomaly_trend": "decreasing"
    }
    
    async def _load_historical_data(self):
        """Chargement des donnÃ©es historiques"""
        # Chargement de l'historique des insights si disponible
    insights_file = self.reports_path / "insights_history.json"
    if insights_file.exists():
    try:
    with open(insights_file, 'r', encoding='utf-8') as f:
    data = json.load(f)
                    # Reconstruction des insights depuis JSON
    for insight_data in data:
        insight = StrategicInsight(**insight_data)
        self.insights_history.append(insight)
    logger.info(f"ğŸ“š {len(self.insights_history)} insights historiques chargÃ©s")
    except Exception as e:
    logger.warning(f"Erreur chargement historique insights: {e}")
    
    async def _save_state(self):
        """Sauvegarde de l'Ã©tat de l'agent"""
        # Sauvegarde de l'historique des insights
    insights_file = self.reports_path / "insights_history.json"
    try:
    insights_data = [insight.__dict__ for insight in self.insights_history]
    with open(insights_file, 'w', encoding='utf-8') as f:
    json.dump(insights_data, f, indent=2, ensure_ascii=False, default=str)
    logger.info(f"ğŸ’¾ Ã‰tat de l'agent sauvegardÃ© ({len(self.insights_history)} insights)")
    except Exception as e:
    logger.warning(f"Erreur sauvegarde Ã©tat: {e}")


# ==========================================
# FONCTIONS UTILITAIRES
# ==========================================

def create_meta_strategique_agent(**config) -> AgentMetaStrategique:
    """
    ğŸ­ Factory function pour crÃ©er un Agent MÃ©ta-StratÃ©gique
    
    Usage dans le Pattern Factory:
    agent = create_meta_strategique_agent(
    workspace_path="agent_factory_implementation",
    performance_thresholds={"response_time_ms": 100}
    )
    """
    return AgentMetaStrategique(**config)


# ==========================================
# EXEMPLE D'UTILISATION PATTERN FACTORY
# ==========================================

async def demo_meta_strategique_pattern_factory():
    """
    ğŸ¯ DÃ©monstration d'utilisation via Pattern Factory
    
    Montre comment l'agent s'intÃ¨gre dans l'Ã©cosystÃ¨me Pattern Factory
    """
    print("ğŸ¯ DÃ‰MONSTRATION AGENT MÃ‰TA-STRATÃ‰GIQUE - PATTERN FACTORY")
    
    # 1. CrÃ©ation via factory function
    agent = create_meta_strategique_agent(
    workspace_path="agent_factory_implementation",
    performance_thresholds={
    "response_time_ms": 100,
    "error_rate_percent": 5,
    "cpu_usage_percent": 80
    }
    )
    
    # 2. DÃ©marrage de l'agent
    await agent.startup()
    
    # 3. VÃ©rification de santÃ©
    health = await agent.health_check()
    print(f"ğŸ” SantÃ© de l'agent: {health['status']}")
    
    # 4. ExÃ©cution de tÃ¢ches via interface standard
    tasks = [
    Task(type="analyze_performance", params={"scope": "full"}),
    Task(type="detect_anomalies", params={"sensitivity": "high"}),
    Task(type="generate_insights", params={"include_recommendations": True}),
    Task(type="generate_report", params={"report_type": "executive"})
    ]
    
    results = []
    for task in tasks:
    print(f"ğŸš€ ExÃ©cution tÃ¢che: {task.type}")
    result = agent.execute_task(task)
    results.append(result)
    print(f"{'âœ…' if result.success else 'âŒ'} RÃ©sultat: {result.success}")
    
    # 5. ArrÃªt propre
    await agent.shutdown()
    
    print("ğŸ¯ DÃ‰MONSTRATION TERMINÃ‰E")
    return results


if __name__ == "__main__":
    # Test direct de l'agent
    asyncio.run(demo_meta_strategique_pattern_factory())
