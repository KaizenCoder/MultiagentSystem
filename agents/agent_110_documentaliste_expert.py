#!/usr/bin/env python3
"""

# üîß CONVERTI AUTOMATIQUEMENT SYNC ‚Üí ASYNC
# Date: 2025-06-19 19h35 - Correction architecture Pattern Factory
# Raison: Harmonisation async/sync avec core/agent_factory_architecture.py

üéñÔ∏è AGENT 10 - DOCUMENTALISTE EXPERT
üìö Documentation compl√®te et parfaite (Sprint 1)

MISSION SPRINT 1:
    pass  # TODO: Impl√©menter
- Documentation technique compl√®te code expert Claude
- Guides utilisateur Agent Factory Pattern
- Documentation API endpoints (/health, /metrics)
- Standards documentation pour √©quipe
- Coordination avec Agent 13 (sp√©cialiste documentation)

RESPONSABILIT√âS:
    pass  # TODO: Impl√©menter
- Documentation technique compl√®te
- Guides utilisateur
- Runbook op√©rateur
- Documentation API
- Coordination avec sp√©cialiste documentation

LIVRABLES:
    pass  # TODO: Impl√©menter
- Documentation parfaite
- Guides complets
- API document√©e
- Standards documentation

UTILISATION OBLIGATOIRE CODE EXPERT CLAUDE:
    pass  # TODO: Impl√©menter
- enhanced_agent_templates.py : Validation JSON Schema, h√©ritage, hooks
- optimized_template_manager.py : Cache LRU, hot-reload, m√©triques

Author: Agent Factory Team - Sprint 1
Version: 1.0.0 (Sprint 1)
Created: 2024-12-28
Updated: 2024-12-28
"""

import asyncio
import json
import sys
import os
import re
import logging
from pathlib import Path
from dataclasses import dataclass, asdict
from datetime import datetime
from typing import Dict, List, Any, Optional

# Pattern Factory imports
try:
    from core.agent_factory_architecture import Agent, Task, Result
    PATTERN_FACTORY_AVAILABLE = True
except ImportError:
    print("‚ö†Ô∏è Pattern Factory non disponible. Utilisation des classes de fallback.")
    PATTERN_FACTORY_AVAILABLE = False
    # Fallback classes si l'architecture centrale n'est pas disponible
    class Agent:
        pass  # TODO: Impl√©menter
        def __init__(self, agent_type: str, **config):
            pass  # TODO: Impl√©menter
        pass  # TODO: Impl√©menter
        
        # ‚úÖ MIGRATION SYST√àME LOGGING UNIFI√â
        try:
            from core.manager import LoggingManager
            logging_manager = LoggingManager()
            self.logger = logging_manager.get_logger(
                config_name="general",
                custom_config={
                    "logger_name": f"nextgen.general.110_documentaliste_expert.{self.agent_id if hasattr(self, 'agent_id') else self.id if hasattr(self, 'id') else 'unknown'}",
                    "log_dir": "logs/general",
                    "metadata": {
                        "agent_type": "110_documentaliste_expert",
                        "agent_role": "general",
                        "system": "nextgeneration"
                    }
                }
            )
        except ImportError:
            # Fallback en cas d'indisponibilit√© du LoggingManager
            self.logger = logging.getLogger(self.__class__.__name__)

            self.agent_id = f"fallback_{agent_type}"
            self.name = f"Fallback {agent_type}"
            self.logger = logging.getLogger(self.agent_id)
        async def startup(self): pass
        async def shutdown(self): pass

    class Task:
        pass  # TODO: Impl√©menter
        def __init__(self, task_id: str, description: str, **kwargs):
            self.task_id = task_id
            self.description = description
            # La classe de fallback utilise 'data' pour la compatibilit√© avec les tests
            self.data = kwargs.get('payload', {})
            self.payload = self.data

    class Result:
        pass  # TODO: Impl√©menter
        def __init__(self, success: bool, data: Any = None, error: str = None):
            self.success = success
            self.data = data
            self.error = error

# ===== CONFIGURATION LOGGING (Globale pour le script) =====
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()
    ]
)

# ===== STRUCTURES DE DONN√âES (Inchang√©es) =====

@dataclass
class DocumentationSection:
    """Section documentation structur√©e"""
    title: str
    content: str
    level: int
    type: str
    tags: List[str]
    author: str = "Agent110DocumentalisteExpert"
    timestamp: datetime = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now()
    
    def to_markdown(self) -> str:
        header = "#" * self.level
        return f"{header} {self.title}\n\n{self.content}\n\n"

@dataclass
class APIDocumentation:
    """Documentation API structur√©e"""
    endpoint: str
    method: str
    description: str
    parameters: Dict[str, Any]
    responses: Dict[str, Any]
    examples: Dict[str, str]

# ===== G√âN√âRATEURS DE DOCUMENTATION (Inchang√©s) =====

class CodeDocumentationGenerator:
    """G√©n√©rateur documentation √† partir du code source."""
    def __init__(self, source_path: Path, logger: logging.Logger):
        self.source_path = source_path
        self.logger = logger
        
    def _analyze_file(self, file_path: Path) -> Dict[str, Any]:
        """Analyse un seul fichier de code."""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            classes = re.findall(r'class\s+(\w+).*?:', content)
            functions = re.findall(r'def\s+(\w+)\(.*?\):', content)
            return {"file": file_path.name, "classes": classes, "functions": functions, "lines": len(content.splitlines())}
        except Exception as e:
            self.logger.error(f"Erreur d'analyse sur {file_path}: {e}")
            return {}
    
    def generate(self) -> str:
        """G√©n√®re la documentation compl√®te pour le r√©pertoire source."""
        doc = f"# üîß Documentation Technique : {self.source_path.name}\n\n"
        if not self.source_path.is_dir():
            raise FileNotFoundError(f"Le r√©pertoire source n'existe pas : {self.source_path}")
        
        for py_file in sorted(self.source_path.rglob("*.py")):
            analysis = self._analyze_file(py_file)
            if not analysis:
                continue
            
            relative_path = py_file.relative_to(self.source_path)
            doc += f"## üìÑ Fichier : `{relative_path}`\n"
            doc += f"- **Lignes de code:** {analysis.get('lines', 0)}\n"
            if analysis.get('classes'):
                doc += f"- **Classes:** {', '.join(analysis.get('classes', []))}\n"
            doc += "\n"
        return doc

class UserGuideGenerator:
    """G√©n√©rateur de guides utilisateur."""
    def generate_quick_start(self) -> str:
        return """# üöÄ Guide de D√©marrage Rapide
## Introduction
Ce guide vous aide √† d√©marrer avec le syst√®me.
## Installation
1. Clonez le d√©p√¥t.
2. Installez les d√©pendances : `pip install -r requirements.txt`.
3. Lancez l'application.
"""

# ===== AGENT PRINCIPAL (Nouvelle Impl√©mentation) =====

class Agent110DocumentalisteExpert(Agent):
    """
    üéñÔ∏è AGENT 110 - DOCUMENTALISTE EXPERT
    Orchestre les g√©n√©rateurs pour produire une documentation de haute qualit√©.
    """
    def __init__(self, **config):
        # Pr√©-initialisation pour satisfaire les d√©pendances de la classe de base
        self.agent_type = "agent_110_documentaliste_expert"
        self.agent_id = config.get("agent_id", f"{self.agent_type}_{datetime.now().strftime('%Y%m%d_%H%M%S')}")
        self.name = "Agent 110 Documentaliste Expert"
        self.logger = logging.getLogger(self.agent_id)

        # L'appel √† super() se fait APR√àS la cr√©ation des attributs dont il d√©pend.
        super().__init__(self.agent_type, **config)
        self.logger.info(f"Agent {self.name} initialis√©.")

        # Cr√©er le r√©pertoire des rapports pour cet agent s'il n'existe pas
        self.reports_path = Path(config.get("reports_dir", "reports")) / self.agent_id
        self.reports_path.mkdir(parents=True, exist_ok=True)
        self.logger.info(f"R√©pertoire des rapports configur√© : {self.reports_path}")
        
    async def startup(self):
        self.logger.info(f"üöÄ Agent {self.agent_id} d√©marr√©.")
        await super().startup()

    async def shutdown(self):
        self.logger.info(f"üõë Agent {self.agent_id} arr√™t√©.")
        await super().shutdown()

    async def health_check(self) -> Dict[str, Any]:
        return {"status": "healthy", "timestamp": datetime.now().isoformat()}

    def get_capabilities(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "version": "2.0.0",
            "description": "G√©n√®re de la documentation technique et des guides utilisateur.",
            "tasks": [
                {"name": "generer_doc_code", "description": "G√©n√®re la documentation technique pour un r√©pertoire source.", "parameters": {"path": "str"}},
                {"name": "generer_guide_demarrage", "description": "G√©n√®re un guide de d√©marrage rapide standard."},
            ]
        }

    async def execute_task(self, task: Task) -> Result:
        self.logger.info(f"Ex√©cution de la t√¢che : {task.task_id}")
        task_params = task.data if hasattr(task, 'data') else (task.payload if hasattr(task, 'payload') else {})
        
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            report_file_path = None

            if task.task_id == "generer_doc_code" or task.description == "generer_doc_code":
                source_path_str = task_params.get("path")
                if not source_path_str:
                    return Result(success=False, error="Le chemin ('path') du code source est manquant.")
                
                source_name = Path(source_path_str).name
                generator = CodeDocumentationGenerator(Path(source_path_str), self.logger)
                doc_content = generator.generate()
                
                report_filename = f"rapport_doc_code_{source_name}_{timestamp}.md"
                report_file_path = self.reports_path / report_filename
                
                with open(report_file_path, "w", encoding="utf-8") as f:
                    f.write(doc_content)
                self.logger.info(f"Rapport de documentation du code sauvegard√© : {report_file_path}")
                return Result(success=True, data={"format": "markdown", "content_file_path": str(report_file_path), "message": f"Documentation du code g√©n√©r√©e et sauvegard√©e dans {report_file_path}"})
                    
            elif task.task_id == "generer_guide_demarrage" or task.description == "generer_guide_demarrage":
                generator = UserGuideGenerator()
                guide_content = generator.generate_quick_start()

                report_filename = f"rapport_guide_demarrage_{timestamp}.md"
                report_file_path = self.reports_path / report_filename

                with open(report_file_path, "w", encoding="utf-8") as f:
                    f.write(guide_content)
                self.logger.info(f"Rapport du guide de d√©marrage sauvegard√© : {report_file_path}")
                return Result(success=True, data={"format": "markdown", "content_file_path": str(report_file_path), "message": f"Guide de d√©marrage g√©n√©r√© et sauvegard√© dans {report_file_path}"})
            
            else:
                return Result(success=False, error=f"T√¢che inconnue: {task.task_id}")

        except Exception as e:
            self.logger.error(f"Erreur lors de l'ex√©cution de la t√¢che '{task.task_id}': {e}", exc_info=True)
            return Result(success=False, error=str(e))

# ===== POINT D'ENTR√âE POUR TEST =====

async def main():
    """Point d'entr√©e pour tester l'agent 110."""
    print("--- D√âMARRAGE DU TEST DE L'AGENT 110 ---")
    agent = None
    # D√©finir un r√©pertoire de rapports sp√©cifique pour les tests
    test_reports_dir = Path("reports_test_agent110") 
    try:
        # Instanciation directe de l'agent avec le r√©pertoire de test
        agent = Agent110DocumentalisteExpert(reports_dir=str(test_reports_dir))
        await agent.startup()

        print("\nüî¨ Test 1: G√©n√©ration du guide de d√©marrage...")
        task1 = Task(task_id="generer_guide_demarrage", description="generer_guide_demarrage")
        result1 = await agent.execute_task(task1)
        if result1.success:
            print(f"[‚úÖ SUCC√àS] Guide g√©n√©r√©. Chemin: {result1.data.get('content_file_path')}")
        else:
            print(f"[‚ùå ERREUR] {result1.error}")

        print("\nüî¨ Test 2: G√©n√©ration de la documentation pour le r√©pertoire './core'...")
        task2 = Task(task_id="generer_doc_code", description="generer_doc_code", payload={"path": "./core"})
        result2 = await agent.execute_task(task2)
        if result2.success:
            print(f"[‚úÖ SUCC√àS] Documentation du code g√©n√©r√©e. Chemin: {result2.data.get('content_file_path')}")
        else:
            print(f"[‚ùå ERREUR] {result2.error}")

    except Exception as e:
        print(f"[‚ùå ERREUR] Une exception non g√©r√©e s'est produite: {e}")
        import traceback
        traceback.print_exc()
    
    finally:
        if agent:
            await agent.shutdown()
        # Optionnel: Nettoyer le r√©pertoire de rapports de test si n√©cessaire
        # import shutil
        # if test_reports_dir.exists():
        # shutil.rmtree(test_reports_dir)
        # print(f"R√©pertoire de test {test_reports_dir} supprim√©.")
        print("\n--- FIN DU TEST DE L'AGENT 110 ---")
    # ‚úÖ M√âTHODES STANDARDIS√âES DE RAPPORT

    def _calculate_report_score(self, metrics: Dict[str, Any]) -> int:
        """Calcule le score global du rapport bas√© sur les m√©triques."""
        score = 0
        issues_critiques = []
        
        # Logique de scoring sp√©cifique √† l'agent
        # √Ä adapter selon le type d'agent
        
        return score
    
    def _assess_conformity(self, score: int) -> str:
        """√âvalue la conformit√© bas√©e sur le score."""
        if score >= 90:
            return "‚úÖ CONFORME - OPTIMAL"
        elif score >= 70:
            return "‚úÖ CONFORME - ACCEPTABLE"
        else:
            return "‚ùå NON CONFORME - CRITIQUE"
    
    def _get_quality_level(self, score: int) -> str:
        """D√©termine le niveau de qualit√©."""
        if score >= 90:
            return "OPTIMAL"
        elif score >= 70:
            return "ACCEPTABLE"
        else:
            return "CRITIQUE"
    
    def _generate_recommendations(self, metrics: Dict[str, Any], issues: List[str]) -> List[str]:
        """G√©n√®re les recommandations bas√©es sur l'analyse."""
        recommendations = []
        
        # Logique de g√©n√©ration de recommandations
        # √Ä adapter selon le type d'agent
        
        return recommendations
    
    def _generate_standard_report(self, context: Dict, metrics: Dict, timestamp) -> Dict[str, Any]:
        """G√©n√®re un rapport selon le format standard de l'agent 06."""
        
        score = self._calculate_report_score(metrics)
        conformity = self._assess_conformity(score)
        quality_level = self._get_quality_level(score)
        
        agent_filename = Path(__file__).name
        
        # Issues critiques (√† personnaliser selon l'agent)
        issues_critiques = []
        
        return {
            'agent_id': getattr(self, 'agent_id', 'unknown'),
            'agent_file_name': agent_filename,
            'type_rapport': 'standard',  # √Ä personnaliser
            'timestamp': timestamp.isoformat(),
            'specialisation': 'Agent Sp√©cialis√©',  # √Ä personnaliser
            'score_global': score,
            'niveau_qualite': quality_level,
            'conformite': conformity,
            'signature_cryptographique': 'N/A (Fonctionnalit√© non impl√©ment√©e pour cet agent)',
            'issues_critiques_identifies': len(issues_critiques),
            'architecture': {
                'description': "Description de l'architecture de l'agent",
                'statut_operationnel': f"Syst√®me {getattr(self, 'agent_id', 'unknown')} op√©rationnel.",
                'confirmation_specialisation': f"{getattr(self, 'agent_id', 'unknown')} confirm√© comme sp√©cialiste.",
                'objectifs_principaux': [
                    "Objectif principal 1",
                    "Objectif principal 2",
                    "Objectif principal 3"
                ],
                'technologies_cles': ["Technologie 1", "Technologie 2"]
            },
            'recommandations': self._generate_recommendations(metrics, issues_critiques),
            'issues_critiques_details': issues_critiques if issues_critiques else [
                "Aucun issue critique majeur d√©tect√©. Le syst√®me fonctionne dans les param√®tres attendus."
            ],
            'details_techniques': {
                'strategie': "Strat√©gie technique de l'agent",
                'composants_actifs': [],
                'metriques_collectees': metrics
            },
            'metriques_detaillees': {
                'score_global': {'actuel': score, 'cible': 100},
                'conformite_pourcentage': {'actuel': score, 'cible': 100, 'unite': '%'}
            },
            'impact_business': {
                'criticite': 'MOYENNE' if score >= 70 else 'HAUTE',
                'domaines_impactes': [],
                'actions_requises': []
            }
        }


    def _generate_markdown_report(self, rapport_json: Dict, context: Dict, timestamp) -> str:
        """G√©n√®re un rapport Markdown selon le format standard."""
        
        agent_name = rapport_json.get('agent_id', 'Agent Inconnu')
        type_rapport = rapport_json.get('type_rapport', 'standard')
        score = rapport_json.get('score_global', 0)
        quality = rapport_json.get('niveau_qualite', 'UNKNOWN')
        conformity = rapport_json.get('conformite', 'NON √âVALU√â')
        
        markdown_content = f"""# üìä RAPPORT STRAT√âGIQUE : {agent_name.upper()}

## üéØ R√âSUM√â EX√âCUTIF

**Agent :** {agent_name}  
**Type de Rapport :** {type_rapport}  
**Date de G√©n√©ration :** {timestamp.strftime('%Y-%m-%d %H:%M:%S')}  
**Score Global :** {score}/100  
**Niveau de Qualit√© :** {quality}  
**Conformit√© :** {conformity}  

## üìà ANALYSE GLOBALE

### Score de Performance
- **Score Actuel :** {score}/100
- **Objectif :** 100/100
- **Statut :** {'üü¢ ACCEPTABLE' if score >= 70 else 'üî¥ CRITIQUE'}

### Architecture
{rapport_json.get('architecture', {}).get('description', 'Description non disponible')}

**Objectifs Principaux :**
"""
        
        # Ajouter les objectifs
        for obj in rapport_json.get('architecture', {}).get('objectifs_principaux', []):
            markdown_content += f"- {obj}\n"
        
        markdown_content += f"""
**Technologies Cl√©s :**
"""
        
        # Ajouter les technologies
        for tech in rapport_json.get('architecture', {}).get('technologies_cles', []):
            markdown_content += f"- {tech}\n"
        
        markdown_content += f"""

## üîç RECOMMANDATIONS

"""
        
        # Ajouter les recommandations
        for reco in rapport_json.get('recommandations', []):
            markdown_content += f"- {reco}\n"
        
        markdown_content += f"""

## ‚ö†Ô∏è ISSUES CRITIQUES

"""
        
        # Ajouter les issues critiques
        for issue in rapport_json.get('issues_critiques_details', []):
            markdown_content += f"- {issue}\n"
        
        markdown_content += f"""

## üìä M√âTRIQUES D√âTAILL√âES

### Performance Globale
- **Score Global :** {rapport_json.get('metriques_detaillees', {}).get('score_global', {}).get('actuel', 0)}/{rapport_json.get('metriques_detaillees', {}).get('score_global', {}).get('cible', 100)}
- **Conformit√© :** {rapport_json.get('metriques_detaillees', {}).get('conformite_pourcentage', {}).get('actuel', 0)}%

## üéØ IMPACT BUSINESS

**Criticit√© :** {rapport_json.get('impact_business', {}).get('criticite', 'NON √âVALU√â')}

### Domaines Impact√©s
"""
        
        # Ajouter les domaines impact√©s
        for domaine in rapport_json.get('impact_business', {}).get('domaines_impactes', []):
            markdown_content += f"- {domaine}\n"
        
        markdown_content += f"""

### Actions Requises
"""
        
        # Ajouter les actions requises
        for action in rapport_json.get('impact_business', {}).get('actions_requises', []):
            markdown_content += f"- {action}\n"
        
        markdown_content += f"""

---
*Rapport g√©n√©r√© automatiquement par {agent_name} - NextGeneration System*  
*Timestamp: {timestamp.isoformat()}*
"""
        
        return markdown_content



if __name__ == "__main__":
    asyncio.run(main())