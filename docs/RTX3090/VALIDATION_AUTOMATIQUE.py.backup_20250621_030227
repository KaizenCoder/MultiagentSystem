#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ü§ñ SCRIPT DE VALIDATION AUTOMATIQUE GPU - NEXTGENERATION
   V√©rifie la compatibilit√© et la performance de l'environnement GPU.
"""

import sys
import logging
import torch

# --- Configuration Logging ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    stream=sys.stdout
)
logger = logging.getLogger("GPU_Validator")

def validate_gpu_environment():
    """
    Ex√©cute une s√©rie de tests pour valider l'environnement GPU.
    """
    logger.info("--- üöÄ D√âMARRAGE DE LA VALIDATION GPU POUR NEXTGENERATION ---")

    # --- Test 1: Disponibilit√© de CUDA ---
    logger.info("--- √âtape 1/4: V√©rification de la disponibilit√© de CUDA ---")
    if torch.cuda.is_available():
        logger.info("‚úÖ SUCC√àS: CUDA est disponible. P√©riph√©rique GPU d√©tect√©.")
    else:
        logger.error("‚ùå √âCHEC: CUDA n'est pas disponible. V√©rifiez l'installation de PyTorch et des drivers NVIDIA.")
        sys.exit(1)

    # --- Test 2: Informations sur le P√©riph√©rique ---
    logger.info("\n--- √âtape 2/4: R√©cup√©ration des informations sur le GPU ---")
    try:
        device_id = torch.cuda.current_device()
        gpu_name = torch.cuda.get_device_name(device_id)
        total_memory_gb = torch.cuda.get_device_properties(device_id).total_memory / (1024**3)
        
        logger.info(f"  - ID du P√©riph√©rique: {device_id}")
        logger.info(f"  - Mod√®le du GPU: {gpu_name}")
        logger.info(f"  - M√©moire Totale: {total_memory_gb:.2f} Go")

        if "RTX 3090" not in gpu_name:
            logger.warning("‚ö†Ô∏è AVERTISSEMENT: Le GPU d√©tect√© n'est pas une RTX 3090, mod√®le de r√©f√©rence du projet.")
        else:
            logger.info("‚úÖ SUCC√àS: GPU de r√©f√©rence (NVIDIA RTX 3090) d√©tect√©.")
            
    except Exception as e:
        logger.error(f"‚ùå √âCHEC: Impossible de r√©cup√©rer les informations du GPU. Erreur: {e}")
        sys.exit(1)

    # --- Test 3: Op√©ration Tensorielle Simple ---
    logger.info("\n--- √âtape 3/4: Test d'une op√©ration tensorielle sur le GPU ---")
    try:
        tensor_cpu = torch.rand(3, 3)
        logger.info("  - Tenseur cr√©√© sur le CPU.")
        
        tensor_gpu = tensor_cpu.to("cuda")
        logger.info("  - Tenseur d√©plac√© vers le GPU.")
        
        result_gpu = tensor_gpu * tensor_gpu + 2
        logger.info("  - Op√©ration (multiplication + addition) ex√©cut√©e sur le GPU.")
        
        result_cpu = result_gpu.to("cpu")
        logger.info("  - R√©sultat rapatri√© sur le CPU.")
        
        logger.info("‚úÖ SUCC√àS: Les op√©rations tensorielles de base sur le GPU fonctionnent.")
    except Exception as e:
        logger.error(f"‚ùå √âCHEC: L'op√©ration tensorielle sur le GPU a √©chou√©. Erreur: {e}")
        sys.exit(1)
        
    # --- Test 4: Disponibilit√© de cuDNN ---
    logger.info("\n--- √âtape 4/4: V√©rification de la disponibilit√© de cuDNN ---")
    if torch.backends.cudnn.is_available():
        logger.info(f"‚úÖ SUCC√àS: cuDNN est disponible (Version: {torch.backends.cudnn.version()}).")
        if not torch.backends.cudnn.enabled:
            logger.warning("‚ö†Ô∏è AVERTISSEMENT: cuDNN est disponible mais n'est pas activ√© par d√©faut.")
    else:
        logger.warning("‚ö†Ô∏è AVERTISSEMENT: cuDNN n'est pas disponible. Les performances pour les r√©seaux de neurones profonds peuvent √™tre r√©duites.")


    logger.info("\n--- ‚úÖ VALIDATION GPU TERMIN√âE AVEC SUCC√àS ---")
    logger.info("Votre environnement semble correctement configur√© pour l'utilisation du GPU avec NextGeneration.")

if __name__ == "__main__":
    validate_gpu_environment() 