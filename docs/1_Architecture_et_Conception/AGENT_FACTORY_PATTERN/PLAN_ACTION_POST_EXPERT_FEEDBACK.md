# üöÄ **PLAN D'ACTION R√âVIS√â - AGENT FACTORY PATTERN**
## **Roadmap Optimis√©e Post-Expert Feedback avec Shift-Left Security**

---

## üìã **SYNTH√àSE EX√âCUTIVE CONSOLID√âE**

### **‚úÖ VALIDATION UNANIME DES 3 EXPERTS**
- **Claude (Anthropic)** : Architecture entreprise + Code production-ready ‚úÖ
- **ChatGPT (OpenAI)** : Plan d'impl√©mentation pragmatique + Timeline concr√®te ‚úÖ  
- **Gemini (Google)** : Innovations avanc√©es + Vision long terme ‚úÖ

### **üéØ OBJECTIF VALID√â ET RAFFIN√â**
- **R√©duction 80%** du temps de cr√©ation d'agents (2-3h ‚Üí 3-5 minutes) ‚úÖ
- **Architecture Orchestration as a Service** valid√©e comme future-ready ‚úÖ
- **S√©curit√© Shift-Left** : Signature crypto d√®s Sprint 2 (non plus Phase 3) ‚úÖ

### **‚ö° OPTIMISATIONS PLAN R√âVIS√â**
- **Gain temps 20%** : Fusion phases redondantes
- **S√©curit√© avanc√©e** : Semaine +1 (vs Semaine +2 initialement)
- **Production-ready** : Semaine +4 avec perf + monitoring complets

---

## üèÉ‚Äç‚ôÇÔ∏è **ROADMAP SPRINT-BASED OPTIMIS√âE**

### **üìÖ SPRINT 0 - KICK-OFF (J+0 ‚Üí J+2)**
*Fusion des anciennes Phase 1 J+0 et J+1 pour gagner 1 jour*

#### **üéØ OBJECTIF**
Code base production-ready op√©rationnelle avec CI/CD

#### **üì¶ LIVRABLES MAJEURS**
- **Merge code Claude** : Adoption versions optimis√©es AgentTemplate + TemplateManager
- **Config Pydantic unifi√©e** : Configuration centralis√©e avec variables environnement
- **CI "smoke" + lint** : GitHub Actions avec mypy --strict + ruff (fail-fast)

#### **üîß ACTIONS D√âTAILL√âES**

**J+0 : Migration Code Base (4h)**
```bash
# Backup + adoption versions Claude
cp orchestrator/app/agents/agent_templates.py orchestrator/app/agents/agent_templates.py.bak
cp enhanced-agent-templates.py orchestrator/app/agents/agent_templates.py
cp optimized-template-manager.py orchestrator/app/agents/template_manager.py
```

**J+1 : Configuration Unifi√©e (3h)**
```python
# orchestrator/app/config/agent_config.py
class AgentFactoryConfig(BaseSettings):
    # Chemins
    templates_dir: Path = Path(__file__).resolve().parent.parent / "agents" / "templates"
    
    # Performance optimis√©e
    cache_ttl: float = 300.0        # 5 min prod, 60s dev (adaptatif)
    max_workers: int = 8            # ThreadPool auto-tuned
    
    # S√©curit√© (pr√©paration Sprint 2)
    enable_signature_validation: bool = True  # Activ√© d√®s Sprint 2
    rsa_public_key_path: str = "keys/template_signing.pub"
    
    class Config:
        env_prefix = "NG_"
```

**J+2 : CI/CD Pipeline (2h)**
```yaml
# .github/workflows/agent-factory-ci.yml
name: Agent Factory CI
on: [push, pull_request]
jobs:
  quality:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: 3.11
      - name: Install dependencies
        run: pip install -r requirements.txt
      - name: Lint with ruff
        run: ruff check . --fix
      - name: Type check with mypy
        run: mypy --strict orchestrator/app/agents/
      - name: Security scan
        run: pip-audit --desc
      - name: Smoke tests
        run: pytest tests/test_smoke.py -v
```

#### **‚úÖ DEFINITION OF DONE SPRINT 0**
- ‚úÖ Code Claude int√©gr√© et fonctionnel
- ‚úÖ Configuration Pydantic centralis√©e
- ‚úÖ CI pipeline op√©rationnelle (lint + type check + smoke tests)
- ‚úÖ 0 vuln√©rabilit√© critical/high (pip-audit)

---

### **üìÖ SPRINT 1 - TESTS & OBSERVABILIT√â DE BASE (J+3 ‚Üí J+6)**

#### **üéØ OBJECTIF**
Validation robustesse et performance avec monitoring basique

#### **üì¶ LIVRABLES MAJEURS**
- **Tests complets** : H√©ritage, hot-reload, performance
- **Endpoint m√©triques** : /factory/metrics + /health
- **Benchmark Locust** : Validation < 100ms/agent en CI

#### **üß™ TESTS SP√âCIFIQUES**

**J+3-4 : Tests Fonctionnels (6h)**
```python
# tests/test_template_inheritance.py - H√©ritage templates
# tests/test_hot_reload.py - Rechargement automatique
# tests/test_scalability_load.py - Performance parall√®le

# Nouveau : Benchmark Locust int√©gr√© CI
# tests/locust_benchmark.py
from locust import HttpUser, task, between

class AgentFactoryUser(HttpUser):
    wait_time = between(0.1, 0.5)
    
    @task
    def create_agent(self):
        response = self.client.post("/factory/agents", 
                                  json={"template_name": "documentaliste"})
        assert response.status_code == 200
        # Validation < 100ms
        assert response.elapsed.total_seconds() < 0.1
```

**J+5-6 : API M√©triques (4h)**
```python
# orchestrator/app/main.py - Endpoints monitoring
@app.get("/factory/metrics")
def get_factory_metrics():
    return {
        "templates_loaded": template_manager.get_metrics()["templates_loaded"],
        "cache_hit_rate": template_manager.get_metrics()["cache_hit_rate"],
        "creation_time_p95": template_manager.get_metrics()["creation_time_p95"],
        "active_agents": len(template_manager.active_agents)
    }

@app.get("/health")
def health_check():
    stats = agent_factory.get_factory_stats()
    return {
        "status": "healthy" if stats["templates_loaded"] > 0 else "degraded",
        "version": "1.0.0-sprint1",
        "uptime_seconds": time.time() - start_time
    }
```

#### **‚úÖ DEFINITION OF DONE SPRINT 1**
- ‚úÖ Tests h√©ritage + hot-reload + performance verts
- ‚úÖ Benchmark Locust < 100ms/agent valid√© en CI
- ‚úÖ API m√©triques expos√©e et document√©e
- ‚úÖ p95 performance respect√©

---

### **üìÖ SPRINT 2 - S√âCURIT√â "SHIFT-LEFT" (Semaine +1)**
*Avancement majeur : S√©curit√© cryptographique d√®s maintenant (non plus Sprint 3)*

#### **üéØ OBJECTIF**
S√©curit√© entreprise op√©rationnelle avant staging

#### **üì¶ LIVRABLES MAJEURS**
- **Signature RSA 2048 + SHA-256** : Validation obligatoire au load des templates
- **Policy OPA basique** : Blacklist tools dangereux
- **Rotation cl√©s** : Int√©gration Vault + alertes Prometheus

#### **üîê S√âCURIT√â CRYPTOGRAPHIQUE**

```python
# orchestrator/app/security/crypto_validator.py
from cryptography.hazmat.primitives import hashes, serialization
from cryptography.hazmat.primitives.asymmetric import rsa, padding
import json
import hashlib
import logging

logger = logging.getLogger(__name__)

class ProductionSecurityValidator:
    """Validation cryptographique production (RSA 2048 + SHA-256)"""
    
    def __init__(self, public_key_path: str):
        try:
            with open(public_key_path, "rb") as f:
                self.public_key = serialization.load_pem_public_key(f.read())
            logger.info(f"Cl√© publique charg√©e: {public_key_path}")
        except Exception as e:
            logger.error(f"√âchec chargement cl√©: {e}")
            raise
            
    def verify_template_signature(self, template_data: Dict, signature_b64: str) -> bool:
        """V√©rification signature template (obligatoire)"""
        try:
            # D√©codage signature base64
            signature = base64.b64decode(signature_b64)
            
            # Hash canonique du template
            template_content = json.dumps(template_data, sort_keys=True, separators=(',', ':'))
            template_hash = hashlib.sha256(template_content.encode('utf-8')).digest()
            
            # V√©rification RSA-PSS
            self.public_key.verify(
                signature,
                template_hash,
                padding.PSS(
                    mgf=padding.MGF1(hashes.SHA256()),
                    salt_length=padding.PSS.MAX_LENGTH
                ),
                hashes.SHA256()
            )
            
            logger.debug(f"Signature valide pour template {template_data.get('name')}")
            return True
            
        except Exception as e:
            logger.error(f"Signature invalide: {e}")
            return False
            
    def validate_policy_opa(self, template_data: Dict) -> bool:
        """Validation politique OPA basique"""
        dangerous_tools = [
            "shell_command", "file_system_write", "network_access", 
            "subprocess", "eval", "exec"
        ]
        
        tools = template_data.get("tools", [])
        blocked_tools = [tool for tool in tools if tool in dangerous_tools]
        
        if blocked_tools:
            logger.warning(f"Tools bloqu√©s par politique: {blocked_tools}")
            return False
            
        return True
```

#### **üîÑ ROTATION CL√âS & MONITORING**

```python
# orchestrator/app/security/key_rotation.py
import hvac  # HashiCorp Vault
from prometheus_client import Counter

SIGNATURE_FAILURES = Counter('template_signature_failures_total', 
                            'Template signature validation failures')

class KeyRotationManager:
    """Gestion rotation cl√©s via Vault"""
    
    def __init__(self, vault_url: str, vault_token: str):
        self.vault_client = hvac.Client(url=vault_url, token=vault_token)
        
    def get_current_public_key(self) -> str:
        """R√©cup√©ration cl√© publique courante depuis Vault"""
        response = self.vault_client.secrets.kv.v2.read_secret_version(
            path='agent-factory/signing-keys'
        )
        return response['data']['data']['public_key']
        
    def rotate_keys_if_needed(self) -> bool:
        """Rotation automatique si n√©cessaire"""
        # Logique rotation bas√©e sur √¢ge cl√© + m√©triques √©checs
        failure_rate = SIGNATURE_FAILURES._value.get()
        if failure_rate > 10:  # Seuil alerte
            logger.warning("Taux √©chec signature √©lev√© - rotation recommand√©e")
            return True
        return False
```

#### **‚úÖ DEFINITION OF DONE SPRINT 2**
- ‚úÖ Signature RSA obligatoire et fonctionnelle
- ‚úÖ Policy OPA bloque tools dangereux
- ‚úÖ Int√©gration Vault pour rotation cl√©s
- ‚úÖ M√©triques s√©curit√© expos√©es Prometheus
- ‚úÖ 0 vuln√©rabilit√© critical/high Trivy

---

### **üìÖ SPRINT 3 - CONTROL/DATA PLANE & SANDBOX (Semaine +2)**

#### **üéØ OBJECTIF**
Architecture s√©par√©e + Sandbox pour agents √† risque

#### **üì¶ LIVRABLES MAJEURS**
- **Refactor Control/Data Plane** : S√©paration gouvernance/ex√©cution
- **WASI sandbox prototype** : Isolation agents risqu√©s
- **RBAC minimale FastAPI** : Authentification/autorisation

#### **üèóÔ∏è ARCHITECTURE S√âPAR√âE**

```python
# orchestrator/app/planes/control_plane.py
class ControlPlane:
    """Plan contr√¥le - Gouvernance et politiques"""
    
    def __init__(self):
        self.security_validator = ProductionSecurityValidator("keys/template_signing.pub")
        self.policy_engine = OPAPolicyEngine()
        self.audit_logger = AuditLogger()
        
    async def authorize_agent_creation(self, 
                                     template_name: str, 
                                     user_context: Dict) -> AuthResult:
        """Autorisation cr√©ation agent avec audit"""
        
        # 1. Validation utilisateur
        if not self._validate_user_permissions(user_context):
            self.audit_logger.log_access_denied(user_context, template_name)
            raise PermissionError("Permissions insuffisantes")
            
        # 2. Validation template s√©curis√©
        template = await template_manager.get_template_async(template_name)
        if not self.security_validator.verify_template_signature(
            template.data, template.signature
        ):
            self.audit_logger.log_security_violation(template_name, "signature_invalid")
            raise SecurityError("Signature template invalide")
            
        # 3. Validation politique
        if not self.security_validator.validate_policy_opa(template.data):
            self.audit_logger.log_policy_violation(template_name, template.data.get("tools"))
            raise PolicyError("Violation politique s√©curit√©")
            
        return AuthResult(authorized=True, sandbox_required=self._requires_sandbox(template))

# orchestrator/app/planes/data_plane.py
class DataPlane:
    """Plan donn√©es - Ex√©cution isol√©e"""
    
    def __init__(self):
        self.wasi_sandbox = WASISandbox()
        self.native_executor = NativeExecutor()
        
    async def execute_agent_creation(self, 
                                   template_name: str, 
                                   auth_result: AuthResult) -> Agent:
        """Ex√©cution cr√©ation avec isolation appropri√©e"""
        
        if auth_result.sandbox_required:
            # Ex√©cution sandbox√©e WASI
            return await self.wasi_sandbox.create_agent_safely(template_name)
        else:
            # Ex√©cution native optimis√©e
            return await self.native_executor.create_agent(template_name)
```

#### **üîê SANDBOX WASI PROTOTYPE**

```python
# orchestrator/app/sandbox/wasi_sandbox.py
import wasmtime
from typing import Dict, Any

class WASISandbox:
    """Sandbox WASI pour agents √† risque"""
    
    def __init__(self):
        self.engine = wasmtime.Engine()
        self.overhead_threshold = 0.2  # 20% overhead max
        
    async def create_agent_safely(self, template_name: str) -> Agent:
        """Cr√©ation agent en environnement isol√©"""
        
        start_time = time.time()
        
        # Configuration WASI avec restrictions
        wasi_config = wasmtime.WasiConfig()
        wasi_config.inherit_stdout()
        wasi_config.inherit_stderr()
        # Pas d'acc√®s filesystem par d√©faut
        
        store = wasmtime.Store(self.engine)
        store.set_wasi(wasi_config)
        
        try:
            # Chargement module WASM agent
            module = wasmtime.Module(self.engine, self._compile_agent_to_wasm(template_name))
            instance = wasmtime.Instance(store, module, [])
            
            # Ex√©cution contr√¥l√©e
            agent = self._execute_agent_creation(store, instance, template_name)
            
            # V√©rification overhead
            execution_time = time.time() - start_time
            native_time = await self._benchmark_native_creation(template_name)
            overhead = (execution_time - native_time) / native_time
            
            if overhead > self.overhead_threshold:
                logger.warning(f"Sandbox overhead {overhead:.1%} > {self.overhead_threshold:.1%}")
                
            return agent
            
        except Exception as e:
            logger.error(f"√âchec sandbox WASI: {e}")
            raise SandboxError(f"Isolation failed: {e}")
```

#### **‚úÖ DEFINITION OF DONE SPRINT 3**
- ‚úÖ Control/Data Plane s√©par√©s et op√©rationnels
- ‚úÖ Sandbox WASI fonctionnel avec overhead < 20%
- ‚úÖ RBAC FastAPI int√©gr√©
- ‚úÖ Audit trail complet
- ‚úÖ Tests int√©gration Control ‚Üî Data Plane

---

### **üìÖ SPRINT 4 - OBSERVABILIT√â AVANC√âE & PERF (Semaine +3)**

#### **üéØ OBJECTIF**
Monitoring production-grade + Optimisations performance

#### **üì¶ LIVRABLES MAJEURS**
- **Tracing OpenTelemetry** : Traces distribu√©es compl√®tes
- **Prometheus counters** : TTL, cache hits, p95
- **ThreadPool auto-tuned** : CPU √ó 2 avec adaptation charge
- **Compression .json.zst** : R√©duction m√©moire 5-10√ó

#### **üìä OBSERVABILIT√â OPENTELEMETRY**

```python
# orchestrator/app/monitoring/tracing.py
from opentelemetry import trace
from opentelemetry.exporter.jaeger.thrift import JaegerExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor

# Configuration tracing
trace.set_tracer_provider(TracerProvider())
tracer = trace.get_tracer(__name__)

jaeger_exporter = JaegerExporter(
    agent_host_name="localhost",
    agent_port=6831,
)
span_processor = BatchSpanProcessor(jaeger_exporter)
trace.get_tracer_provider().add_span_processor(span_processor)

# Instrumentation Agent Factory
class TracedAgentFactory(AgentFactory):
    
    @tracer.start_as_current_span("agent_creation")
    async def create_agent(self, template_name: str, **kwargs):
        span = trace.get_current_span()
        span.set_attribute("template.name", template_name)
        span.set_attribute("template.version", await self._get_template_version(template_name))
        
        start_time = time.time()
        try:
            agent = await super().create_agent(template_name, **kwargs)
            span.set_attribute("creation.success", True)
            return agent
        except Exception as e:
            span.set_attribute("creation.success", False)
            span.set_attribute("error.message", str(e))
            raise
        finally:
            creation_time = time.time() - start_time
            span.set_attribute("creation.duration_ms", creation_time * 1000)
            AGENT_CREATION_TIME.observe(creation_time)
```

#### **‚ö° OPTIMISATIONS PERFORMANCE**

```python
# orchestrator/app/optimization/adaptive_threading.py
import psutil
from concurrent.futures import ThreadPoolExecutor
from threading import Lock

class AdaptiveThreadPool:
    """ThreadPool auto-adaptatif selon charge CPU"""
    
    def __init__(self):
        self.base_workers = psutil.cpu_count() * 2
        self.current_workers = self.base_workers
        self.executor = ThreadPoolExecutor(max_workers=self.current_workers)
        self.adjustment_lock = Lock()
        
    def adapt_to_load(self):
        """Adaptation dynamique selon charge syst√®me"""
        cpu_percent = psutil.cpu_percent(interval=1)
        memory_percent = psutil.virtual_memory().percent
        
        with self.adjustment_lock:
            if cpu_percent > 80 and self.current_workers > self.base_workers // 2:
                # R√©duction charge CPU √©lev√©e
                self.current_workers = max(self.current_workers - 2, self.base_workers // 2)
                self._resize_executor()
            elif cpu_percent < 50 and memory_percent < 70:
                # Augmentation si ressources disponibles
                self.current_workers = min(self.current_workers + 1, self.base_workers * 2)
                self._resize_executor()
                
    def _resize_executor(self):
        """Redimensionnement ThreadPool"""
        old_executor = self.executor
        self.executor = ThreadPoolExecutor(max_workers=self.current_workers)
        old_executor.shutdown(wait=False)
        logger.info(f"ThreadPool redimensionn√©: {self.current_workers} workers")

# orchestrator/app/optimization/compression.py
import zstandard as zstd
import json

class TemplateCompression:
    """Compression templates JSON avec Zstandard"""
    
    def __init__(self):
        self.compressor = zstd.ZstdCompressor(level=3)
        self.decompressor = zstd.ZstdDecompressor()
        
    def compress_template(self, template_data: Dict) -> bytes:
        """Compression template JSON"""
        json_bytes = json.dumps(template_data, separators=(',', ':')).encode('utf-8')
        compressed = self.compressor.compress(json_bytes)
        
        compression_ratio = len(compressed) / len(json_bytes)
        logger.debug(f"Compression ratio: {compression_ratio:.2%}")
        
        return compressed
        
    def decompress_template(self, compressed_data: bytes) -> Dict:
        """D√©compression template"""
        json_bytes = self.decompressor.decompress(compressed_data)
        return json.loads(json_bytes.decode('utf-8'))
```

#### **‚úÖ DEFINITION OF DONE SPRINT 4**
- ‚úÖ Tracing OpenTelemetry op√©rationnel
- ‚úÖ M√©triques Prometheus compl√®tes (p95, cache, TTL)
- ‚úÖ ThreadPool adaptatif selon charge
- ‚úÖ Compression templates active (gain m√©moire mesur√©)
- ‚úÖ Performance < 50ms/agent valid√©e

---

### **üìÖ SPRINT 5 - RELEASE CANDIDATE (Semaine +4)**

#### **üéØ OBJECTIF**
D√©ploiement production avec validation chaos engineering

#### **üì¶ LIVRABLES MAJEURS**
- **K8s blue-green deploy** : Helm chart production-ready
- **Chaos test** : 25% nodes off + validation r√©silience
- **Doc "Operator runbook"** : Proc√©dures op√©rationnelles

#### **üöÄ D√âPLOIEMENT KUBERNETES**

```yaml
# helm/agent-factory/values.yaml
replicaCount: 3

image:
  repository: nextgeneration/agent-factory
  tag: "1.0.0-rc1"
  pullPolicy: IfNotPresent

service:
  type: ClusterIP
  port: 8000

ingress:
  enabled: true
  annotations:
    kubernetes.io/ingress.class: nginx
    cert-manager.io/cluster-issuer: letsencrypt-prod
  hosts:
    - host: agent-factory.nextgen.local
      paths:
        - path: /
          pathType: Prefix

resources:
  limits:
    cpu: 2000m
    memory: 4Gi
  requests:
    cpu: 1000m
    memory: 2Gi

autoscaling:
  enabled: true
  minReplicas: 3
  maxReplicas: 10
  targetCPUUtilizationPercentage: 70

monitoring:
  serviceMonitor:
    enabled: true
    interval: 30s
    path: /metrics
```

#### **üí• CHAOS ENGINEERING**

```python
# tests/chaos/chaos_test.py
import pytest
import kubernetes
import time
import requests

class ChaosTestSuite:
    """Tests r√©silience avec Chaos Engineering"""
    
    def __init__(self):
        self.k8s_client = kubernetes.client.ApiClient()
        self.base_url = "http://agent-factory.nextgen.local"
        
    @pytest.mark.chaos
    def test_node_failure_resilience(self):
        """Test r√©silience avec 25% nodes arr√™t√©s"""
        
        # 1. Baseline performance
        baseline_latency = self._measure_average_latency()
        
        # 2. Arr√™t 25% des nodes
        nodes_to_stop = self._get_worker_nodes()[:len(self._get_worker_nodes()) // 4]
        
        for node in nodes_to_stop:
            self._cordon_and_drain_node(node)
            
        time.sleep(30)  # Stabilisation
        
        # 3. Validation service toujours op√©rationnel
        chaos_latency = self._measure_average_latency()
        
        # 4. Assertions
        assert chaos_latency < baseline_latency * 2  # D√©gradation < 100%
        assert self._check_service_health()
        
        # 5. Restauration
        for node in nodes_to_stop:
            self._uncordon_node(node)
            
    def _measure_average_latency(self, samples=100) -> float:
        """Mesure latence moyenne cr√©ation agents"""
        latencies = []
        
        for _ in range(samples):
            start = time.time()
            response = requests.post(f"{self.base_url}/factory/agents",
                                   json={"template_name": "documentaliste"})
            latency = time.time() - start
            
            assert response.status_code == 200
            latencies.append(latency)
            
        return sum(latencies) / len(latencies)
```

#### **üìö OPERATOR RUNBOOK**

```markdown
# Agent Factory - Operator Runbook

## üö® Alertes Critiques

### Template Signature Failures > 10/min
**Sympt√¥me**: M√©triques `template_signature_failures_total` √©lev√©es
**Action**: 
1. V√©rifier rotation cl√©s Vault
2. Analyser logs s√©curit√©
3. D√©clencher rotation manuelle si n√©cessaire

### Cache Hit Rate < 80%
**Sympt√¥me**: Performance d√©grad√©e, latence √©lev√©e
**Action**:
1. V√©rifier TTL configuration
2. Analyser patterns d'acc√®s templates
3. Ajuster cache_ttl si n√©cessaire

### Pod Memory > 90%
**Sympt√¥me**: Risque OOMKilled
**Action**:
1. V√©rifier compression templates active
2. Analyser fuites m√©moire potentielles
3. Scale horizontal si n√©cessaire

## üîß Proc√©dures Maintenance

### Rotation Cl√©s Signature
```bash
# 1. G√©n√©ration nouvelle paire
openssl genrsa -out private_new.pem 2048
openssl rsa -in private_new.pem -pubout -out public_new.pem

# 2. Upload Vault
vault kv put agent-factory/signing-keys public_key=@public_new.pem

# 3. Rolling restart
kubectl rollout restart deployment/agent-factory
```

### Mise √† jour Templates
```bash
# 1. Signature nouveau template
python scripts/sign_template.py new_template.json

# 2. D√©ploiement
kubectl create configmap agent-templates --from-file=templates/ --dry-run=client -o yaml | kubectl apply -f -

# 3. Hot-reload automatique (watchdog)
```
```

#### **‚úÖ DEFINITION OF DONE SPRINT 5**
- ‚úÖ D√©ploiement K8s blue-green fonctionnel
- ‚úÖ Chaos test 25% nodes passant
- ‚úÖ Runbook op√©rateur complet
- ‚úÖ Monitoring production op√©rationnel
- ‚úÖ SLA < 100ms p95 respect√© en production

---

## üéØ **BACKLOG NEXT QUARTER**
*Innovations futures hors p√©rim√®tre MVP*

### **üìà ROADMAP LONG TERME**
- **Agent Marketplace** : √âcosyst√®me partage agents (Claude)
- **Interface NLP** : Cr√©ation agents langage naturel
- **GNN Recommender** : Recommandations agents intelligentes
- **Multi-modal Agents** : Support images/audio/documents (Gemini)

---

## üîë **T√ÇCHES TRANSVERSES**

### **üìä QUALIT√â DE CODE**
- **mypy --strict** : Fail-fast d√®s Sprint 0
- **ruff** : Linting automatique
- **Coverage** : > 90% tests unitaires + int√©gration

### **üîí SUPPLY CHAIN SECURITY**
- **pip-audit** : Scan vuln√©rabilit√©s int√©gr√© CI
- **Trivy** : Scan containers + d√©pendances
- **SBOM** : Software Bill of Materials g√©n√©r√©

### **‚ö†Ô∏è RISQUES & MITIGATIONS**

| Risque | Mitigation | Sprint |
|--------|------------|---------|
| Hot-reload CPU intensif | TTL adaptatif + debounce watchdog | 1 |
| Cl√© RSA compromise | Rotation Vault + alertes Prometheus | 2 |
| Sandbox overhead > 20% | Benchmark WASI vs Native, activation conditionnelle | 3 |
| Latence production > SLA | Auto-scaling + ThreadPool adaptatif | 4 |

---

## üìâ **√âCONOMIE TEMPS OBTENUE**

| √âtape | Plan Original | Plan R√©vis√© | Gain |
|-------|---------------|-------------|------|
| **Bases fusionn√©es** | 2 jours | 1 jour | -50% |
| **S√©curit√© disponible** | Semaine +2 | Semaine +1 | -1 semaine |
| **Production ready** | Semaine +2 post-Phase 4 | Semaine +4 (complet) | +monitoring |

**Gain net : ~20% d√©lai global sans supprimer aucune exigence business**

---

## üö¶ **PROCHAINES ACTIONS IMM√âDIATES**

### **‚úÖ VALIDATION JALONNEMENT**
- Daily team 15min pour validation nouveau planning
- Cr√©ation branche `roadmap/v2-optimized`
- Issue Sprint 0 avec checklist d√©taill√©e

### **üöÄ SPRINT 0 KICKOFF**
**Checklist Sprint 0 :**
- [ ] Merge code Claude (AgentTemplate + TemplateManager)
- [ ] Config Pydantic unifi√©e
- [ ] CI smoke tests + lint (GitHub Actions)
- [ ] Validation imports + tests basiques
- [ ] Documentation Sprint 1 pr√©par√©e

**Une fois Sprint 0 termin√© (J+2) :**
- Revue pipeline CI + rapport Locust
- Validation m√©triques baseline
- Lancement Sprint 1

---

**üéØ Plan d'action r√©vis√© int√©grant shift-left security, optimisations temporelles et suppression des redondances pour livraison production-ready Semaine +4** 