#  wiki:
# üéØ Wiki du projet : Utilisation et Standards de la RTX 3090

**Avertissement :** Ce document contient des informations techniques sensibles et des standards de configuration stricts. Le respect de ces directives est **obligatoire** pour garantir la performance, la stabilit√© et la s√©curit√© de l'infrastructure GPU du projet NextGeneration.

## 1. üöÄ Synth√®se Ex√©cutive et Mission

La mission principale de ce sous-projet √©tait d'int√©grer et d'optimiser une carte graphique **NVIDIA RTX 3090 (24 Go)** comme unique acc√©l√©rateur pour les t√¢ches d'intelligence artificielle, en garantissant un environnement de production stable, performant et s√©curis√©.

**Statut du Projet : Mission Accomplie - Production Ready**
- **Validation** : Le syst√®me a √©t√© enti√®rement valid√© par un essaim d'agents autonomes, avec un score de 100%.
- **Performance** : Des performances de **4.9 √† 8.2 tokens/seconde** ont √©t√© atteintes sur les mod√®les locaux, en fonction de leur complexit√©.
- **Optimisation** : **33 Go** d'espace de stockage ont √©t√© lib√©r√©s gr√¢ce √† la rationalisation des mod√®les.
- **S√©curit√©** : Le traitement 100% local des donn√©es garantit une confidentialit√© maximale.

## 2. üö® Standards Stricts de Configuration (R√®gles Non N√©gociables)

Ces r√®gles ont √©t√© √©tablies pour √©liminer les probl√®mes de compatibilit√© et de performance li√©s √† une configuration multi-GPU h√©t√©rog√®ne (RTX 3090 + RTX 5060 Ti). **Aucune exception n'est autoris√©e.**

### R√®gle #1 : GPU Exclusif
- **GPU AUTORIS√â** : **NVIDIA RTX 3090 (24 Go)**, physiquement install√©e sur le **Bus PCI 1**.
- **GPU INTERDIT** : Toute autre carte, et en particulier la RTX 5060 Ti, ne doit pas √™tre utilis√©e pour les calculs d'IA.

### R√®gle #2 : Configuration d'Environnement Obligatoire
Chaque script Python utilisant le GPU **doit imp√©rativement** inclure la configuration d'environnement suivante au tout d√©but du fichier, avant m√™me les imports de biblioth√®ques comme PyTorch ou TensorFlow.

```python
import os

# CONFIGURATION CRITIQUE GPU - RTX 3090 UNIQUEMENT
# Cette configuration assure que seul le bon GPU est visible et utilis√© par CUDA.
os.environ['CUDA_VISIBLE_DEVICES'] = '1'        # Cible la RTX 3090 sur le bus PCI 1.
os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'  # Assure que l'ID est bas√© sur le bus physique.
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:1024'  # Optimisation de la fragmentation m√©moire.
```

### R√®gle #3 : Validation Syst√©matique dans le Code
Chaque script doit inclure et appeler une fonction de validation pour s'assurer que l'environnement est correctement configur√© avant d'ex√©cuter le moindre calcul.

```python
import torch

def validate_rtx3090_mandatory():
    """Valide que l'environnement respecte les standards stricts pour la RTX 3090."""
    if not torch.cuda.is_available():
        raise RuntimeError("ERREUR CRITIQUE: CUDA n'est pas disponible.")
    
    if os.environ.get('CUDA_VISIBLE_DEVICES') != '1':
        raise RuntimeError("ERREUR DE CONFIGURATION: CUDA_VISIBLE_DEVICES doit √™tre '1'.")
        
    gpu_name = torch.cuda.get_device_name(0) # Doit √™tre 0 car CUDA_VISIBLE_DEVICES mappe le device '1' √† l'index '0'
    if "RTX 3090" not in gpu_name:
        raise RuntimeError(f"ERREUR CRITIQUE: Le GPU d√©tect√© est '{gpu_name}'. Seule la RTX 3090 est autoris√©e.")
    
    print("‚úÖ Configuration GPU RTX 3090 valid√©e avec succ√®s.")

# Appeler cette fonction au d√©but de l'ex√©cution principale.
validate_rtx3090_mandatory()
```

## 3. üèóÔ∏è Architecture Technique D√©taill√©e

### Stack Logicielle de R√©f√©rence
- **Driver NVIDIA**: `550.xx` ou sup√©rieur
- **CUDA Toolkit**: `12.1` ou sup√©rieur
- **PyTorch**: `2.1.0` ou sup√©rieur (compil√© pour CUDA 12.1)
- **Ollama**: Service de mod√®les de langage, configur√© pour utiliser exclusivement la RTX 3090.

### Configuration du service Ollama
Ollama est configur√© via des variables d'environnement pour s'ex√©cuter **uniquement** sur la RTX 3090. Un script `.bat` est disponible pour lancer le service avec la bonne configuration.
- **Variables Cl√©s**:
  - `CUDA_VISIBLE_DEVICES="1"`
  - `OLLAMA_GPU_DEVICE="1"`
  - `OLLAMA_NUM_GPU="1"`
- **Lancement**: Utiliser le script `start_ollama_rtx3090.bat` pour un d√©marrage conforme.

### Orchestrateur et Worker (`OllamaLocalWorker`)
L'orchestrateur du projet utilise un `worker` sp√©cialis√©, `OllamaLocalWorker`, qui est au c≈ìur de l'intelligence du syst√®me.
- **R√¥le**: Recevoir des t√¢ches et s√©lectionner le mod√®le local le plus appropri√© pour les traiter.
- **S√©lection Intelligente**: Le worker analyse les mots-cl√©s de la t√¢che (ex: "code", "rapide", "analyse complexe") pour choisir dynamiquement parmi les 4 mod√®les optimis√©s.

## 4. üöÄ Guides d'Impl√©mentation et d'Utilisation

### Configuration Initiale de l'Environnement
1.  **Optimisation Windows**: R√©glez le plan d'alimentation sur "Performances √©lev√©es" et activez la "Planification de processeur graphique √† acc√©l√©ration mat√©rielle".
2.  **Panneau NVIDIA**: R√©glez le mode de gestion de l'alimentation sur "Privil√©gier les performances maximales".
3.  **Lancement Ollama**: Ex√©cutez le script `start_ollama_rtx3090.bat` pour d√©marrer le service de mod√®les sur le bon GPU.
4.  **Monitoring**: Lancez `start_monitor_rtx3090.bat` pour avoir une vue en temps r√©el de l'√©tat du GPU (VRAM, temp√©rature, utilisation).

### Template de D√©veloppement
Tous les nouveaux scripts doivent √™tre bas√©s sur le template `TEMPLATE DE CODE OBLIGATOIRE V2.0` d√©fini dans `standards_gpu_rtx3090_definitifs.md`.

## 5. ‚úÖ Validation et Rapports de Performance

Le syst√®me a √©t√© valid√© √† l'aide de scripts et d'agents autonomes.
- **Script de validation des standards**: `VALIDATION_STANDARDS_RTX3090.py`
- **Rapport final d'int√©gration**: `RAPPORT_FINAL_INTEGRATION_ORCHESTRATEUR_RTX3090.md`
- **Rapport de validation d'Ollama**: `RAPPORT_FINAL_VALIDATION_OLLAMA_RTX3090.md`

Ces documents attestent que la configuration est stable, performante et conforme aux standards.

## 6. üß† Gestion des Mod√®les (Optimisation & Recommandations)

### Mod√®les Optimis√©s et Valid√©s
La configuration de production repose sur 4 mod√®les principaux, chacun ayant un r√¥le sp√©cifique :

| Mod√®le | Performance | Usage Optimal | Nom du mod√®le Ollama |
| :--- | :--- | :--- | :--- |
| **Qwen-Coder** | 8.2 tok/s | G√©n√©ration de code, debugging | `qwen2.5-coder:1.5b` |
| **Nous-Hermes** | 6.4 tok/s | R√©ponses rapides, t√¢ches simples | `nous-hermes-2-mistral-7b-dpo`|
| **Llama3-Q6K** | 4.9 tok/s | Usage g√©n√©ral, √©quilibr√© | `llama3:8b-instruct-q6_k` |
| **Mixtral-Q3K**| 5.4 tok/s | Analyses complexes, haute qualit√© | `mixtral:8x7b-instruct-v0.1-q3_k_m` |

### Optimisation de la M√©moire
- Le mod√®le `Mixtral-8x7b` (26 Go) a √©t√© identifi√© comme √©tant trop volumineux pour la VRAM de la RTX 3090 (24 Go).
- **Solution**: Il a √©t√© remplac√© par une version quantiz√©e, `mixtral:8x7b-instruct-v0.1-q3_k_m`, qui offre une qualit√© similaire pour une empreinte m√©moire bien plus faible.
- **Action continue**: Il est recommand√© de supprimer les mod√®les redondants ou non optimis√©s pour lib√©rer de l'espace disque. 