# üìö DOCUMENTATION API COMPL√àTE - LOGGING NEXTGENERATION

## üéØ Vue d'Ensemble

Le syst√®me de logging NextGeneration offre une API unifi√©e et puissante pour la gestion centralis√©e des logs. Cette documentation pr√©sente toutes les APIs publiques, leurs param√®tres, exemples d'utilisation et bonnes pratiques.

## üöÄ APIs Principales

### üîß LoggingManager - Gestionnaire Principal

Le `LoggingManager` est le point d'entr√©e principal du syst√®me (pattern Singleton).

#### Initialisation

```python
from logging_manager_optimized import LoggingManager

# Obtenir l'instance unique
manager = LoggingManager()

# Le manager se configure automatiquement au premier acc√®s
```

#### `get_logger(config_name, custom_config)` - API Principale

**Description** : Obtient un logger configur√© selon les sp√©cifications.

**Param√®tres** :
- `config_name` (str, optionnel) : Nom de configuration pr√©d√©finie
- `custom_config` (dict, optionnel) : Configuration personnalis√©e

**Retour** : `logging.Logger` configur√©

```python
# Logger simple
logger = manager.get_logger()

# Logger avec configuration personnalis√©e
config = {
    "logger_name": "nextgen.api",
    "log_level": "DEBUG",
    "console_enabled": True,
    "file_enabled": True,
    "elasticsearch_enabled": True,
    "encryption_enabled": True
}
logger = manager.get_logger(custom_config=config)

# Logger avec configuration pr√©d√©finie
logger = manager.get_logger(config_name="agent_default")
```

#### `get_agent_logger(agent_name, role, domain, agent_id, async_enabled)` - API Agents

**Description** : Cr√©e un logger sp√©cialis√© pour les agents avec m√©tadonn√©es enrichies.

**Param√®tres** :
- `agent_name` (str) : Nom de l'agent
- `role` (str) : R√¥le de l'agent
- `domain` (str) : Domaine d'expertise
- `agent_id` (str, optionnel) : Identifiant unique
- `async_enabled` (bool, d√©faut: False) : Mode asynchrone

**Retour** : `logging.Logger` sp√©cialis√© agent

```python
# Logger agent simple
agent_logger = manager.get_agent_logger(
    agent_name="coordinateur_principal",
    role="coordination",
    domain="factory_pattern"
)

# Logger agent avec ID et mode async
agent_logger = manager.get_agent_logger(
    agent_name="analyseur_code",
    role="analysis",
    domain="refactoring",
    agent_id="agent_001",
    async_enabled=True
)

# Utilisation
agent_logger.info("D√©marrage de l'analyse", extra={
    "operation": "code_analysis",
    "target": "logging_manager.py"
})
```

#### `create_audit_logger(user_id, action_type)` - API Audit

**Description** : Cr√©e un logger d'audit avec tra√ßabilit√© utilisateur.

**Param√®tres** :
- `user_id` (str) : Identifiant utilisateur
- `action_type` (str) : Type d'action audit√©e

**Retour** : `logging.Logger` avec adapter d'audit

```python
# Logger d'audit
audit_logger = manager.create_audit_logger(
    user_id="admin_001",
    action_type="configuration_change"
)

# Utilisation automatique des m√©tadonn√©es d'audit
audit_logger.warning("Modification configuration s√©curit√©", extra={
    "config_section": "encryption",
    "old_value": "disabled",
    "new_value": "enabled"
})
```

#### `get_performance_logger()` - API Performance

**Description** : Obtient un logger sp√©cialis√© pour les m√©triques de performance.

**Retour** : `logging.Logger` optimis√© performance

```python
# Logger performance
perf_logger = manager.get_performance_logger()

# Logging de m√©triques
perf_logger.info("Performance mesur√©e", extra={
    "operation": "elasticsearch_batch",
    "duration_ms": 45.2,
    "records_processed": 1000,
    "throughput_rps": 22123
})
```

### üìä Context Manager Performance

#### `log_performance(operation_name, logger)` - Mesure Automatique

**Description** : Context manager pour mesurer automatiquement les performances.

**Param√®tres** :
- `operation_name` (str) : Nom de l'op√©ration
- `logger` (logging.Logger, optionnel) : Logger √† utiliser

```python
# Mesure automatique avec logger par d√©faut
with manager.log_performance("database_query"):
    result = execute_complex_query()

# Mesure avec logger personnalis√©
with manager.log_performance("file_processing", custom_logger):
    process_large_file("data.csv")

# Mesure avec m√©tadonn√©es additionnelles
with manager.log_performance("api_call") as perf_context:
    response = api_client.get("/users")
    perf_context.add_metadata({
        "status_code": response.status_code,
        "response_size": len(response.content)
    })
```

### üìà APIs de M√©triques

#### `get_metrics()` - M√©triques Globales

**Description** : Obtient toutes les m√©triques du syst√®me de logging.

**Retour** : `Dict[str, Any]` avec m√©triques compl√®tes

```python
metrics = manager.get_metrics()

# Structure des m√©triques
{
    "total_logs": 15847,
    "logs_per_level": {
        "DEBUG": 5234,
        "INFO": 8456,
        "WARNING": 1823,
        "ERROR": 298,
        "CRITICAL": 36
    },
    "performance_stats": {
        "avg_processing_time_ms": 2.3,
        "max_processing_time_ms": 45.1,
        "total_processing_time_ms": 36447.2
    },
    "elasticsearch_stats": {...},
    "security_stats": {...}
}
```

#### `get_advanced_monitoring_metrics()` - M√©triques Monitoring

**Description** : M√©triques d√©taill√©es du syst√®me de monitoring avanc√©.

```python
monitoring_metrics = manager.get_advanced_monitoring_metrics()

# M√©triques OpenTelemetry et performance
{
    "tracing_enabled": True,
    "spans_created": 1547,
    "metrics_exported": 2341,
    "performance_alerts": 12,
    "avg_span_duration_ms": 15.7
}
```

#### `get_elasticsearch_metrics()` - M√©triques Elasticsearch

**Description** : M√©triques sp√©cifiques √† l'int√©gration Elasticsearch.

```python
es_metrics = manager.get_elasticsearch_metrics()

# M√©triques cache, compression, performance
{
    "documents_sent": 8456,
    "cache_hit_rate": 73.2,
    "compression_efficiency": 68.4,
    "connection_pool_utilization": 45.2,
    "avg_batch_size": 12.3
}
```

#### `get_security_metrics()` - M√©triques S√©curit√©

**Description** : M√©triques de s√©curit√© et chiffrement.

```python
security_metrics = manager.get_security_metrics()

# M√©triques chiffrement, rotation cl√©s, d√©tection
{
    "encrypted_logs": 3421,
    "key_rotations": 5,
    "sensitive_data_detections": 156,
    "security_violations": 0,
    "current_key_age_hours": 18.5
}
```

## ‚öôÔ∏è Configuration Avanc√©e

### LoggingConfig - Classe de Configuration

**Description** : Dataclass pour configuration compl√®te d'un logger.

```python
from logging_manager_optimized import LoggingConfig

# Configuration compl√®te
config = LoggingConfig(
    # Configuration de base
    logger_name="nextgen.advanced",
    log_level="INFO",
    log_dir="logs/advanced",
    filename_pattern="{component}_{date}.log",
    max_file_size=50 * 1024 * 1024,  # 50MB
    backup_count=10,
    console_enabled=True,
    file_enabled=True,
    
    # Configuration avanc√©e
    async_enabled=True,
    compression_enabled=True,
    retention_days=30,
    
    # Elasticsearch
    elasticsearch_enabled=True,
    elasticsearch_host="localhost:9200",
    elasticsearch_index="nextgen-advanced",
    elasticsearch_cache_enabled=True,
    elasticsearch_cache_size=1000,
    elasticsearch_compression_enabled=True,
    elasticsearch_connection_pool_size=5,
    
    # S√©curit√©
    encryption_enabled=True,
    encryption_key="your-32-byte-key-here",
    key_rotation_hours=24,
    max_keys_history=5,
    enhanced_sensitive_detection=True,
    sensitive_data_masking=True,
    
    # Alertes
    alerting_enabled=True,
    alert_email="admin@company.com",
    alert_webhook="https://hooks.slack.com/webhook",
    
    # Monitoring
    advanced_monitoring_enabled=True
)

logger = manager.get_logger(custom_config=config.__dict__)
```

### Configuration par Environnement

```python
# Configuration d√©veloppement
dev_config = {
    "log_level": "DEBUG",
    "console_enabled": True,
    "file_enabled": True,
    "elasticsearch_enabled": False,
    "encryption_enabled": False
}

# Configuration production
prod_config = {
    "log_level": "INFO",
    "console_enabled": False,
    "file_enabled": True,
    "elasticsearch_enabled": True,
    "encryption_enabled": True,
    "alerting_enabled": True,
    "advanced_monitoring_enabled": True
}

# Configuration test
test_config = {
    "log_level": "WARNING",
    "console_enabled": True,
    "file_enabled": False,
    "elasticsearch_enabled": False
}
```

## üé® Handlers Sp√©cialis√©s

### AsyncLogHandler - Logging Asynchrone

**Description** : Handler haute performance avec traitement asynchrone par batch.

```python
# Configuration automatique via LoggingConfig
config = {
    "async_enabled": True,
    "logger_name": "async_logger"
}
async_logger = manager.get_logger(custom_config=config)

# Le handler async est configur√© automatiquement
async_logger.info("Message trait√© de fa√ßon asynchrone")
```

### ElasticsearchHandler - Int√©gration Elasticsearch

**Fonctionnalit√©s** :
- Cache intelligent MD5
- Compression GZIP
- Pool de connexions
- M√©triques temps r√©el

```python
# Configuration Elasticsearch optimis√©e
es_config = {
    "elasticsearch_enabled": True,
    "elasticsearch_host": "cluster.elastic.com:9200",
    "elasticsearch_index": "production-logs",
    "elasticsearch_cache_enabled": True,
    "elasticsearch_compression_enabled": True
}
```

### EncryptionHandler - Chiffrement Avanc√©

**Fonctionnalit√©s** :
- Chiffrement Fernet
- Rotation automatique des cl√©s
- D√©tection de donn√©es sensibles
- Historique s√©curis√© des cl√©s

```python
# Configuration chiffrement
crypto_config = {
    "encryption_enabled": True,
    "encryption_key": "your-secure-key",
    "key_rotation_hours": 12,  # Rotation toutes les 12h
    "enhanced_sensitive_detection": True
}
```

### AlertingHandler - Syst√®me d'Alertes

**Fonctionnalit√©s** :
- Alertes email SMTP
- Webhooks (Slack, Teams, etc.)
- Cooldown anti-spam
- Filtrage intelligent

```python
# Configuration alertes
alert_config = {
    "alerting_enabled": True,
    "alert_email": "ops@company.com",
    "alert_webhook": "https://hooks.slack.com/services/YOUR/WEBHOOK/URL"
}
```

## üèóÔ∏è Architecture et Patterns

### Pattern Singleton

Le `LoggingManager` utilise le pattern Singleton thread-safe :

```python
# Toujours la m√™me instance
manager1 = LoggingManager()
manager2 = LoggingManager()
assert manager1 is manager2  # True
```

### Pattern Factory

Le manager agit comme une factory pour les loggers :

```python
# Cr√©ation automatique selon configuration
logger_a = manager.get_logger(config_name="type_a")
logger_b = manager.get_logger(config_name="type_b")
agent_logger = manager.get_agent_logger("agent", "role", "domain")
```

### Pattern Observer

Syst√®me de m√©triques avec observation des √©v√©nements :

```python
# Les m√©triques sont automatiquement mises √† jour
logger.info("Message")  # ‚Üí met √† jour total_logs, logs_per_level, etc.
```

## üö® Gestion d'Erreurs

### Fallbacks Automatiques

Le syst√®me int√®gre des fallbacks robustes :

```python
# Si Elasticsearch √©choue ‚Üí fallback vers fichier
# Si chiffrement √©choue ‚Üí fallback vers texte clair avec alerte
# Si async √©choue ‚Üí fallback vers synchrone
```

### Logging des Erreurs Internes

```python
# Les erreurs du syst√®me de logging sont captur√©es
# et logg√©es dans un logger interne s√©par√©
internal_logger = manager._internal_logger
```

## üìã Exemples d'Usage Complets

### Application Web

```python
# Configuration pour API web
web_config = {
    "logger_name": "nextgen.web.api",
    "log_level": "INFO",
    "elasticsearch_enabled": True,
    "alerting_enabled": True,
    "advanced_monitoring_enabled": True
}

web_logger = manager.get_logger(custom_config=web_config)

# Logging structur√© pour API
@app.route('/users/<user_id>')
def get_user(user_id):
    with manager.log_performance("get_user_api"):
        web_logger.info("API call", extra={
            "endpoint": "/users/{user_id}",
            "user_id": user_id,
            "method": "GET"
        })
        
        try:
            user = database.get_user(user_id)
            web_logger.info("User retrieved", extra={
                "user_id": user_id,
                "found": True
            })
            return jsonify(user)
        except UserNotFound:
            web_logger.warning("User not found", extra={
                "user_id": user_id,
                "found": False
            })
            return jsonify({"error": "User not found"}), 404
```

### Agent d'IA

```python
# Logger sp√©cialis√© pour agent
agent_logger = manager.get_agent_logger(
    agent_name="code_analyzer",
    role="analysis",
    domain="software_engineering",
    agent_id="agent_001",
    async_enabled=True
)

class CodeAnalyzer:
    def __init__(self):
        self.logger = agent_logger
    
    def analyze_file(self, filepath):
        self.logger.info("Starting file analysis", extra={
            "filepath": filepath,
            "operation": "analyze_file"
        })
        
        with manager.log_performance("file_analysis", self.logger):
            # Analyse du fichier
            results = self._perform_analysis(filepath)
            
            self.logger.info("Analysis completed", extra={
                "filepath": filepath,
                "issues_found": len(results.issues),
                "complexity_score": results.complexity
            })
            
            return results
```

### Syst√®me de Batch

```python
# Configuration pour traitement batch
batch_config = {
    "logger_name": "nextgen.batch.processor",
    "async_enabled": True,
    "elasticsearch_enabled": True,
    "compression_enabled": True
}

batch_logger = manager.get_logger(custom_config=batch_config)

def process_batch(items):
    batch_logger.info("Batch processing started", extra={
        "batch_size": len(items),
        "operation": "process_batch"
    })
    
    processed = 0
    errors = 0
    
    for item in items:
        try:
            with manager.log_performance("process_item"):
                process_item(item)
                processed += 1
        except Exception as e:
            batch_logger.error("Item processing failed", extra={
                "item_id": item.id,
                "error": str(e)
            })
            errors += 1
    
    batch_logger.info("Batch processing completed", extra={
        "total_items": len(items),
        "processed": processed,
        "errors": errors,
        "success_rate": processed / len(items) * 100
    })
```

## üîç Debugging et Diagnostics

### Mode Debug

```python
# Activation du debug
debug_config = {
    "log_level": "DEBUG",
    "console_enabled": True
}
debug_logger = manager.get_logger(custom_config=debug_config)

# Informations de debug d√©taill√©es
debug_logger.debug("Variable state", extra={
    "variables": {"x": 42, "y": "hello"},
    "function": "process_data",
    "line": 156
})
```

### M√©triques de Diagnostic

```python
# Diagnostic complet du syst√®me
def system_health_check():
    metrics = manager.get_metrics()
    es_metrics = manager.get_elasticsearch_metrics()
    security_metrics = manager.get_security_metrics()
    
    health = {
        "logging_system": "healthy" if metrics["errors_count"] == 0 else "degraded",
        "elasticsearch": "healthy" if es_metrics["elasticsearch_errors"] == 0 else "degraded",
        "security": "healthy" if security_metrics["security_violations"] == 0 else "alert"
    }
    
    return health
```

## üéØ Bonnes Pratiques

### Structuration des Logs

```python
# ‚úÖ Bon : logs structur√©s avec extra
logger.info("User login successful", extra={
    "user_id": "user_123",
    "ip_address": "192.168.1.100",
    "session_id": "sess_abc123"
})

# ‚ùå √âviter : logs non structur√©s
logger.info(f"User {user_id} logged in from {ip}")
```

### Gestion des Niveaux

```python
# DEBUG : Informations d√©taill√©es pour d√©veloppement
logger.debug("Variable values", extra={"vars": locals()})

# INFO : √âv√©nements normaux d'application
logger.info("Process completed successfully")

# WARNING : Situations anormales mais r√©cup√©rables
logger.warning("API rate limit approaching", extra={"current_rate": 95})

# ERROR : Erreurs qui affectent une op√©ration
logger.error("Database connection failed", extra={"db_host": "localhost"})

# CRITICAL : Erreurs qui peuvent arr√™ter l'application
logger.critical("Out of memory", extra={"memory_usage": "99%"})
```

### Performance

```python
# ‚úÖ Bon : utiliser le context manager
with manager.log_performance("expensive_operation"):
    result = expensive_computation()

# ‚úÖ Bon : logging asynchrone pour haute charge
config = {"async_enabled": True}
high_volume_logger = manager.get_logger(custom_config=config)
```

## üîí S√©curit√©

### Donn√©es Sensibles

Le syst√®me d√©tecte automatiquement et masque :
- Mots de passe
- Cl√©s API
- Num√©ros de carte de cr√©dit
- Emails
- Adresses IP
- Tokens d'authentification

```python
# Automatiquement masqu√©
logger.info("User authentication", extra={
    "password": "secret123",  # ‚Üí "password": "***MASKED***"
    "api_key": "sk-1234567890abcdef"  # ‚Üí "api_key": "***MASKED***"
})
```

### Chiffrement

```python
# Configuration chiffrement recommand√©e
secure_config = {
    "encryption_enabled": True,
    "key_rotation_hours": 24,
    "enhanced_sensitive_detection": True
}
```

## üìä Monitoring Production

### M√©triques Cl√©s

```python
# V√©rifications r√©guli√®res recommand√©es
def monitor_logging_health():
    metrics = manager.get_metrics()
    
    # V√©rifier les erreurs
    if metrics["errors_count"] > 100:
        alert("High error count in logging system")
    
    # V√©rifier les performances
    if metrics["performance_stats"]["avg_processing_time_ms"] > 50:
        alert("Logging performance degraded")
    
    # V√©rifier Elasticsearch
    es_metrics = manager.get_elasticsearch_metrics()
    if es_metrics["cache_hit_rate"] < 50:
        alert("Elasticsearch cache efficiency low")
```

### Alertes Recommand√©es

- Taux d'erreur > 1%
- Temps de traitement > 100ms
- Cache hit rate < 60%
- Violations de s√©curit√© > 0
- Espace disque < 10%

---

## üìö R√©f√©rence Rapide

### Import Principal
```python
from logging_manager_optimized import LoggingManager
```

### APIs Essentielles
```python
manager = LoggingManager()
logger = manager.get_logger(custom_config=config)
agent_logger = manager.get_agent_logger(name, role, domain)
metrics = manager.get_metrics()
```

### Configuration Minimale
```python
config = {"logger_name": "my_app", "log_level": "INFO"}
```

### Configuration Production
```python
config = {
    "logger_name": "production_app",
    "elasticsearch_enabled": True,
    "encryption_enabled": True,
    "alerting_enabled": True,
    "advanced_monitoring_enabled": True
}
```

---

*Documentation g√©n√©r√©e pour NextGeneration Logging System v1.1.0*
*Derni√®re mise √† jour : 2025-06-20* 