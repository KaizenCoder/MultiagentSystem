# Agent MAINTENANCE 02 â€“ Ã‰valuateur d'UtilitÃ©

## 1. Identification

- **Nom :** Ã‰valuateur d'UtilitÃ© NextGeneration
- **Identifiant :** `agent_MAINTENANCE_02_evaluateur_utilite`
- **Version :** 2.2.0 (Harmonisation Standards Pattern Factory NextGeneration)
- **Responsable Principal :** Ã‰quipe de Maintenance NextGeneration
- **Contact Technique :** `#canal-maintenance-ia`

## 2. Description GÃ©nÃ©rale

âš–ï¸ Agent spÃ©cialisÃ© dans l'Ã©valuation quantitative de la pertinence et de la qualitÃ© fonctionnelle des scripts Python via analyse AST avancÃ©e avec systÃ¨me de scoring heuristique.

Cet agent dÃ©termine l'utilitÃ© d'un code source en analysant sa structure, sa complexitÃ© et sa richesse fonctionnelle pour orienter les dÃ©cisions de maintenance.

## 3. Objectifs et Missions

- **Ã‰valuation Quantitative :** Scoring automatique basÃ© sur l'analyse AST des structures Python
- **Classification d'UtilitÃ© :** DÃ©termination binaire utilitÃ©/inutilitÃ© selon seuil configurable
- **DÃ©tection d'Obsolescence :** Identification d'Ã©lÃ©ments vides ou non fonctionnels
- **Analyse de ComplexitÃ© :** Mesure de la richesse structurelle et fonctionnelle
- **Support Maintenance :** Aide Ã  la dÃ©cision pour conservation/suppression de code

## 4. FonctionnalitÃ©s ClÃ©s (ConformitÃ© Pattern Factory)

L'agent respecte le Pattern Factory NextGeneration et expose les mÃ©thodes suivantes :

- **`startup()`** : Initialise l'agent Ã©valuateur d'utilitÃ©
- **`health_check()`** : VÃ©rifie l'Ã©tat de santÃ©. Retourne `{"status": "ok"}` en fonctionnement normal
- **`execute_task(task: Task)`** : Point d'entrÃ©e principal pour les Ã©valuations d'utilitÃ©
  - **Action attendue** : Ã‰valuation de fichier Python
    - **`task.params` attendus** :
      - `file_path` (str) : Chemin vers le fichier Python Ã  Ã©valuer
    - **RÃ©sultat** : Score d'utilitÃ©, classification binaire et dÃ©tails
- **`shutdown()`** : ArrÃªte l'agent proprement

### CapacitÃ©s SpÃ©cialisÃ©es

```python
get_capabilities() -> [
    "evaluate_utility",
    "ast_evaluation", 
    "scoring_heuristique_code",
    "detection_elements_obsoletes",
    "classification_binaire_utilite",
    "analyse_complexite_structurelle",
    "gestion_erreurs_syntaxiques"
]
```

## 5. SystÃ¨me de Scoring Heuristique

### MÃ©triques de Base

| Ã‰lÃ©ment AST | Points AttribuÃ©s | Description |
|-------------|------------------|-------------|
| **Import** | +1 par import | Chaque module importÃ© |
| **Classe** | +10 + len(body) | Points base + complexitÃ© interne |
| **Fonction** | +5 + len(body) | Points base + complexitÃ© interne |
| **Appel de fonction** | +1 | Chaque ast.Call dÃ©tectÃ© |
| **Structure contrÃ´le** | +2 | if/for/while/try |

### Bonus et Malus

- **Bonus Classe + Fonction** : +5 points si prÃ©sence des deux
- **Malus Ã‰lÃ©ments Vides** : -5 points par fonction/classe avec seulement `pass`

### Classification

```python
score >= seuil_min (dÃ©faut: 15) â†’ "Utile" (is_useful: True)
score < seuil_min â†’ "Peu utile" (is_useful: False)
```

## 6. Workflow d'Ã‰valuation

```
1. ğŸ“‹ RÃ©ception tÃ¢che avec file_path
2. ğŸ“– Lecture fichier Python (UTF-8)
3. ğŸ—ï¸ Parsing AST du code source
4. ğŸ§® Calcul score via mÃ©triques heuristiques
5. âš–ï¸ Classification binaire selon seuil
6. ğŸ“Š Retour rÃ©sultat structurÃ©
```

## 7. Format de RÃ©sultat

### SuccÃ¨s d'Ã‰valuation

```json
{
  "success": true,
  "data": {
    "score": 42,
    "is_useful": true,
    "details": "Ã‰valuation rÃ©ussie"
  }
}
```

### Erreur Syntaxique

```json
{
  "success": true,
  "data": {
    "score": 0,
    "is_useful": false,
    "details": "Erreur de syntaxe: invalid syntax (line 15)"
  }
}
```

### Erreur de Lecture

```json
{
  "success": false,
  "error": "Erreur de lecture du fichier: [Errno 2] No such file or directory"
}
```

## 8. Exemples d'Utilisation

### Ã‰valuation d'un Agent

```python
from core.agent_factory_architecture import Task
from agents.agent_MAINTENANCE_02_evaluateur_utilite import create_agent_MAINTENANCE_02_evaluateur_utilite

# CrÃ©ation de l'agent
evaluateur = create_agent_MAINTENANCE_02_evaluateur_utilite()
await evaluateur.startup()

# Ã‰valuation d'un fichier
task = Task(
    type="evaluate_utility",
    params={"file_path": "./agents/agent_exemple.py"}
)

result = await evaluateur.execute_task(task)
if result.success:
    score = result.data["score"]
    is_useful = result.data["is_useful"]
    print(f"Score: {score}, Utile: {is_useful}")
else:
    print(f"Erreur: {result.error}")

await evaluateur.shutdown()
```

### Ã‰valuation de Plusieurs Fichiers

```python
files_to_evaluate = [
    "./agents/agent_01.py",
    "./agents/agent_02.py", 
    "./agents/agent_obsolete.py"
]

results = []
for file_path in files_to_evaluate:
    task = Task(type="evaluate_utility", params={"file_path": file_path})
    result = await evaluateur.execute_task(task)
    results.append({
        "file": file_path,
        "score": result.data.get("score", 0) if result.success else 0,
        "useful": result.data.get("is_useful", False) if result.success else False
    })

# Filtrer les agents utiles
useful_agents = [r for r in results if r["useful"]]
print(f"Agents utiles: {len(useful_agents)}/{len(results)}")
```

## 9. Configuration

### Seuil d'UtilitÃ© PersonnalisÃ©

```python
# Via configuration d'agent (si disponible)
evaluateur.config = {"min_score_for_usefulness": 20}  # Seuil plus Ã©levÃ©

# Seuil par dÃ©faut : 15 points
```

## 10. DÃ©pendances

- **Python 3.8+**
- **Modules standard** : ast, pathlib, logging
- **core.agent_factory_architecture** (Agent, Task, Result)
- **Aucune dÃ©pendance externe** pour l'analyse AST

## 11. Journal des Modifications (Changelog)

- **v2.2.0 (2025-06-26)** :
  - Harmonisation avec standards Pattern Factory NextGeneration
  - Enrichissement docstrings classe avec description dÃ©taillÃ©e du scoring
  - Extension `get_capabilities()` : 2 â†’ 7 capacitÃ©s spÃ©cialisÃ©es
  - Documentation .md complÃ¨tement refaite avec exemples concrets
- **v2.1.0** :
  - AmÃ©lioration systÃ¨me de scoring avec bonus/malus
  - Gestion robuste des erreurs syntaxiques
- **v1.0** :
  - Version initiale avec Ã©valuation AST de base

## 12. ProcÃ©dure de Test CLI

```python
# test_agent_maintenance_02_evaluation.py
import asyncio
from agents.agent_MAINTENANCE_02_evaluateur_utilite import create_agent_MAINTENANCE_02_evaluateur_utilite
from core.agent_factory_architecture import Task

async def test_evaluateur_utilite():
    # 1. CrÃ©ation et startup
    evaluateur = create_agent_MAINTENANCE_02_evaluateur_utilite()
    await evaluateur.startup()
    
    # 2. Test health check
    health = await evaluateur.health_check()
    print(f"SantÃ©: {health}")
    
    # 3. Test capacitÃ©s
    caps = evaluateur.get_capabilities()
    print(f"CapacitÃ©s: {len(caps)} trouvÃ©es")
    
    # 4. Test auto-Ã©valuation
    task_self = Task(
        type="evaluate_utility",
        params={"file_path": "./agents/agent_MAINTENANCE_02_evaluateur_utilite.py"}
    )
    
    result = await evaluateur.execute_task(task_self)
    print(f"Auto-Ã©valuation rÃ©ussie: {result.success}")
    if result.success:
        print(f"  Score: {result.data['score']}")
        print(f"  Utile: {result.data['is_useful']}")
        print(f"  DÃ©tails: {result.data['details']}")
    
    # 5. Test fichier inexistant
    task_error = Task(
        type="evaluate_utility", 
        params={"file_path": "./fichier_inexistant.py"}
    )
    
    result_error = await evaluateur.execute_task(task_error)
    print(f"Gestion erreur: {not result_error.success}")
    
    # 6. Shutdown
    await evaluateur.shutdown()

# ExÃ©cution
# python -c "import asyncio; asyncio.run(test_evaluateur_utilite())"
```

## 13. Cas d'Usage RecommandÃ©s

- **Audit de codebase** : Identification des fichiers peu utiles
- **Nettoyage de maintenance** : Support Ã  la dÃ©cision de suppression
- **Ã‰valuation qualitÃ©** : Mesure quantitative de la richesse du code
- **Triage automatique** : Classification rapide de grands volumes de fichiers
- **MÃ©triques de projet** : Calcul de scores globaux de qualitÃ©

## 14. Statut et Validation

- âœ… **Pattern Factory** : Conforme (Agent, Task, Result)
- âœ… **MÃ©thodes async** : startup, shutdown, execute_task, health_check  
- âœ… **Capabilities** : 7 capacitÃ©s spÃ©cialisÃ©es dÃ©finies
- âœ… **Documentation** : Docstrings enrichies et .md synchronisÃ©
- âœ… **Tests CLI** : ProcÃ©dure de validation dÃ©finie
- âœ… **Scoring System** : MÃ©triques heuristiques documentÃ©es

**Agent MAINTENANCE 02 - Ã‰tat : PRÃŠT POUR VALIDATION**