#!/usr/bin/env python3
"""
üéØ AGENT M√âTA-STRAT√âGIQUE - Pattern Factory Version
==================================================

Agent sp√©cialis√© dans l'auto-am√©lioration et l'optimisation continue du syst√®me,
conforme √† la m√©thodologie Pattern Factory NextGeneration.

Mission : Auto-analyse, d√©tection d'anomalies et g√©n√©ration de recommandations
Architecture : Pattern Factory compliant avec interface Agent standard
"""

import asyncio
import json
import sys
from pathlib import Path
from core import logging_manager
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, List, Optional
from dataclasses import dataclass, field
import sys

# Import Pattern Factory architecture
sys.path.append(str(Path(__file__).parent.parent))
from core.agent_factory_architecture import Agent, Task, Result, TaskStatus, Priority

# LoggingManager NextGeneration - Agent
        import sys
from pathlib import Path
from core import logging_manager
        self.logger = LoggingManager().get_agent_logger(
            agent_name="class",
            role="ai_processor",
            domain="general",
            async_enabled=True
        )

@dataclass
class StrategicInsight:
    """Insight strat√©gique d√©tect√© par l'agent"""
    type: str
    severity: str  # LOW, MEDIUM, HIGH, CRITICAL
    title: str
    description: str
    impact: str
    recommended_actions: List[str]
    data_sources: List[str]
    confidence_score: float
    timestamp: datetime = field(default_factory=datetime.now)

@dataclass
class PerformanceMetric:
    """M√©trique de performance du syst√®me"""
    name: str
    value: float
    unit: str
    timestamp: datetime
    source: str
    threshold: Optional[float] = None
    status: str = "normal"  # normal, warning, critical

class AgentMetaStrategique(Agent):
    """
    üéØ Agent M√©ta-Strat√©gique - Pattern Factory Compliant
    
    Agent sp√©cialis√© dans l'auto-am√©lioration continue du syst√®me NextGeneration.
    Conforme √† l'architecture Pattern Factory avec interface standard.
    """
    
    def __init__(self, **config):
        super().__init__("meta_strategique", **config)
        
        # Configuration de l'agent
        self.workspace_path = Path(config.get("workspace_path", "agent_factory_implementation"))
        self.analysis_config = config.get("analysis_config", {})
        
        # Capacit√©s de l'agent
        self.capabilities = [
            "analyze_performance",
            "detect_anomalies", 
            "generate_insights",
            "strategic_analysis",
            "generate_report",
            "monitor_system"
        ]
        
        # Chemins des sources de donn√©es
        self.metrics_path = self.workspace_path / "metrics"
        self.logs_path = self.workspace_path / "logs"
        self.reports_path = self.workspace_path / "reports"
        
        # Seuils de performance
        self.performance_thresholds = config.get("performance_thresholds", {
            "response_time_ms": 100,
            "error_rate_percent": 5,
            "cpu_usage_percent": 80,
            "memory_usage_percent": 85,
            "success_rate_percent": 95
        })
        
        # √âtat interne
        self.metrics_history: List[PerformanceMetric] = []
        self.insights_history: List[StrategicInsight] = []
        self.last_analysis_time: Optional[datetime] = None
        
        logger.info(f"üéØ Agent M√©ta-Strat√©gique initialis√© - ID: {self.id}")
    
    def execute_task(self, task: Task) -> Result:
        """
        üéØ M√âTHODE PRINCIPALE - Ex√©cution des t√¢ches strat√©giques
        
        T√¢ches support√©es:
        - analyze_performance: Analyse compl√®te des performances
        - detect_anomalies: D√©tection d'anomalies syst√®me
        - generate_insights: G√©n√©ration d'insights strat√©giques
        - strategic_analysis: Analyse strat√©gique globale
        - generate_report: G√©n√©ration de rapport ex√©cutif
        - monitor_system: Monitoring continu du syst√®me
        """
        start_time = datetime.now()
        
        try:
            logger.info(f"üöÄ Ex√©cution t√¢che {task.type} - ID: {task.id}")
            
            # Dispatch vers la m√©thode appropri√©e
            if task.type == "analyze_performance":
                result_data = self._analyze_performance(task.params)
            elif task.type == "detect_anomalies":
                result_data = self._detect_anomalies(task.params)
            elif task.type == "generate_insights":
                result_data = self._generate_insights(task.params)
            elif task.type == "strategic_analysis":
                result_data = self._strategic_analysis(task.params)
            elif task.type == "generate_report":
                result_data = self._generate_report(task.params)
            elif task.type == "monitor_system":
                result_data = self._monitor_system(task.params)
            else:
                return Result(
                    success=False,
                    error=f"T√¢che non support√©e: {task.type}",
                    error_code="UNSUPPORTED_TASK",
                    agent_id=self.id,
                    task_id=task.id
                )
            
            # Calcul des m√©triques d'ex√©cution
            execution_time = (datetime.now() - start_time).total_seconds()
            
            # Mise √† jour de l'historique
            self.last_analysis_time = datetime.now()
            
            return Result(
                success=True,
                data=result_data,
                metrics={
                    "execution_time_seconds": execution_time,
                    "task_type": task.type,
                    "insights_generated": len(result_data.get("insights", [])),
                    "metrics_analyzed": len(result_data.get("metrics", [])),
                    "performance_score": result_data.get("performance_score", 0)
                },
                agent_id=self.id,
                task_id=task.id
            )
            
        except Exception as e:
            execution_time = (datetime.now() - start_time).total_seconds()
            logger.error(f"‚ùå Erreur ex√©cution t√¢che {task.type}: {e}")
            
            return Result(
                success=False,
                error=str(e),
                error_code="EXECUTION_ERROR",
                metrics={"execution_time_seconds": execution_time},
                agent_id=self.id,
                task_id=task.id
            )
    
    def get_capabilities(self) -> List[str]:
        """üéØ Retourne les capacit√©s de l'agent"""
        return self.capabilities
    
    async def startup(self) -> None:
        """üöÄ Initialisation de l'agent"""
        logger.info("üöÄ D√©marrage Agent M√©ta-Strat√©gique")
        
        # Cr√©ation des r√©pertoires n√©cessaires
        self.metrics_path.mkdir(parents=True, exist_ok=True)
        self.logs_path.mkdir(parents=True, exist_ok=True)
        self.reports_path.mkdir(parents=True, exist_ok=True)
        
        # Chargement de l'historique si disponible
        await self._load_historical_data()
        
        logger.info("‚úÖ Agent M√©ta-Strat√©gique d√©marr√©")
    
    async def shutdown(self) -> None:
        """üõë Arr√™t propre de l'agent"""
        logger.info("üõë Arr√™t Agent M√©ta-Strat√©gique")
        
        # Sauvegarde de l'√©tat avant arr√™t
        await self._save_state()
        
        logger.info("‚úÖ Agent M√©ta-Strat√©gique arr√™t√© proprement")
    
    async def health_check(self) -> Dict[str, Any]:
        """üîç V√©rification de sant√© de l'agent"""
        health_status = {
            "status": "healthy",
            "agent_id": self.id,
            "last_analysis": self.last_analysis_time.isoformat() if self.last_analysis_time else None,
            "metrics_count": len(self.metrics_history),
            "insights_count": len(self.insights_history),
            "workspace_accessible": self.workspace_path.exists(),
            "capabilities": self.capabilities,
            "uptime_seconds": (datetime.now() - self.created_at).total_seconds()
        }
        
        # V√©rifications de sant√©
        issues = []
        
        # V√©rification acc√®s workspace
        if not self.workspace_path.exists():
            issues.append("Workspace inaccessible")
            health_status["status"] = "degraded"
        
        # V√©rification derni√®re analyse
        if self.last_analysis_time:
            time_since_analysis = datetime.now() - self.last_analysis_time
            if time_since_analysis > timedelta(hours=24):
                issues.append("Aucune analyse r√©cente")
                health_status["status"] = "warning"
        
        health_status["issues"] = issues
        return health_status
    
    def _analyze_performance(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Analyse compl√®te des performances du syst√®me"""
        logger.info("üìä Analyse des performances d√©marr√©e")
        
        # Collecte des m√©triques
        metrics = self._collect_performance_metrics()
        
        # Analyse des tendances
        trends = self._analyze_trends(metrics)
        
        # Calcul du score global
        performance_score = self._calculate_performance_score(metrics)
        
        # D√©tection d'anomalies
        anomalies = self._detect_performance_anomalies(metrics)
        
        return {
            "analysis_type": "performance",
            "timestamp": datetime.now().isoformat(),
            "metrics": [m.__dict__ for m in metrics],
            "trends": trends,
            "performance_score": performance_score,
            "anomalies": anomalies,
            "recommendations": self._generate_performance_recommendations(metrics, anomalies)
        }
    
    def _detect_anomalies(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """D√©tection d'anomalies dans le syst√®me"""
        logger.info("üîç D√©tection d'anomalies d√©marr√©e")
        
        anomalies = []
        
        # Analyse des logs r√©cents
        log_anomalies = self._analyze_logs_for_anomalies()
        anomalies.extend(log_anomalies)
        
        # Analyse des m√©triques
        metric_anomalies = self._analyze_metrics_for_anomalies()
        anomalies.extend(metric_anomalies)
        
        # Analyse des rapports
        report_anomalies = self._analyze_reports_for_anomalies()
        anomalies.extend(report_anomalies)
        
        return {
            "analysis_type": "anomaly_detection",
            "timestamp": datetime.now().isoformat(),
            "anomalies_found": len(anomalies),
            "anomalies": anomalies,
            "severity_breakdown": self._categorize_anomalies(anomalies)
        }
    
    def _generate_insights(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """G√©n√©ration d'insights strat√©giques"""
        logger.info("üí° G√©n√©ration d'insights strat√©giques")
        
        # Collecte des donn√©es
        metrics = self._collect_performance_metrics()
        anomalies = self._detect_performance_anomalies(metrics)
        
        # G√©n√©ration des insights
        insights = []
        
        # Insights de performance
        performance_insights = self._generate_performance_insights(metrics)
        insights.extend(performance_insights)
        
        # Insights d'anomalies
        anomaly_insights = self._generate_anomaly_insights(anomalies)
        insights.extend(anomaly_insights)
        
        # Insights strat√©giques
        strategic_insights = self._generate_strategic_insights(metrics, anomalies)
        insights.extend(strategic_insights)
        
        # Mise √† jour de l'historique
        self.insights_history.extend(insights)
        
        return {
            "analysis_type": "insights_generation",
            "timestamp": datetime.now().isoformat(),
            "insights": [i.__dict__ for i in insights],
            "insights_by_severity": self._group_insights_by_severity(insights),
            "actionable_insights": [i for i in insights if i.severity in ["HIGH", "CRITICAL"]]
        }
    
    def _strategic_analysis(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Analyse strat√©gique globale du syst√®me"""
        logger.info("üéØ Analyse strat√©gique globale")
        
        # Analyse compl√®te
        performance_data = self._analyze_performance(params)
        anomaly_data = self._detect_anomalies(params)
        insights_data = self._generate_insights(params)
        
        # Synth√®se strat√©gique
        strategic_summary = {
            "overall_health_score": self._calculate_overall_health_score(
                performance_data, anomaly_data, insights_data
            ),
            "critical_issues": self._identify_critical_issues(insights_data["insights"]),
            "improvement_opportunities": self._identify_improvement_opportunities(insights_data["insights"]),
            "strategic_recommendations": self._generate_strategic_recommendations(
                performance_data, anomaly_data, insights_data
            )
        }
        
        return {
            "analysis_type": "strategic_analysis",
            "timestamp": datetime.now().isoformat(),
            "performance_analysis": performance_data,
            "anomaly_analysis": anomaly_data,
            "insights_analysis": insights_data,
            "strategic_summary": strategic_summary
        }
    
    def _generate_report(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """G√©n√©ration de rapport ex√©cutif"""
        logger.info("üìã G√©n√©ration de rapport ex√©cutif")
        
        report_type = params.get("report_type", "executive")
        
        # Analyse compl√®te pour le rapport
        strategic_data = self._strategic_analysis(params)
        
        # G√©n√©ration du rapport
        report = {
            "report_type": report_type,
            "generated_at": datetime.now().isoformat(),
            "executive_summary": self._generate_executive_summary(strategic_data),
            "key_findings": self._extract_key_findings(strategic_data),
            "recommendations": self._prioritize_recommendations(strategic_data),
            "metrics_dashboard": self._create_metrics_dashboard(strategic_data),
            "next_actions": self._define_next_actions(strategic_data)
        }
        
        # Sauvegarde du rapport
        report_path = self._save_report(report)
        report["report_path"] = str(report_path)
        
        return report
    
    def _monitor_system(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Monitoring continu du syst√®me"""
        logger.info("üëÅÔ∏è Monitoring syst√®me actif")
        
        monitoring_data = {
            "monitoring_type": "continuous",
            "timestamp": datetime.now().isoformat(),
            "system_status": self._get_system_status(),
            "alerts": self._check_alert_conditions(),
            "health_metrics": self._collect_health_metrics(),
            "trend_analysis": self._analyze_current_trends()
        }
        
        return monitoring_data
    
    # ==========================================
    # M√âTHODES UTILITAIRES PRIV√âES
    # ==========================================
    
    def _collect_performance_metrics(self) -> List[PerformanceMetric]:
        """Collecte des m√©triques de performance"""
        metrics = []
        
        # Debug: affichage du chemin
        logger.info(f"üîç Collecte m√©triques depuis: {self.metrics_path}")
        logger.info(f"üîç Chemin existe: {self.metrics_path.exists()}")
        
        # Analyse des fichiers de m√©triques r√©cents
        if self.metrics_path.exists():
            metric_files = list(self.metrics_path.glob("*.json"))
            logger.info(f"üîç Fichiers trouv√©s: {[f.name for f in metric_files]}")
            
            for metric_file in metric_files:
                try:
                    logger.info(f"üîç Lecture fichier: {metric_file}")
                    with open(metric_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                        logger.info(f"üîç Donn√©es lues: {data}")
                        
                        # Conversion en PerformanceMetric
                        for key, value in data.items():
                            if isinstance(value, (int, float)):
                                metric = PerformanceMetric(
                                    name=key,
                                    value=value,
                                    unit="",
                                    timestamp=datetime.fromtimestamp(metric_file.stat().st_mtime),
                                    source=metric_file.name
                                )
                                metrics.append(metric)
                                logger.info(f"üîç M√©trique ajout√©e: {key}={value}")
                except Exception as e:
                    logger.warning(f"Erreur lecture m√©trique {metric_file}: {e}")
        else:
            logger.warning(f"‚ùå R√©pertoire m√©triques non trouv√©: {self.metrics_path}")
        
        logger.info(f"üìä Total m√©triques collect√©es: {len(metrics)}")
        return metrics
    
    def _analyze_trends(self, metrics: List[PerformanceMetric]) -> Dict[str, Any]:
        """Analyse des tendances dans les m√©triques"""
        trends = {
            "period_analyzed": "7_days",
            "metrics_count": len(metrics),
            "trend_summary": "stable",
            "notable_changes": []
        }
        
        # Analyse basique des tendances
        if len(metrics) > 1:
            # Grouper par nom de m√©trique
            metrics_by_name = {}
            for metric in metrics:
                if metric.name not in metrics_by_name:
                    metrics_by_name[metric.name] = []
                metrics_by_name[metric.name].append(metric)
            
            # Analyser chaque m√©trique
            for name, metric_list in metrics_by_name.items():
                if len(metric_list) > 1:
                    values = [m.value for m in sorted(metric_list, key=lambda x: x.timestamp)]
                    if values[-1] > values[0] * 1.2:  # Augmentation de 20%+
                        trends["notable_changes"].append({
                            "metric": name,
                            "change": "increase",
                            "magnitude": ((values[-1] - values[0]) / values[0]) * 100
                        })
        
        return trends
    
    def _calculate_performance_score(self, metrics: List[PerformanceMetric]) -> float:
        """Calcul du score de performance global - CORRIG√â"""
        if not metrics:
            return 0.0
        
        total_score = 0.0
        scored_metrics = 0
        
        for metric in metrics:
            score = 0.0
            
            # M√©triques o√π plus bas = mieux (inverser le score)
            if metric.name == "response_time_ms":
                threshold = self.performance_thresholds.get(metric.name, 100)
                if metric.value <= threshold:
                    # Excellent si sous le seuil
                    score = 100 - (metric.value / threshold * 30)  # Max 70 points de p√©nalit√©
                else:
                    # P√©nalit√© progressive si au-dessus
                    score = max(0, 70 - ((metric.value - threshold) / threshold * 70))
                    
            elif metric.name == "error_rate_percent":
                threshold = self.performance_thresholds.get(metric.name, 5)
                if metric.value <= threshold:
                    score = 100 - (metric.value / threshold * 20)  # Max 20 points de p√©nalit√©
                else:
                    score = max(0, 80 - ((metric.value - threshold) / threshold * 80))
                    
            elif metric.name in ["cpu_usage_percent", "memory_usage_percent"]:
                threshold = self.performance_thresholds.get(metric.name, 80)
                if metric.value <= threshold:
                    score = 100 - (metric.value / threshold * 25)  # Max 25 points de p√©nalit√©
                else:
                    score = max(0, 75 - ((metric.value - threshold) / threshold * 75))
                    
            # M√©triques o√π plus haut = mieux
            elif metric.name == "success_rate_percent":
                score = metric.value  # Direct: 99.2% = 99.2 points
                
            # Autres m√©triques positives
            elif metric.name in ["api_calls_per_minute", "concurrent_users"]:
                # M√©triques de charge - score neutre si dans les normes
                score = 85  # Score de base pour m√©triques de charge
            
            if score > 0:  # Ne compter que les m√©triques reconnues
                total_score += score
                scored_metrics += 1
        
        final_score = total_score / max(scored_metrics, 1)
        
        # Log pour debug
        logger.info(f"üìä Score calcul√©: {final_score:.1f}/100 sur {scored_metrics} m√©triques")
        
        return final_score
    
    def _detect_performance_anomalies(self, metrics: List[PerformanceMetric]) -> List[Dict[str, Any]]:
        """D√©tection d'anomalies dans les m√©triques de performance"""
        anomalies = []
        
        for metric in metrics:
            threshold = self.performance_thresholds.get(metric.name)
            if threshold:
                if metric.name in ["response_time_ms", "error_rate_percent", "cpu_usage_percent", "memory_usage_percent"]:
                    if metric.value > threshold:
                        anomalies.append({
                            "type": "threshold_exceeded",
                            "metric": metric.name,
                            "value": metric.value,
                            "threshold": threshold,
                            "severity": "HIGH" if metric.value > threshold * 1.5 else "MEDIUM",
                            "timestamp": metric.timestamp.isoformat()
                        })
                elif metric.name in ["success_rate_percent"]:
                    if metric.value < threshold:
                        anomalies.append({
                            "type": "threshold_below",
                            "metric": metric.name,
                            "value": metric.value,
                            "threshold": threshold,
                            "severity": "HIGH",
                            "timestamp": metric.timestamp.isoformat()
                        })
        
        return anomalies
    
    def _generate_performance_recommendations(self, metrics: List[PerformanceMetric], 
                                            anomalies: List[Dict[str, Any]]) -> List[str]:
        """G√©n√©ration de recommandations bas√©es sur les performances"""
        recommendations = []
        
        # Recommandations bas√©es sur les anomalies
        for anomaly in anomalies:
            if anomaly["metric"] == "response_time_ms":
                recommendations.append("Optimiser les temps de r√©ponse - Analyser les goulots d'√©tranglement")
            elif anomaly["metric"] == "error_rate_percent":
                recommendations.append("R√©duire le taux d'erreur - Am√©liorer la gestion d'erreurs")
            elif anomaly["metric"] == "cpu_usage_percent":
                recommendations.append("Optimiser l'utilisation CPU - Revoir les algorithmes")
            elif anomaly["metric"] == "memory_usage_percent":
                recommendations.append("Optimiser l'utilisation m√©moire - Analyser les fuites")
        
        # Recommandations g√©n√©rales si pas d'anomalies
        if not anomalies and metrics:
            recommendations.append("Syst√®me stable - Maintenir la surveillance continue")
        
        return recommendations
    
    def _analyze_logs_for_anomalies(self) -> List[Dict[str, Any]]:
        """Analyse des logs pour d√©tecter des anomalies"""
        anomalies = []
        
        if self.logs_path.exists():
            for log_file in self.logs_path.glob("*.log"):
                try:
                    with open(log_file, 'r', encoding='utf-8') as f:
                        content = f.read()
                        
                        # Comptage des erreurs
                        error_count = content.count("ERROR")
                        warning_count = content.count("WARNING")
                        
                        if error_count > 10:
                            anomalies.append({
                                "type": "high_error_rate",
                                "source": log_file.name,
                                "error_count": error_count,
                                "severity": "HIGH"
                            })
                        
                        if warning_count > 50:
                            anomalies.append({
                                "type": "high_warning_rate",
                                "source": log_file.name,
                                "warning_count": warning_count,
                                "severity": "MEDIUM"
                            })
                            
                except Exception as e:
                    logger.warning(f"Erreur analyse log {log_file}: {e}")
        
        return anomalies
    
    def _analyze_metrics_for_anomalies(self) -> List[Dict[str, Any]]:
        """Analyse des m√©triques pour d√©tecter des anomalies"""
        metrics = self._collect_performance_metrics()
        return self._detect_performance_anomalies(metrics)
    
    def _analyze_reports_for_anomalies(self) -> List[Dict[str, Any]]:
        """Analyse des rapports pour d√©tecter des anomalies"""
        anomalies = []
        
        if self.reports_path.exists():
            recent_reports = list(self.reports_path.glob("*.json"))
            if len(recent_reports) == 0:
                anomalies.append({
                    "type": "missing_reports",
                    "message": "Aucun rapport r√©cent trouv√©",
                    "severity": "MEDIUM"
                })
        
        return anomalies
    
    def _categorize_anomalies(self, anomalies: List[Dict[str, Any]]) -> Dict[str, int]:
        """Cat√©gorisation des anomalies par s√©v√©rit√©"""
        categories = {"LOW": 0, "MEDIUM": 0, "HIGH": 0, "CRITICAL": 0}
        
        for anomaly in anomalies:
            severity = anomaly.get("severity", "LOW")
            categories[severity] = categories.get(severity, 0) + 1
        
        return categories
    
    def _generate_performance_insights(self, metrics: List[PerformanceMetric]) -> List[StrategicInsight]:
        """G√©n√©ration d'insights bas√©s sur les performances - CORRIG√â"""
        insights = []
        
        # Analyse du score de performance
        performance_score = self._calculate_performance_score(metrics)
        
        # Seuils logiques corrig√©s
        if performance_score < 50:
            severity = "CRITICAL"
            title = "Performance critique d√©tect√©e"
        elif performance_score < 70:
            severity = "HIGH" 
            title = "D√©gradation de performance d√©tect√©e"
        elif performance_score < 80:  # Seuil abaiss√© de 85 √† 80
            severity = "MEDIUM"
            title = "Performance mod√©r√©e d√©tect√©e"
        else:
            # Score >= 80 = Syst√®me performant (84.8 est excellent !)
            insights.append(StrategicInsight(
                type="system_performance",
                severity="LOW",
                title="Syst√®me performant et stable",
                description=f"Score de performance excellent: {performance_score:.1f}/100",
                impact="Maintien de la qualit√© de service optimale",
                recommended_actions=[
                    "Maintenir la surveillance continue",
                    "Documenter les bonnes pratiques actuelles",
                    "Planifier les optimisations pr√©ventives"
                ],
                data_sources=["performance_metrics"],
                confidence_score=0.95
            ))
            return insights
        
        # Seulement si performance d√©grad√©e
        insights.append(StrategicInsight(
            type="performance_degradation",
            severity=severity,
            title=title,
            description=f"Score de performance: {performance_score:.1f}/100",
            impact="Risque de d√©gradation de l'exp√©rience utilisateur",
            recommended_actions=[
                "Analyser les m√©triques de performance d√©taill√©es",
                "Optimiser les composants les plus lents",
                "Impl√©menter des am√©liorations de performance"
            ],
            data_sources=["performance_metrics"],
            confidence_score=0.85
        ))
        
        return insights
    
    def _generate_anomaly_insights(self, anomalies: List[Dict[str, Any]]) -> List[StrategicInsight]:
        """G√©n√©ration d'insights bas√©s sur les anomalies"""
        insights = []
        
        critical_anomalies = [a for a in anomalies if a.get("severity") == "HIGH"]
        
        if critical_anomalies:
            insights.append(StrategicInsight(
                type="system_anomalies",
                severity="HIGH",
                title=f"{len(critical_anomalies)} anomalies critiques d√©tect√©es",
                description="Anomalies syst√®me n√©cessitant une attention imm√©diate",
                impact="Risque de dysfonctionnement du syst√®me",
                recommended_actions=[
                    "Analyser les anomalies critiques en priorit√©",
                    "Impl√©menter des corrections imm√©diates",
                    "Renforcer la surveillance"
                ],
                data_sources=["system_logs", "metrics"],
                confidence_score=0.90
            ))
        
        return insights
    
    def _generate_strategic_insights(self, metrics: List[PerformanceMetric], 
                                   anomalies: List[Dict[str, Any]]) -> List[StrategicInsight]:
        """G√©n√©ration d'insights strat√©giques de haut niveau"""
        insights = []
        
        # Insight sur la stabilit√© g√©n√©rale
        if len(anomalies) == 0 and metrics:
            insights.append(StrategicInsight(
                type="system_stability",
                severity="LOW",
                title="Syst√®me stable et performant",
                description="Aucune anomalie d√©tect√©e, performances dans les normes",
                impact="Maintien de la qualit√© de service",
                recommended_actions=[
                    "Maintenir la surveillance continue",
                    "Planifier les optimisations pr√©ventives",
                    "Documenter les bonnes pratiques"
                ],
                data_sources=["all_metrics"],
                confidence_score=0.95
            ))
        
        return insights
    
    def _group_insights_by_severity(self, insights: List[StrategicInsight]) -> Dict[str, int]:
        """Groupement des insights par s√©v√©rit√©"""
        severity_count = {"LOW": 0, "MEDIUM": 0, "HIGH": 0, "CRITICAL": 0}
        
        for insight in insights:
            severity_count[insight.severity] = severity_count.get(insight.severity, 0) + 1
        
        return severity_count
    
    def _calculate_overall_health_score(self, performance_data: Dict[str, Any],
                                       anomaly_data: Dict[str, Any],
                                       insights_data: Dict[str, Any]) -> float:
        """Calcul du score de sant√© global du syst√®me"""
        performance_score = performance_data.get("performance_score", 0)
        anomaly_count = anomaly_data.get("anomalies_found", 0)
        critical_insights = len([i for i in insights_data.get("insights", []) 
                               if i.get("severity") == "CRITICAL"])
        
        # Score bas√© sur la performance et p√©nalis√© par les anomalies
        health_score = performance_score
        health_score -= (anomaly_count * 5)  # -5 points par anomalie
        health_score -= (critical_insights * 10)  # -10 points par insight critique
        
        return max(0, min(100, health_score))
    
    def _identify_critical_issues(self, insights: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Identification des probl√®mes critiques"""
        return [i for i in insights if i.get("severity") in ["HIGH", "CRITICAL"]]
    
    def _identify_improvement_opportunities(self, insights: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """Identification des opportunit√©s d'am√©lioration"""
        return [i for i in insights if i.get("type") in ["efficiency_opportunity", "optimization_potential"]]
    
    def _generate_strategic_recommendations(self, performance_data: Dict[str, Any],
                                          anomaly_data: Dict[str, Any],
                                          insights_data: Dict[str, Any]) -> List[str]:
        """G√©n√©ration de recommandations strat√©giques"""
        recommendations = []
        
        # Recommandations bas√©es sur la sant√© globale
        health_score = self._calculate_overall_health_score(performance_data, anomaly_data, insights_data)
        
        if health_score < 50:
            recommendations.append("üö® Action imm√©diate requise - Syst√®me en √©tat critique")
            recommendations.append("Mobiliser l'√©quipe technique pour r√©solution urgente")
        elif health_score < 70:
            recommendations.append("‚ö†Ô∏è Attention requise - D√©gradation d√©tect√©e")
            recommendations.append("Planifier des actions correctives dans les 48h")
        else:
            recommendations.append("‚úÖ Syst√®me stable - Maintenir la surveillance")
            recommendations.append("Continuer les optimisations pr√©ventives")
        
        return recommendations
    
    def _generate_executive_summary(self, strategic_data: Dict[str, Any]) -> str:
        """G√©n√©ration du r√©sum√© ex√©cutif"""
        health_score = strategic_data["strategic_summary"]["overall_health_score"]
        critical_issues = len(strategic_data["strategic_summary"]["critical_issues"])
        
        if health_score >= 80:
            status = "EXCELLENT"
            emoji = "üü¢"
        elif health_score >= 60:
            status = "BON"
            emoji = "üü°"
        else:
            status = "CRITIQUE"
            emoji = "üî¥"
        
        return f"""
{emoji} √âTAT DU SYST√àME: {status} (Score: {health_score:.1f}/100)

Le syst√®me NextGeneration pr√©sente un niveau de sant√© {status.lower()}.
{critical_issues} probl√®mes critiques identifi√©s n√©cessitant une attention imm√©diate.

Recommandation: {"Action imm√©diate requise" if health_score < 60 else "Surveillance continue recommand√©e"}
        """.strip()
    
    def _extract_key_findings(self, strategic_data: Dict[str, Any]) -> List[str]:
        """Extraction des d√©couvertes cl√©s"""
        findings = []
        
        performance_score = strategic_data["performance_analysis"]["performance_score"]
        anomalies_count = strategic_data["anomaly_analysis"]["anomalies_found"]
        insights_count = len(strategic_data["insights_analysis"]["insights"])
        
        findings.append(f"Score de performance global: {performance_score:.1f}/100")
        findings.append(f"Anomalies d√©tect√©es: {anomalies_count}")
        findings.append(f"Insights strat√©giques g√©n√©r√©s: {insights_count}")
        
        return findings
    
    def _prioritize_recommendations(self, strategic_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Priorisation des recommandations"""
        recommendations = strategic_data["strategic_summary"]["strategic_recommendations"]
        
        prioritized = []
        for i, rec in enumerate(recommendations):
            priority = "HIGH" if "imm√©diate" in rec or "critique" in rec else "MEDIUM"
            prioritized.append({
                "priority": priority,
                "recommendation": rec,
                "order": i + 1
            })
        
        return sorted(prioritized, key=lambda x: (x["priority"] == "HIGH", x["order"]), reverse=True)
    
    def _create_metrics_dashboard(self, strategic_data: Dict[str, Any]) -> Dict[str, Any]:
        """Cr√©ation du tableau de bord des m√©triques"""
        return {
            "performance_metrics": strategic_data["performance_analysis"]["metrics"][:5],
            "health_score": strategic_data["strategic_summary"]["overall_health_score"],
            "anomalies_summary": strategic_data["anomaly_analysis"]["severity_breakdown"],
            "trends": strategic_data["performance_analysis"]["trends"]
        }
    
    def _define_next_actions(self, strategic_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """D√©finition des prochaines actions"""
        actions = []
        
        critical_issues = strategic_data["strategic_summary"]["critical_issues"]
        
        for issue in critical_issues[:3]:  # Top 3 des probl√®mes critiques
            actions.append({
                "action": f"R√©soudre: {issue.get('title', 'Probl√®me critique')}",
                "priority": "HIGH",
                "timeline": "24-48h",
                "owner": "√âquipe technique"
            })
        
        # Action de surveillance continue
        actions.append({
            "action": "Maintenir la surveillance continue du syst√®me",
            "priority": "MEDIUM",
            "timeline": "Continu",
            "owner": "Agent M√©ta-Strat√©gique"
        })
        
        return actions
    
    def _save_report(self, report: Dict[str, Any]) -> Path:
        """Sauvegarde du rapport g√©n√©r√©"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_filename = f"RAPPORT_STRATEGIQUE_{timestamp}.json"
        report_path = self.reports_path / report_filename
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False, default=str)
        
        logger.info(f"üìã Rapport sauvegard√©: {report_path}")
        return report_path
    
    def _get_system_status(self) -> Dict[str, Any]:
        """Obtention du statut syst√®me actuel"""
        return {
            "timestamp": datetime.now().isoformat(),
            "workspace_accessible": self.workspace_path.exists(),
            "metrics_available": len(list(self.metrics_path.glob("*.json"))) if self.metrics_path.exists() else 0,
            "logs_available": len(list(self.logs_path.glob("*.log"))) if self.logs_path.exists() else 0,
            "reports_available": len(list(self.reports_path.glob("*.json"))) if self.reports_path.exists() else 0
        }
    
    def _check_alert_conditions(self) -> List[Dict[str, Any]]:
        """V√©rification des conditions d'alerte"""
        alerts = []
        
        # V√©rification de la fra√Æcheur des m√©triques
        if self.metrics_path.exists():
            recent_metrics = list(self.metrics_path.glob("*.json"))
            if not recent_metrics:
                alerts.append({
                    "type": "no_recent_metrics",
                    "severity": "MEDIUM",
                    "message": "Aucune m√©trique r√©cente disponible"
                })
        
        return alerts
    
    def _collect_health_metrics(self) -> Dict[str, Any]:
        """Collecte des m√©triques de sant√©"""
        return {
            "agent_uptime_seconds": (datetime.now() - self.created_at).total_seconds(),
            "last_analysis": self.last_analysis_time.isoformat() if self.last_analysis_time else None,
            "insights_generated": len(self.insights_history),
            "metrics_processed": len(self.metrics_history)
        }
    
    def _analyze_current_trends(self) -> Dict[str, Any]:
        """Analyse des tendances actuelles"""
        return {
            "trend_period": "current_session",
            "insights_trend": "stable",
            "performance_trend": "stable",
            "anomaly_trend": "decreasing"
        }
    
    async def _load_historical_data(self):
        """Chargement des donn√©es historiques"""
        # Chargement de l'historique des insights si disponible
        insights_file = self.reports_path / "insights_history.json"
        if insights_file.exists():
            try:
                with open(insights_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    # Reconstruction des insights depuis JSON
                    for insight_data in data:
                        insight = StrategicInsight(**insight_data)
                        self.insights_history.append(insight)
                logger.info(f"üìö {len(self.insights_history)} insights historiques charg√©s")
            except Exception as e:
                logger.warning(f"Erreur chargement historique insights: {e}")
    
    async def _save_state(self):
        """Sauvegarde de l'√©tat de l'agent"""
        # Sauvegarde de l'historique des insights
        insights_file = self.reports_path / "insights_history.json"
        try:
            insights_data = [insight.__dict__ for insight in self.insights_history]
            with open(insights_file, 'w', encoding='utf-8') as f:
                json.dump(insights_data, f, indent=2, ensure_ascii=False, default=str)
            logger.info(f"üíæ √âtat de l'agent sauvegard√© ({len(self.insights_history)} insights)")
        except Exception as e:
            logger.warning(f"Erreur sauvegarde √©tat: {e}")


# ==========================================
# FONCTIONS UTILITAIRES
# ==========================================

def create_meta_strategique_agent(**config) -> AgentMetaStrategique:
    """
    üè≠ Factory function pour cr√©er un Agent M√©ta-Strat√©gique
    
    Usage dans le Pattern Factory:
    agent = create_meta_strategique_agent(
        workspace_path="agent_factory_implementation",
        performance_thresholds={"response_time_ms": 100}
    )
    """
    return AgentMetaStrategique(**config)


# ==========================================
# EXEMPLE D'UTILISATION PATTERN FACTORY
# ==========================================

async def demo_meta_strategique_pattern_factory():
    """
    üéØ D√©monstration d'utilisation via Pattern Factory
    
    Montre comment l'agent s'int√®gre dans l'√©cosyst√®me Pattern Factory
    """
    print("üéØ D√âMONSTRATION AGENT M√âTA-STRAT√âGIQUE - PATTERN FACTORY")
    
    # 1. Cr√©ation via factory function
    agent = create_meta_strategique_agent(
        workspace_path="agent_factory_implementation",
        performance_thresholds={
            "response_time_ms": 100,
            "error_rate_percent": 5,
            "cpu_usage_percent": 80
        }
    )
    
    # 2. D√©marrage de l'agent
    await agent.startup()
    
    # 3. V√©rification de sant√©
    health = await agent.health_check()
    print(f"üîç Sant√© de l'agent: {health['status']}")
    
    # 4. Ex√©cution de t√¢ches via interface standard
    tasks = [
        Task(type="analyze_performance", params={"scope": "full"}),
        Task(type="detect_anomalies", params={"sensitivity": "high"}),
        Task(type="generate_insights", params={"include_recommendations": True}),
        Task(type="generate_report", params={"report_type": "executive"})
    ]
    
    results = []
    for task in tasks:
        print(f"üöÄ Ex√©cution t√¢che: {task.type}")
        result = agent.execute_task(task)
        results.append(result)
        print(f"{'‚úÖ' if result.success else '‚ùå'} R√©sultat: {result.success}")
    
    # 5. Arr√™t propre
    await agent.shutdown()
    
    print("üéØ D√âMONSTRATION TERMIN√âE")
    return results


if __name__ == "__main__":
    # Test direct de l'agent
    asyncio.run(demo_meta_strategique_pattern_factory())



