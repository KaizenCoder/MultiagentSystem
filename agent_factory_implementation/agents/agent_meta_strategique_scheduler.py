#!/usr/bin/env python3
"""

# üîß CONVERTI AUTOMATIQUEMENT SYNC ‚Üí ASYNC
# Date: 2025-06-19 19h35 - Correction architecture Pattern Factory
# Raison: Harmonisation async/sync avec core/agent_factory_architecture.py

üöß DRAFT VERSION üöß
Planificateur pour l'Agent M√©ta-Strat√©gique - VERSION DRAFT/PROTOTYPE
Mission: Ex√©cuter p√©riodiquement l'analyse strat√©gique et g√©n√©rer les rapports

‚ö†Ô∏è ATTENTION: CETTE VERSION EST UN PROTOTYPE EN D√âVELOPPEMENT
- Ne pas utiliser en production
- Fonctionnalit√©s en cours de test et validation
- Rapports g√©n√©r√©s √† titre exp√©rimental uniquement

Fonctionnalit√©s:
- Planification automatique des analyses
- Int√©gration avec l'API GitHub pour les m√©triques CI/CD
- Notifications des insights critiques
- Archivage des rapports historiques
"""

import asyncio
import json
from logging_manager_optimized import LoggingManager
import schedule
import time
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

# Import de notre agent m√©ta-strat√©gique
import sys
sys.path.append(str(Path(__file__).parent.parent))
from agent_meta_strategique import AgentMetaStrategique

class AgentMetaStrategiqueScheduler:
    """Planificateur pour l'ex√©cution p√©riodique de l'Agent M√©ta-Strat√©gique"""
    
    def __init__(self, config_path: str = "config/meta_strategique_config.json"):
    self.config_path = Path(config_path)
        # LoggingManager NextGeneration - Agent
    from logging_manager_optimized import LoggingManager
    self.logger = LoggingManager().get_agent_logger(
    agent_name="AgentMetaStrategiqueScheduler",
    role="ai_processor",
    domain="general",
    async_enabled=True
    )
        
        # Configuration par d√©faut
    self.default_config = {
    "execution_schedule": {
    "daily_report": "09:00",
    "weekly_deep_analysis": "MON:08:00",
    "critical_monitoring": 30  # minutes
    },
    "notifications": {
    "email_enabled": False,
    "email_recipients": [],
    "smtp_server": "smtp.gmail.com",
    "smtp_port": 587,
    "webhook_url": None
    },
    "github_integration": {
    "enabled": False,
    "api_token": None,
    "repo_owner": "nextgeneration",
    "repo_name": "nextgeneration"
    },
    "analysis_settings": {
    "retention_days": 30,
    "critical_threshold": 0.8,
    "archive_reports": True
    }
    }
        
    self.config = self.load_config()
    self.agent = AgentMetaStrategique()
    self.last_analysis_results = None
        
    def load_config(self) -> Dict[str, Any]:
        """Chargement de la configuration"""
    if self.config_path.exists():
    try:
    with open(self.config_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
                    # Fusion avec la config par d√©faut
        merged_config = self.default_config.copy()
        merged_config.update(config)
        return merged_config
    except Exception as e:
    self.logger.error(f"Erreur chargement config: {e}")
        
        # Cr√©er la configuration par d√©faut
    self.save_config(self.default_config)
    return self.default_config
    
    def save_config(self, config: Dict[str, Any]):
        """Sauvegarde de la configuration"""
    self.config_path.parent.mkdir(parents=True, exist_ok=True)
    with open(self.config_path, 'w', encoding='utf-8') as f:
    json.dump(config, f, indent=2, ensure_ascii=False)
    
    def start_scheduler(self):
        """D√©marrage du planificateur"""
    self.logger.info("üöß D√©marrage du planificateur Agent M√©ta-Strat√©gique DRAFT/PROTOTYPE")
        
        # Planification des t√¢ches
    self.setup_schedules()
        
        # Ex√©cution imm√©diate pour test
    self.logger.info("üîç Ex√©cution d'analyse initiale...")
    self.execute_daily_analysis()
        
        # Boucle principale
    try:
    while True:
    schedule.run_pending()
    await asyncio.sleep(60)  # V√©rification chaque minute
    except KeyboardInterrupt:
    self.logger.info("üõë Arr√™t du planificateur")
    
    def setup_schedules(self):
        """Configuration des planifications"""
    config = self.config["execution_schedule"]
        
        # Rapport quotidien
    daily_time = config["daily_report"]
    schedule.every().day.at(daily_time).do(self.execute_daily_analysis)
    self.logger.info(f"üìÖ Rapport quotidien planifi√© √† {daily_time}")
        
        # Analyse hebdomadaire approfondie
    weekly_schedule = config["weekly_deep_analysis"]
    if ":" in weekly_schedule:
    day, time_str = weekly_schedule.split(":")
    getattr(schedule.every(), day.lower()).at(time_str).do(self.execute_weekly_deep_analysis)
    self.logger.info(f"üìä Analyse hebdomadaire planifi√©e {day} √† {time_str}")
        
        # Monitoring critique
    critical_interval = config["critical_monitoring"]
    schedule.every(critical_interval).minutes.do(self.execute_critical_monitoring)
    self.logger.info(f"üö® Monitoring critique toutes les {critical_interval} minutes")
    
    def execute_daily_analysis(self):
        """Ex√©cution de l'analyse quotidienne"""
    self.logger.info("üìä D√©but analyse quotidienne")
        
    try:
            # Ex√©cution de l'analyse
    results = self.agent.analyser_performance_globale()
    self.last_analysis_results = results
            
            # Sauvegarde du rapport
    rapport_path = self.agent.sauvegarder_rapport_strategique()
            
            # V√©rification des insights critiques
    critical_insights = [i for i in results["strategic_insights"] 
                   if i["severity"] in ["HIGH", "CRITICAL"]]
            
    if critical_insights:
    self.handle_critical_insights(critical_insights)
            
            # Nettoyage des anciens rapports
    self.cleanup_old_reports()
            
    self.logger.info(f"‚úÖ Analyse quotidienne termin√©e - Rapport: {rapport_path}")
            
    except Exception as e:
    self.logger.error(f"‚ùå Erreur analyse quotidienne: {e}")
    
    def execute_weekly_deep_analysis(self):
        """Ex√©cution de l'analyse hebdomadaire approfondie"""
    self.logger.info("üîç D√©but analyse hebdomadaire approfondie")
        
    try:
            # Analyse standard
    self.execute_daily_analysis()
            
            # Analyse des tendances sur 7 jours
    trends_analysis = self.analyze_weekly_trends()
            
            # G√©n√©ration du rapport hebdomadaire
    weekly_report = self.generate_weekly_executive_report(trends_analysis)
            
            # Sauvegarde du rapport hebdomadaire
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    weekly_report_path = self.agent.reports_path / f"RAPPORT_HEBDOMADAIRE_{timestamp}.md"
            
    with open(weekly_report_path, 'w', encoding='utf-8') as f:
    f.write(weekly_report)
            
    self.logger.info(f"‚úÖ Analyse hebdomadaire termin√©e - Rapport: {weekly_report_path}")
            
    except Exception as e:
    self.logger.error(f"‚ùå Erreur analyse hebdomadaire: {e}")
    
    def execute_critical_monitoring(self):
        """Monitoring critique pour d√©tection rapide des probl√®mes"""
    try:
            # V√©rification rapide des m√©triques critiques
    critical_metrics = self.check_critical_metrics()
            
    if critical_metrics["alerts"]:
    self.logger.warning(f"üö® {len(critical_metrics['alerts'])} alertes critiques d√©tect√©es")
                
                # Notification imm√©diate si configur√©e
    if self.config["notifications"]["email_enabled"]:
        self.send_critical_alert(critical_metrics["alerts"])
                
                # Ex√©cution d'une analyse d'urgence
    self.execute_emergency_analysis(critical_metrics)
            
    except Exception as e:
    self.logger.error(f"‚ùå Erreur monitoring critique: {e}")
    
    def check_critical_metrics(self) -> Dict[str, Any]:
        """V√©rification rapide des m√©triques critiques"""
    alerts = []
        
        # V√©rification des logs r√©cents
    recent_logs = list(self.agent.logs_path.glob("*.log"))
    for log_file in recent_logs[-5:]:  # 5 derniers logs
    if log_file.stat().st_size > 1024 * 1024:  # > 1MB
    try:
        with open(log_file, 'r', encoding='utf-8') as f:
            content = f.read()
            error_count = content.count("ERROR")
            if error_count > 10:
                alerts.append({
                    "type": "high_error_rate",
                    "source": log_file.name,
                    "error_count": error_count,
                    "severity": "CRITICAL"
                })
    except Exception:
        continue
        
        # V√©rification des m√©triques de performance r√©centes
    recent_metrics = list(self.agent.metrics_path.glob("*.json"))
    if recent_metrics:
    latest_metric = max(recent_metrics, key=lambda x: x.stat().st_mtime)
    if datetime.now() - datetime.fromtimestamp(latest_metric.stat().st_mtime) > timedelta(hours=2):
    alerts.append({
        "type": "stale_metrics",
        "message": "Aucune m√©trique r√©cente d√©tect√©e",
        "severity": "HIGH"
    })
        
    return {"alerts": alerts, "timestamp": datetime.now().isoformat()}
    
    def handle_critical_insights(self, critical_insights: List[Dict[str, Any]]):
        """Gestion des insights critiques"""
    self.logger.warning(f"üö® {len(critical_insights)} insights critiques d√©tect√©s")
        
        # Notification par email si configur√©e
    if self.config["notifications"]["email_enabled"]:
    self.send_critical_insights_notification(critical_insights)
        
        # Webhook si configur√©
    webhook_url = self.config["notifications"].get("webhook_url")
    if webhook_url:
    self.send_webhook_notification(critical_insights, webhook_url)
        
        # Log d√©taill√©
    for insight in critical_insights:
    self.logger.critical(f"INSIGHT CRITIQUE: {insight['title']} - {insight['description']}")
    
    def send_critical_alert(self, alerts: List[Dict[str, Any]]):
        """Envoi d'alerte critique par email"""
    if not self.config["notifications"]["email_enabled"]:
    return
        
    try:
    subject = f"üö® ALERTE CRITIQUE - NextGeneration - {datetime.now().strftime('%Y-%m-%d %H:%M')}"
            
    body = f"""
ALERTE CRITIQUE D√âTECT√âE

Nombre d'alertes: {len(alerts)}
Timestamp: {datetime.now().isoformat()}

D√âTAILS DES ALERTES:
"""
            
    for alert in alerts:
    body += f"""
- Type: {alert['type']}
- S√©v√©rit√©: {alert['severity']}
- D√©tails: {alert.get('message', 'N/A')}
"""
            
    body += """
Action requise: V√©rifier imm√©diatement le syst√®me NextGeneration.

---
Alerte g√©n√©r√©e automatiquement par l'Agent M√©ta-Strat√©gique
"""
            
    self.send_email(subject, body)
            
    except Exception as e:
    self.logger.error(f"Erreur envoi alerte email: {e}")
    
    def send_email(self, subject: str, body: str):
        """Envoi d'email"""
    config = self.config["notifications"]
        
    msg = MIMEMultipart()
    msg['From'] = config.get("email_from", "agent-meta@nextgeneration.com")
    msg['To'] = ", ".join(config["email_recipients"])
    msg['Subject'] = subject
        
    msg.attach(MIMEText(body, 'plain', 'utf-8'))
        
    server = smtplib.SMTP(config["smtp_server"], config["smtp_port"])
    server.starttls()
        
        # Authentification si configur√©e
    email_user = config.get("email_user")
    email_password = config.get("email_password")
    if email_user and email_password:
    server.login(email_user, email_password)
        
    server.send_message(msg)
    server.quit()
    
    def analyze_weekly_trends(self) -> Dict[str, Any]:
        """Analyse des tendances hebdomadaires"""
        # Collecte des rapports de la semaine
    week_ago = datetime.now() - timedelta(days=7)
        
    weekly_reports = []
    for report_file in self.agent.reports_path.glob("REVUE_STRATEGIQUE_*.md"):
    file_time = datetime.fromtimestamp(report_file.stat().st_mtime)
    if file_time >= week_ago:
    weekly_reports.append({
        "file": report_file.name,
        "timestamp": file_time,
        "size": report_file.stat().st_size
    })
        
    return {
    "reports_analyzed": len(weekly_reports),
    "period_start": week_ago.isoformat(),
    "period_end": datetime.now().isoformat(),
    "trend_summary": "Analyse des tendances hebdomadaires en cours de d√©veloppement"
    }
    
    def generate_weekly_executive_report(self, trends: Dict[str, Any]) -> str:
        """G√©n√©ration du rapport ex√©cutif hebdomadaire"""
    return f"""# üöß RAPPORT EX√âCUTIF HEBDOMADAIRE - VERSION DRAFT üöß
## Agent M√©ta-Strat√©gique PROTOTYPE - Semaine du {datetime.now().strftime('%Y-%m-%d')}

‚ö†Ô∏è **ATTENTION: RAPPORT G√âN√âR√â PAR VERSION EXP√âRIMENTALE**
- **Statut**: DRAFT/PROTOTYPE v0.1.0-draft
- **Usage**: Tests et validation uniquement

---

## üéØ R√âSUM√â DE LA SEMAINE

### Activit√© de Monitoring
- **Rapports g√©n√©r√©s**: {trends['reports_analyzed']}
- **P√©riode analys√©e**: {trends['period_start']} ‚Üí {trends['period_end']}

### Tendances Identifi√©es
{trends['trend_summary']}

---

## üìà √âVOLUTION DES M√âTRIQUES

*Analyse des tendances hebdomadaires en d√©veloppement*

---

## üí° RECOMMANDATIONS STRAT√âGIQUES

1. **Maintenir la surveillance continue** - Le syst√®me de monitoring fonctionne correctement
2. **Analyser les patterns √©mergents** - Identifier les tendances √† long terme
3. **Optimiser les processus** - Am√©liorer l'efficacit√© bas√©e sur les donn√©es collect√©es

---

*Rapport g√©n√©r√© automatiquement par l'Agent M√©ta-Strat√©gique*
*Prochaine analyse: {(datetime.now() + timedelta(days=7)).strftime('%Y-%m-%d')}*
"""
    
    def cleanup_old_reports(self):
        """Nettoyage des anciens rapports"""
    retention_days = self.config["analysis_settings"]["retention_days"]
    cutoff_date = datetime.now() - timedelta(days=retention_days)
        
    cleaned_count = 0
    for report_file in self.agent.reports_path.glob("REVUE_STRATEGIQUE_*.md"):
    file_time = datetime.fromtimestamp(report_file.stat().st_mtime)
    if file_time < cutoff_date:
    if self.config["analysis_settings"]["archive_reports"]:
                    # Archiver au lieu de supprimer
        archive_path = self.agent.reports_path / "archive"
        archive_path.mkdir(exist_ok=True)
        report_file.rename(archive_path / report_file.name)
    else:
        report_file.unlink()
    cleaned_count += 1
        
    if cleaned_count > 0:
    self.logger.info(f"üßπ {cleaned_count} anciens rapports nettoy√©s/archiv√©s")
    
    def execute_emergency_analysis(self, critical_metrics: Dict[str, Any]):
        """Analyse d'urgence en cas de probl√®me critique"""
    self.logger.critical("üö® Ex√©cution d'analyse d'urgence")
        
    try:
            # Analyse focalis√©e sur le probl√®me
    emergency_analysis = self.agent.analyser_performance_globale()
            
            # Ajout du contexte d'urgence
    emergency_analysis["emergency_context"] = {
    "trigger": "critical_monitoring",
    "alerts": critical_metrics["alerts"],
    "timestamp": datetime.now().isoformat()
    }
            
            # Sauvegarde du rapport d'urgence
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    emergency_report_path = self.agent.reports_path / f"URGENCE_STRATEGIQUE_{timestamp}.json"
            
    with open(emergency_report_path, 'w', encoding='utf-8') as f:
    json.dump(emergency_analysis, f, indent=2, ensure_ascii=False)
            
    self.logger.critical(f"üö® Rapport d'urgence sauvegard√©: {emergency_report_path}")
            
    except Exception as e:
    self.logger.error(f"‚ùå Erreur analyse d'urgence: {e}")


def main():
    """Fonction principale"""
    # Configuration du logging
    logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
    logging.FileHandler('agent_meta_strategique.log'),
    logging.StreamHandler()
    ]
    )
    
    # Cr√©ation et d√©marrage du planificateur
    scheduler = AgentMetaStrategiqueScheduler()
    scheduler.start_scheduler()


if __name__ == "__main__":
    main() 